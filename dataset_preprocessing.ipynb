{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nqj9p1iRQhB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have loaded your datasets into Pandas DataFrames named `patients` and `noteevents`\n",
        "# You can read CSV files using pd.read_csv or other appropriate methods.\n",
        "\n",
        "# Create a DataFrame for mimic.mimic3.patients\n",
        "patients = pd.read_csv('/content/drive/My Drive/PATIENTS.csv')  # Replace 'path/to/patients.csv' with the actual path\n",
        "\n",
        "# Create a DataFrame for mimic.mimic3.noteevents\n",
        "noteevents = pd.read_csv('/content/drive/My Drive/NOTEEVENTS.csv')  # Replace 'path/to/noteevents.csv' with the actual path"
      ],
      "metadata": {
        "id": "mWmZw3L7RWqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noteevents = noteevents.sort_values(by = 'CHARTDATE')"
      ],
      "metadata": {
        "id": "5LB_HXEZRYib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter cases where the category is \"discharge summary\"\n",
        "discharge_df = noteevents[noteevents['CATEGORY'] == 'Discharge summary']\n",
        "\n",
        "# Step 2: Convert 'Encounter_Date' to datetime if not already\n",
        "discharge_df['CHARTDATE'] = pd.to_datetime(discharge_df['CHARTDATE'])\n",
        "\n",
        "# step 3: Add \"within_date\" column with offset set to 30 days from discharge date\n",
        "discharge_df['within_date'] = discharge_df['CHARTDATE'] + pd.DateOffset(days=30)\n"
      ],
      "metadata": {
        "id": "uJNDwiC4Rabt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = discharge_df.sort_values(by='SUBJECT_ID')\n",
        "\n",
        "# Step 4: Keep only the first occurrence for each unique 'subject_id'\n",
        "df_first_occurrence = df_sorted.drop_duplicates(subset='SUBJECT_ID', keep='first')"
      ],
      "metadata": {
        "id": "gatDj7FwRc-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine discharge summary and noteevents data\n",
        "merged_df = pd.merge(noteevents, df_first_occurrence, on='SUBJECT_ID', suffixes=('', '_first'))\n",
        "\n",
        "# Step 5: Filter based on the condition that 'CHART DATE' is less than 'within_date' but more than the first discharge date\n",
        "merged_filtered_df = merged_df[(merged_df['CHARTDATE_first']<merged_df['CHARTDATE']) & (merged_df['CHARTDATE']< merged_df['within_date'])]"
      ],
      "metadata": {
        "id": "boxkQWyUR2g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### sort by chart time maybe\n",
        "merged_filtered_df= merged_filtered_df.sort_values(by='CHARTTIME')\n",
        "\n",
        "###and only keep the first one...\n",
        "final_df = merged_filtered_df.drop_duplicates(subset='SUBJECT_ID', keep='first')\n",
        "\n",
        "#merge with patients data\n",
        "merged_patients_notes = patients.merge(final_df, on='SUBJECT_ID')\n",
        "\n",
        "#load admissions data\n",
        "admissions = pd.read_csv('/content/drive/My Drive/ADMISSIONS.csv')\n",
        "\n",
        "#merge with demographic data from admissions.csv\n",
        "admissions_first = admissions.drop_duplicates(subset='SUBJECT_ID', keep='first')\n",
        "notes_demog = admissions_first.merge(merged_patients_notes, on='SUBJECT_ID')\n",
        "\n",
        "#drop unecessary columns\n",
        "notes_demog = notes_demog.drop(columns = [\"ROW_ID\",\"ADMITTIME\", \"DISCHTIME\", \"DOB\", \"DEATHTIME\", \"ADMISSION_TYPE\",\"ADMISSION_LOCATION\", \"DISCHARGE_LOCATION\", \"EDREGTIME\", \"EDOUTTIME\", \"DIAGNOSIS\", \"HOSPITAL_EXPIRE_FLAG\", \"HAS_CHARTEVENTS_DATA\", \"ROW_ID_x\", \"ROW_ID_y\", \"DOD\", \"DOD_HOSP\", \"DOD_SSN\", \"EXPIRE_FLAG\", \"HADM_ID_x\", \"HADM_ID_y\", \"STORETIME\", \"DESCRIPTION\", \"CGID\", \"ISERROR\", \"ROW_ID_first\",\"HADM_ID_first\", \"STORETIME_first\", \"DESCRIPTION_first\", \"CGID_first\", \"ISERROR_first\", ], axis = 1)\n",
        "\n",
        "#rename TEXT columns\n",
        "notes_demog = notes_demog.rename(columns = {\"TEXT\": \"Report2\", \"TEXT_first\": \"Report1\"})"
      ],
      "metadata": {
        "id": "z_ecJwrESb4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}