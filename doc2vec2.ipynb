{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>CARD_ARRHYTHMIA</th>\n",
       "      <th>CELL_SKIN_INF</th>\n",
       "      <th>CELL_NO_MCC</th>\n",
       "      <th>CVA_INFARCT</th>\n",
       "      <th>PANCREAS_DIS</th>\n",
       "      <th>DIGEST_DIS_NO_MCC</th>\n",
       "      <th>HEART_FAILURE</th>\n",
       "      <th>HEART_SHOCK_MCC</th>\n",
       "      <th>...</th>\n",
       "      <th>Brief Hospital Course</th>\n",
       "      <th>Medications on Admission</th>\n",
       "      <th>Discharge Medications</th>\n",
       "      <th>Discharge Disposition</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "      <th>Discharge Condition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>training_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29659838</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: ___ year-old female wit...</td>\n",
       "      <td>Medications on Admission: The Preadmission Med...</td>\n",
       "      <td>Discharge Medications: 1. HumuLIN 70/30 (insul...</td>\n",
       "      <td>Discharge Disposition: Home With Service\\n \\nF...</td>\n",
       "      <td>Discharge Diagnosis: Primary Diagnoses:\\nAcute...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: Mrs. ___, \\n\\n___ were...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: EW EMER., Admission Location: ...</td>\n",
       "      <td>[admission, type, ew, emer, admission, locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20897796</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medications on Admission: The Preadmission Med...</td>\n",
       "      <td>Discharge Medications: 1.  Acetaminophen 325-6...</td>\n",
       "      <td>Discharge Disposition: Home With Service\\n \\nF...</td>\n",
       "      <td>Discharge Diagnosis: PRIMARY DIAGNOSIS\\n- Acut...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: Dear ___,\\n\\nYou were ...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: OBSERVATION ADMIT, Admission L...</td>\n",
       "      <td>[admission, type, observation, admit, admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21975601</td>\n",
       "      <td>HOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: # Unstable angina: Desc...</td>\n",
       "      <td>Medications on Admission: - Clopidogrel 75 mg ...</td>\n",
       "      <td>Discharge Medications: 1. clopidogrel 75 mg Ta...</td>\n",
       "      <td>Discharge Disposition: Home</td>\n",
       "      <td>Discharge Diagnosis: Primary diagnosis:\\nAtypi...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: It was a pleasure taki...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: EW EMER., Admission Location: ...</td>\n",
       "      <td>[admission, type, ew, emer, admission, locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28994087</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: ___ female with NSCLC s...</td>\n",
       "      <td>Medications on Admission: amlodipine 5 mg Tabl...</td>\n",
       "      <td>Discharge Medications: 1. oxygen\\n___ continuo...</td>\n",
       "      <td>Discharge Disposition: Home With Service\\n \\nF...</td>\n",
       "      <td>Discharge Diagnosis: # post-obstructive pneumo...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: You were admitted with...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: EW EMER., Admission Location: ...</td>\n",
       "      <td>[admission, type, ew, emer, admission, locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26295318</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: TRANSITIONAL ISSUES:\\n=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge Medications: 1.  Rosuvastatin Calciu...</td>\n",
       "      <td>Discharge Disposition: Extended Care\\n \\nFacil...</td>\n",
       "      <td>Discharge Diagnosis: Primary diagnosis:\\n=====...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: Dear Mr. ___,\\n\\nIt wa...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: URGENT, Admission Location: TR...</td>\n",
       "      <td>[admission, type, urgent, admission, location,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19579</th>\n",
       "      <td>25047276</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: The patient was admitte...</td>\n",
       "      <td>Medications on Admission: The Preadmission Med...</td>\n",
       "      <td>Discharge Medications: 1. fluticasone 50 mcg/a...</td>\n",
       "      <td>Discharge Disposition: Home With Service\\n \\nF...</td>\n",
       "      <td>Discharge Diagnosis: Osteoarthritis, Left Knee</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: 1. Please return to th...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: SURGICAL SAME DAY ADMISSION, A...</td>\n",
       "      <td>[admission, type, surgical, day, admission, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19580</th>\n",
       "      <td>20274882</td>\n",
       "      <td>HOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medications on Admission: The Preadmission Med...</td>\n",
       "      <td>Discharge Medications: 1. Amlodipine 5 mg PO D...</td>\n",
       "      <td>Discharge Disposition: Home</td>\n",
       "      <td>Discharge Diagnosis: PRIMARY DIAGNOSIS\\n======...</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: Dear ___,\\n\\n___ were ...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: OBSERVATION ADMIT, Admission L...</td>\n",
       "      <td>[admission, type, observation, admit, admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19581</th>\n",
       "      <td>28129567</td>\n",
       "      <td>HOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: Positive stress test/CA...</td>\n",
       "      <td>Medications on Admission: The Preadmission Med...</td>\n",
       "      <td>Discharge Medications: 1. Aspirin 81 mg PO DAI...</td>\n",
       "      <td>Discharge Disposition: Home</td>\n",
       "      <td>Discharge Diagnosis: Coronary artery disease</td>\n",
       "      <td>Discharge Condition: Mental Status: Clear and ...</td>\n",
       "      <td>Discharge Instructions: Dear Ms. ___, \\n\\nTaki...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: URGENT, Admission Location: PH...</td>\n",
       "      <td>[admission, type, urgent, admission, location,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19582</th>\n",
       "      <td>27638769</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: # Altered Mental Status...</td>\n",
       "      <td>Medications on Admission: AZITHROMYCIN (starte...</td>\n",
       "      <td>Discharge Medications: 1. Doxazosin 1 mg Table...</td>\n",
       "      <td>Discharge Disposition: Home With Service\\n \\nF...</td>\n",
       "      <td>Discharge Diagnosis: Primary: pneumonia\\nSecon...</td>\n",
       "      <td>Discharge Condition: good, stable, intermitten...</td>\n",
       "      <td>Discharge Instructions: You were evaluated for...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: EW EMER., Admission Location: ...</td>\n",
       "      <td>[admission, type, ew, emer, admission, locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19583</th>\n",
       "      <td>26071774</td>\n",
       "      <td>HOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Brief Hospital Course: ___ year old man hx of ...</td>\n",
       "      <td>Medications on Admission: Keppra 1500mg BID\\nT...</td>\n",
       "      <td>Discharge Medications: 1. Metoprolol Tartrate ...</td>\n",
       "      <td>Discharge Disposition: Home</td>\n",
       "      <td>Discharge Diagnosis: Seizure/symptomatic Epile...</td>\n",
       "      <td>Discharge Condition: Improved</td>\n",
       "      <td>Discharge Instructions: You were admitted to t...</td>\n",
       "      <td>Followup Instructions: ___</td>\n",
       "      <td>Admission Type: EW EMER., Admission Location: ...</td>\n",
       "      <td>[admission, type, ew, emer, admission, locatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19584 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id        discharge_location  CARD_ARRHYTHMIA  CELL_SKIN_INF  \\\n",
       "0      29659838          HOME HEALTH CARE                0              0   \n",
       "1      20897796          HOME HEALTH CARE                0              0   \n",
       "2      21975601                      HOME                0              0   \n",
       "3      28994087          HOME HEALTH CARE                0              0   \n",
       "4      26295318  SKILLED NURSING FACILITY                0              0   \n",
       "...         ...                       ...              ...            ...   \n",
       "19579  25047276          HOME HEALTH CARE                0              0   \n",
       "19580  20274882                      HOME                0              0   \n",
       "19581  28129567                      HOME                0              0   \n",
       "19582  27638769          HOME HEALTH CARE                0              0   \n",
       "19583  26071774                      HOME                0              0   \n",
       "\n",
       "       CELL_NO_MCC  CVA_INFARCT  PANCREAS_DIS  DIGEST_DIS_NO_MCC  \\\n",
       "0                0            0             0                  0   \n",
       "1                0            0             0                  0   \n",
       "2                0            0             0                  0   \n",
       "3                0            0             0                  0   \n",
       "4                0            0             0                  0   \n",
       "...            ...          ...           ...                ...   \n",
       "19579            0            0             0                  0   \n",
       "19580            0            0             0                  0   \n",
       "19581            0            0             0                  0   \n",
       "19582            0            0             0                  0   \n",
       "19583            0            1             0                  0   \n",
       "\n",
       "       HEART_FAILURE  HEART_SHOCK_MCC  ...  \\\n",
       "0                  1                0  ...   \n",
       "1                  1                1  ...   \n",
       "2                  0                0  ...   \n",
       "3                  0                0  ...   \n",
       "4                  1                1  ...   \n",
       "...              ...              ...  ...   \n",
       "19579              0                0  ...   \n",
       "19580              0                0  ...   \n",
       "19581              0                0  ...   \n",
       "19582              0                0  ...   \n",
       "19583              0                0  ...   \n",
       "\n",
       "                                   Brief Hospital Course  \\\n",
       "0      Brief Hospital Course: ___ year-old female wit...   \n",
       "1                                                    NaN   \n",
       "2      Brief Hospital Course: # Unstable angina: Desc...   \n",
       "3      Brief Hospital Course: ___ female with NSCLC s...   \n",
       "4      Brief Hospital Course: TRANSITIONAL ISSUES:\\n=...   \n",
       "...                                                  ...   \n",
       "19579  Brief Hospital Course: The patient was admitte...   \n",
       "19580                                                NaN   \n",
       "19581  Brief Hospital Course: Positive stress test/CA...   \n",
       "19582  Brief Hospital Course: # Altered Mental Status...   \n",
       "19583  Brief Hospital Course: ___ year old man hx of ...   \n",
       "\n",
       "                                Medications on Admission  \\\n",
       "0      Medications on Admission: The Preadmission Med...   \n",
       "1      Medications on Admission: The Preadmission Med...   \n",
       "2      Medications on Admission: - Clopidogrel 75 mg ...   \n",
       "3      Medications on Admission: amlodipine 5 mg Tabl...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "19579  Medications on Admission: The Preadmission Med...   \n",
       "19580  Medications on Admission: The Preadmission Med...   \n",
       "19581  Medications on Admission: The Preadmission Med...   \n",
       "19582  Medications on Admission: AZITHROMYCIN (starte...   \n",
       "19583  Medications on Admission: Keppra 1500mg BID\\nT...   \n",
       "\n",
       "                                   Discharge Medications  \\\n",
       "0      Discharge Medications: 1. HumuLIN 70/30 (insul...   \n",
       "1      Discharge Medications: 1.  Acetaminophen 325-6...   \n",
       "2      Discharge Medications: 1. clopidogrel 75 mg Ta...   \n",
       "3      Discharge Medications: 1. oxygen\\n___ continuo...   \n",
       "4      Discharge Medications: 1.  Rosuvastatin Calciu...   \n",
       "...                                                  ...   \n",
       "19579  Discharge Medications: 1. fluticasone 50 mcg/a...   \n",
       "19580  Discharge Medications: 1. Amlodipine 5 mg PO D...   \n",
       "19581  Discharge Medications: 1. Aspirin 81 mg PO DAI...   \n",
       "19582  Discharge Medications: 1. Doxazosin 1 mg Table...   \n",
       "19583  Discharge Medications: 1. Metoprolol Tartrate ...   \n",
       "\n",
       "                                   Discharge Disposition  \\\n",
       "0      Discharge Disposition: Home With Service\\n \\nF...   \n",
       "1      Discharge Disposition: Home With Service\\n \\nF...   \n",
       "2                            Discharge Disposition: Home   \n",
       "3      Discharge Disposition: Home With Service\\n \\nF...   \n",
       "4      Discharge Disposition: Extended Care\\n \\nFacil...   \n",
       "...                                                  ...   \n",
       "19579  Discharge Disposition: Home With Service\\n \\nF...   \n",
       "19580                        Discharge Disposition: Home   \n",
       "19581                        Discharge Disposition: Home   \n",
       "19582  Discharge Disposition: Home With Service\\n \\nF...   \n",
       "19583                        Discharge Disposition: Home   \n",
       "\n",
       "                                     Discharge Diagnosis  \\\n",
       "0      Discharge Diagnosis: Primary Diagnoses:\\nAcute...   \n",
       "1      Discharge Diagnosis: PRIMARY DIAGNOSIS\\n- Acut...   \n",
       "2      Discharge Diagnosis: Primary diagnosis:\\nAtypi...   \n",
       "3      Discharge Diagnosis: # post-obstructive pneumo...   \n",
       "4      Discharge Diagnosis: Primary diagnosis:\\n=====...   \n",
       "...                                                  ...   \n",
       "19579     Discharge Diagnosis: Osteoarthritis, Left Knee   \n",
       "19580  Discharge Diagnosis: PRIMARY DIAGNOSIS\\n======...   \n",
       "19581       Discharge Diagnosis: Coronary artery disease   \n",
       "19582  Discharge Diagnosis: Primary: pneumonia\\nSecon...   \n",
       "19583  Discharge Diagnosis: Seizure/symptomatic Epile...   \n",
       "\n",
       "                                     Discharge Condition  \\\n",
       "0      Discharge Condition: Mental Status: Clear and ...   \n",
       "1      Discharge Condition: Mental Status: Clear and ...   \n",
       "2      Discharge Condition: Mental Status: Clear and ...   \n",
       "3      Discharge Condition: Mental Status: Clear and ...   \n",
       "4      Discharge Condition: Mental Status: Clear and ...   \n",
       "...                                                  ...   \n",
       "19579  Discharge Condition: Mental Status: Clear and ...   \n",
       "19580  Discharge Condition: Mental Status: Clear and ...   \n",
       "19581  Discharge Condition: Mental Status: Clear and ...   \n",
       "19582  Discharge Condition: good, stable, intermitten...   \n",
       "19583                      Discharge Condition: Improved   \n",
       "\n",
       "                                  Discharge Instructions  \\\n",
       "0      Discharge Instructions: Mrs. ___, \\n\\n___ were...   \n",
       "1      Discharge Instructions: Dear ___,\\n\\nYou were ...   \n",
       "2      Discharge Instructions: It was a pleasure taki...   \n",
       "3      Discharge Instructions: You were admitted with...   \n",
       "4      Discharge Instructions: Dear Mr. ___,\\n\\nIt wa...   \n",
       "...                                                  ...   \n",
       "19579  Discharge Instructions: 1. Please return to th...   \n",
       "19580  Discharge Instructions: Dear ___,\\n\\n___ were ...   \n",
       "19581  Discharge Instructions: Dear Ms. ___, \\n\\nTaki...   \n",
       "19582  Discharge Instructions: You were evaluated for...   \n",
       "19583  Discharge Instructions: You were admitted to t...   \n",
       "\n",
       "            Followup Instructions  \\\n",
       "0      Followup Instructions: ___   \n",
       "1      Followup Instructions: ___   \n",
       "2      Followup Instructions: ___   \n",
       "3      Followup Instructions: ___   \n",
       "4      Followup Instructions: ___   \n",
       "...                           ...   \n",
       "19579  Followup Instructions: ___   \n",
       "19580  Followup Instructions: ___   \n",
       "19581  Followup Instructions: ___   \n",
       "19582  Followup Instructions: ___   \n",
       "19583  Followup Instructions: ___   \n",
       "\n",
       "                                           training_text  \\\n",
       "0      Admission Type: EW EMER., Admission Location: ...   \n",
       "1      Admission Type: OBSERVATION ADMIT, Admission L...   \n",
       "2      Admission Type: EW EMER., Admission Location: ...   \n",
       "3      Admission Type: EW EMER., Admission Location: ...   \n",
       "4      Admission Type: URGENT, Admission Location: TR...   \n",
       "...                                                  ...   \n",
       "19579  Admission Type: SURGICAL SAME DAY ADMISSION, A...   \n",
       "19580  Admission Type: OBSERVATION ADMIT, Admission L...   \n",
       "19581  Admission Type: URGENT, Admission Location: PH...   \n",
       "19582  Admission Type: EW EMER., Admission Location: ...   \n",
       "19583  Admission Type: EW EMER., Admission Location: ...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [admission, type, ew, emer, admission, locatio...  \n",
       "1      [admission, type, observation, admit, admissio...  \n",
       "2      [admission, type, ew, emer, admission, locatio...  \n",
       "3      [admission, type, ew, emer, admission, locatio...  \n",
       "4      [admission, type, urgent, admission, location,...  \n",
       "...                                                  ...  \n",
       "19579  [admission, type, surgical, day, admission, ad...  \n",
       "19580  [admission, type, observation, admit, admissio...  \n",
       "19581  [admission, type, urgent, admission, location,...  \n",
       "19582  [admission, type, ew, emer, admission, locatio...  \n",
       "19583  [admission, type, ew, emer, admission, locatio...  \n",
       "\n",
       "[19584 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Admission Type: EW EMER., Admission Location: EMERGENCY ROOM, Insurance: '\n",
      " 'Medicare, Language: ENGLISH, Marital Status: WIDOWED, Race: WHITE, Gender: '\n",
      " 'F, Age: 88  \\n'\n",
      " 'Name:  ___                      Unit No:   ___\\n'\n",
      " ' \\n'\n",
      " 'Admission Date:  ___              Discharge Date:   ___\\n'\n",
      " ' \\n'\n",
      " 'Date of Birth:  ___             Sex:   F\\n'\n",
      " ' \\n'\n",
      " 'Service: SURGERY\\n'\n",
      " ' \\n'\n",
      " 'Allergies: \\n'\n",
      " 'Patient recorded as having No Known Allergies to Drugs\\n'\n",
      " ' \\n'\n",
      " 'Attending: ___. Chief Complaint: tx from OSH for evaluation of gallstone '\n",
      " 'pancreatitis Major Surgical or Invasive Procedure: none History of Present '\n",
      " 'Illness: ___ F transferred from OSH w/ gallstone pancreatitis. About 1\\n'\n",
      " 'month ago the patient was taken to the hospital s/p fall and\\n'\n",
      " 'found to have  UTI.  She was discharged to a rehab facility and \\n'\n",
      " '2\\n'\n",
      " 'weeks later she began having nausea and bouts of emesis.  This\\n'\n",
      " 'continued intermittently for 2 weeks with associated PO\\n'\n",
      " 'intolerance.  Given her poor PO intake and concern for\\n'\n",
      " 'malnutrition she was take to see a GI physician who found her to\\n'\n",
      " \"have elevated LFT's and lipase 439.  RUQ U/S demonstrated\\n\"\n",
      " 'cholelithiasis and gallstones without a sonographic ___. \\n'\n",
      " 'The GB wall is less than 3 mm and the CBD is 4.1 mm. There are \\n'\n",
      " 'no\\n'\n",
      " 'recorded fevers.  \\n'\n",
      " '\\n'\n",
      " 'After being transferred to our ED the patient was found to be\\n'\n",
      " 'hypotensive (SBP in ___s).  Her blood pressure responded well to\\n'\n",
      " 'fluid resuscitation.  She received approximately 5 L IVF.  The\\n'\n",
      " 'patient denies any abdominal pain.  She denies fevers or chills. Past '\n",
      " 'Medical History: PMH:  \\n'\n",
      " 'HTN, HLD, SIADH\\n'\n",
      " '\\n'\n",
      " 'PSH: none Social History: ___\\n'\n",
      " 'Family History:\\n'\n",
      " 'non contributory Physical Exam: VS: 99.8  87 103/49  14  100% 2L NC\\n'\n",
      " 'Gen: NAD, Alert\\n'\n",
      " '___: irregularly irregular\\n'\n",
      " 'Pulm: no respiratory distress\\n'\n",
      " 'Abd: slightly firm to deep palpation, ND, NT  no rebound, no\\n'\n",
      " 'guarding\\n'\n",
      " '___: minimal lower limb edema\\n'\n",
      " ' \\n'\n",
      " 'Pertinent Results:\\n'\n",
      " '___ 01:30AM   WBC-8.1 RBC-3.56* HGB-12.1 HCT-35.5* MCV-100* \\n'\n",
      " 'MCH-34.0* MCHC-34.0 RDW-16.2*\\n'\n",
      " '___ 01:30AM   ___ PTT-30.5 ___\\n'\n",
      " '___ 01:30AM   ALT(SGPT)-149* AST(SGOT)-165* ALK PHOS-447* \\n'\n",
      " 'TOT BILI-1.3\\n'\n",
      " '___ 01:30AM   LIPASE-442*\\n'\n",
      " '___ 01:30AM   GLUCOSE-94 UREA N-66* CREAT-1.9* SODIUM-135 \\n'\n",
      " 'POTASSIUM-4.7 CHLORIDE-97 TOTAL CO2-27 ANION GAP-16\\n'\n",
      " '___ 01:35AM   LACTATE-2.6* K+-6.3*\\n'\n",
      " '___ 03:46AM   LACTATE-1.5 K+-3.4*\\n'\n",
      " '___ 07:59PM   GLUCOSE-83 UREA N-50* CREAT-1.4* SODIUM-137 \\n'\n",
      " 'POTASSIUM-4.1 CHLORIDE-108 TOTAL CO2-22 ANION GAP-11\\n'\n",
      " '___ 07:59PM   ALT(SGPT)-97* AST(SGOT)-89* LD(___)-399* \\n'\n",
      " 'CK(CPK)-36 ALK PHOS-260* AMYLASE-82 TOT BILI-1.2\\n'\n",
      " '\\n'\n",
      " 'Glucose UreaN Creat Na K Cl HCO3 AnGap \\n'\n",
      " '___ 05:22    67*1 34* 1.7* 139 3.6 ___ \\n'\n",
      " 'Source: Line-CVL \\n'\n",
      " '___ 20:52        35* 1.7* 140 3.7 109* 23 12 \\n'\n",
      " 'Source: Line-CVL \\n'\n",
      " '___ 11:20    56*1 38* 1.8* 140 4.6 ___ \\n'\n",
      " '___ 02:02         39* 1.7* 138 4.2 ___ \\n'\n",
      " 'ADDED TE13-TE19 AT ___ \\n'\n",
      " '___ 16:36    67*1 41* 1.7* 137 3.7 ___ \\n'\n",
      " 'Source: Line-mll \\n'\n",
      " '___ 04:12         41* 1.7* 138 3.8 ___ \\n'\n",
      " '\\n'\n",
      " 'ALT AST LD(___) CK(___) AlkPhos Amylase TotBili DirBili IndBili \\n'\n",
      " '___ 05:22    50* 39     148*   1.0     \\n'\n",
      " 'Source: Line-CVL \\n'\n",
      " '___ 11:20    60* 50*     190* 47 1.2 0.5* 0.7 \\n'\n",
      " '___ 02:02    54* 46* 390*1   187* 45 1.2 0.5* 0.7 \\n'\n",
      " 'ADDED TE13-TE19 AT ___ \\n'\n",
      " '___ 03:00    60* 49* 323*   174*   1.6*     \\n'\n",
      " 'Source: Line-arterial \\n'\n",
      " '___ 03:03    85* 75* 355*   220* 61 1.4     \\n'\n",
      " '___ 19:59    97* 89* 399* 362 260* 82 1.2     \\n'\n",
      " '___ 01:30    149*3 165*4     447*   1.3     \\n'\n",
      " 'MODERATELY HEMOLYZED SPECIMEN \\n'\n",
      " '\\n'\n",
      " 'OTHER ENZYMES & BILIRUBINS Lipase \\n'\n",
      " '___ 05:22    87* \\n'\n",
      " '\\n'\n",
      " '___ CT Abd/pelvis: \\n'\n",
      " '1. Evaluation limited by the lack of IV contrast. \\n'\n",
      " '2. Rounded 2.6 cm calcified density in the epigastric region of \\n'\n",
      " 'unclear \\n'\n",
      " 'etiology. \\n'\n",
      " '3. Cholelithiasis \\n'\n",
      " '\\n'\n",
      " '___ Cardiac Echo : \\n'\n",
      " 'Suboptimal image quality. The left atrium is elongated. Left \\n'\n",
      " 'ventricular wall thicknesses are normal. The left ventricular \\n'\n",
      " 'cavity size is normal. Due to suboptimal technical quality, a \\n'\n",
      " 'focal wall motion abnormality cannot be fully excluded. Overall \\n'\n",
      " 'left ventricular systolic function is probably normal \\n'\n",
      " '(LVEF>50%). The right ventricular cavity is dilated with normal \\n'\n",
      " 'free wall contractility. The diameters of aorta at the sinus, \\n'\n",
      " 'ascending and arch levels are normal. The aortic valve leaflets \\n'\n",
      " '(3) are mildly thickened but aortic stenosis is not present. \\n'\n",
      " 'Trace aortic regurgitation is seen. The mitral valve leaflets \\n'\n",
      " 'are mildly thickened. Moderate (2+) mitral regurgitation is \\n'\n",
      " 'seen. The tricuspid valve leaflets are mildly thickened. \\n'\n",
      " 'Moderate [2+] tricuspid regurgitation is seen. There is mild \\n'\n",
      " 'pulmonary artery systolic hypertension. There is an anterior \\n'\n",
      " 'space which most likely represents a prominent fat pad.  \\n'\n",
      " '\\n'\n",
      " '___ Duplex scan left upper extremity : Technically limited \\n'\n",
      " 'study, no DVT seen in the left upper extremity. \\n'\n",
      " '\\n'\n",
      " 'URINE CULTURE (Final ___: \\n'\n",
      " '      PROTEUS MIRABILIS.    10,000-100,000 ORGANISMS/ML.. \\n'\n",
      " '         PRESUMPTIVE IDENTIFICATION. \\n'\n",
      " '      STAPH AUREUS COAG +.    >100,000 ORGANISMS/ML.. \\n'\n",
      " '\\n'\n",
      " '                              SENSITIVITIES: MIC expressed in \\n'\n",
      " 'MCG/ML\\n'\n",
      " '                      \\n'\n",
      " '_________________________________________________________\\n'\n",
      " '                             PROTEUS MIRABILIS\\n'\n",
      " '                             |          STAPH AUREUS COAG +\\n'\n",
      " '                             |          |   \\n'\n",
      " 'AMPICILLIN------------   <=2 S\\n'\n",
      " 'AMPICILLIN/SULBACTAM--   <=2 S\\n'\n",
      " 'CEFAZOLIN-------------    16 I\\n'\n",
      " 'CEFEPIME--------------   <=1 S\\n'\n",
      " 'CEFTAZIDIME-----------   <=1 S\\n'\n",
      " 'CEFTRIAXONE-----------   <=1 S\\n'\n",
      " 'CIPROFLOXACIN---------<=0.25 S\\n'\n",
      " 'GENTAMICIN------------   <=1 S    <=0.5 S\\n'\n",
      " 'LEVOFLOXACIN----------              =>8 R\\n'\n",
      " 'MEROPENEM-------------<=0.25 S\\n'\n",
      " 'NITROFURANTOIN--------             <=16 S\\n'\n",
      " 'OXACILLIN-------------              0.5 S\\n'\n",
      " 'PIPERACILLIN/TAZO-----   <=4 S\\n'\n",
      " 'TOBRAMYCIN------------   <=1 S\\n'\n",
      " 'TRIMETHOPRIM/SULFA----   <=1 S    <=0.5 S Brief Hospital Course: Surgery '\n",
      " 'evaluated the patient in the ED.  \\n'\n",
      " '\\n'\n",
      " 'OSH US demonstrated: Imaging ___ OSH:\\n'\n",
      " 'RUQ demonstrated cholelithiasis and gallstones without a \\n'\n",
      " 'sonographic ___.  The GB wall is less than 3 mm and the CBD \\n'\n",
      " 'is 4.1 mm.  There is a 7 mm mass in the right lobe of the liver. \\n'\n",
      " ' The pancreas is poorly visualized. \\n'\n",
      " '\\n'\n",
      " 'She was hypotensive and the ED resident placed a CVL for SBP in \\n'\n",
      " 'low 80___s.  She was bolused a total of ___ L and her blood \\n'\n",
      " 'pressure responded well.  On CXR after her CVL placement (L \\n'\n",
      " 'subclavian) it was noted this was actually not in the subclavian \\n'\n",
      " 'vein.  This was removed.  On ___ there was concern for clot in \\n'\n",
      " 'her L hand as it was discolored.  She did have dopplerable \\n'\n",
      " 'signals (radial/ulner).  She underwent LUE U/S and arterial U/S \\n'\n",
      " 'and no clot was seen.  An echocardiogram was performed which \\n'\n",
      " 'showed an EF of 50%.\\n'\n",
      " '\\n'\n",
      " 'Over the next several days her lipase trended downward however \\n'\n",
      " 'her Tbili remained elevated.  GI was consulted and ERCP was \\n'\n",
      " 'planned.\\n'\n",
      " '\\n'\n",
      " 'In the ICU she did have oliguria and mild renal insufficiency \\n'\n",
      " 'with Cr increasing from 1.3 on admission to as high as 1.9.  She \\n'\n",
      " 'was given albumin and was on a Lasix gtt for gentle diureses.  \\n'\n",
      " 'She responded well to this.  And it was discontinued in \\n'\n",
      " 'preparation for her ERCP.  \\n'\n",
      " ' \\n'\n",
      " 'Following transfer to the Surgical floor she remained stable in \\n'\n",
      " 'that she did not have any abdominal pain and when she was booked \\n'\n",
      " 'for her ERCP she refused adamantly. Her niece tried to encourage \\n'\n",
      " 'her to persue it but again Ms. ___ did not want it done.\\n'\n",
      " '\\n'\n",
      " 'Subsequently her low fat diet was resumed and she was able to \\n'\n",
      " 'eat without any pain or nausea.  Her appetite was only fair \\n'\n",
      " 'though and she was encouraged to try to eat as well as take \\n'\n",
      " 'protein shakes to try to increase her strength and help with \\n'\n",
      " 'healing of her decubitus ulcers which were noted on admission. \\n'\n",
      " '\\n'\n",
      " \"Her LFT's were trending down and her creatinine stabilized at \\n\"\n",
      " '1.7.  After much discussion with Ms. ___ and ___ niece, she \\n'\n",
      " 'decided to return to her rehab and evaluate how things go over \\n'\n",
      " 'the next few weeks.  She is determined to return home but she \\n'\n",
      " 'has a long way to go as she requires the ___ lift to get out \\n'\n",
      " 'of bed and she is just totally deconditioned since her last \\n'\n",
      " 'hospitalization.\\n'\n",
      " '\\n'\n",
      " 'Ms. ___ will return to the ___ today and \\n'\n",
      " 'will follow up in the ___ if she decides that she wants \\n'\n",
      " \"any further work up. Medications on Admission: lasix 20', prilosec 20', \"\n",
      " \"Compazine 10 Q6H prn, MVI', Vit D\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(df['training_text'].iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['hadm_id', 'CARD_ARRHYTHMIA', 'CELL_SKIN_INF',\n",
    "       'CELL_NO_MCC', 'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC',\n",
    "       'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI',\n",
    "       'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA',\n",
    "       'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', 'SEPTICEMIA', 'SYNCOPE',\n",
    "        'training_text']\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "df.to_csv('data/training_text_drg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=5; total time= 6.6min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=5; total time= 6.7min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=10; total time= 6.5min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=5; total time= 6.9min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=10; total time= 7.1min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=100, doc2vec__window=10; total time= 7.5min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=5; total time= 7.4min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=5; total time= 7.4min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=5; total time= 7.3min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=10; total time= 7.7min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=10; total time= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 17:06:31,864 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc2,s0.001,t4>', 'datetime': '2024-06-06T17:06:31.864139', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 17:06:31,864 : INFO : collecting all words and their counts\n",
      "2024-06-06 17:06:31,865 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=200, doc2vec__window=10; total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 17:06:32,862 : INFO : PROGRESS: at example #10000, processed 9007167 words (9032680 words/s), 82418 word types, 0 tags\n",
      "2024-06-06 17:06:33,410 : INFO : collected 105907 word types and 15667 unique tags from a corpus of 15667 examples and 14167241 words\n",
      "2024-06-06 17:06:33,411 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 17:06:33,491 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 50049 unique words (47.26% of original 105907, drops 55858)', 'datetime': '2024-06-06T17:06:33.491005', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 17:06:33,491 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 14111383 word corpus (99.61% of original 14167241, drops 55858)', 'datetime': '2024-06-06T17:06:33.491522', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 17:06:33,595 : INFO : deleting the raw counts dictionary of 105907 items\n",
      "2024-06-06 17:06:33,596 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2024-06-06 17:06:33,597 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 12741863.786470093 word corpus (90.3%% of prior 14111383)', 'datetime': '2024-06-06T17:06:33.597330', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 17:06:33,780 : INFO : estimated required memory for 50049 words and 200 dimensions: 120769900 bytes\n",
      "2024-06-06 17:06:33,781 : INFO : resetting layer weights\n",
      "2024-06-06 17:06:33,819 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 50049 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T17:06:33.819038', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 17:06:34,822 : INFO : EPOCH 0 - PROGRESS: at 14.23% examples, 1795092 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:35,823 : INFO : EPOCH 0 - PROGRESS: at 28.60% examples, 1815552 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:36,824 : INFO : EPOCH 0 - PROGRESS: at 44.11% examples, 1863841 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:37,826 : INFO : EPOCH 0 - PROGRESS: at 60.48% examples, 1921151 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:38,831 : INFO : EPOCH 0 - PROGRESS: at 75.89% examples, 1928391 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:39,831 : INFO : EPOCH 0 - PROGRESS: at 89.97% examples, 1912731 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:40,470 : INFO : EPOCH 0: training on 14167241 raw words (12757996 effective words) took 6.6s, 1919006 effective words/s\n",
      "2024-06-06 17:06:41,477 : INFO : EPOCH 1 - PROGRESS: at 14.81% examples, 1862706 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:42,477 : INFO : EPOCH 1 - PROGRESS: at 29.50% examples, 1870853 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:43,482 : INFO : EPOCH 1 - PROGRESS: at 44.30% examples, 1867432 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:44,484 : INFO : EPOCH 1 - PROGRESS: at 57.87% examples, 1835856 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:45,495 : INFO : EPOCH 1 - PROGRESS: at 71.97% examples, 1822515 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:46,497 : INFO : EPOCH 1 - PROGRESS: at 86.37% examples, 1829281 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:47,410 : INFO : EPOCH 1: training on 14167241 raw words (12757234 effective words) took 6.9s, 1838587 effective words/s\n",
      "2024-06-06 17:06:48,413 : INFO : EPOCH 2 - PROGRESS: at 14.09% examples, 1774733 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:49,420 : INFO : EPOCH 2 - PROGRESS: at 27.50% examples, 1741446 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:50,422 : INFO : EPOCH 2 - PROGRESS: at 42.20% examples, 1776873 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:51,424 : INFO : EPOCH 2 - PROGRESS: at 57.36% examples, 1818772 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:52,425 : INFO : EPOCH 2 - PROGRESS: at 72.93% examples, 1851531 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:53,430 : INFO : EPOCH 2 - PROGRESS: at 88.23% examples, 1871528 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:54,249 : INFO : EPOCH 2: training on 14167241 raw words (12757415 effective words) took 6.8s, 1865717 effective words/s\n",
      "2024-06-06 17:06:55,253 : INFO : EPOCH 3 - PROGRESS: at 14.95% examples, 1884003 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:56,254 : INFO : EPOCH 3 - PROGRESS: at 28.89% examples, 1830808 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:57,256 : INFO : EPOCH 3 - PROGRESS: at 44.11% examples, 1861638 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:06:58,257 : INFO : EPOCH 3 - PROGRESS: at 59.41% examples, 1885926 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:06:59,267 : INFO : EPOCH 3 - PROGRESS: at 75.13% examples, 1906318 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:00,268 : INFO : EPOCH 3 - PROGRESS: at 89.07% examples, 1888766 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:00,985 : INFO : EPOCH 3: training on 14167241 raw words (12757417 effective words) took 6.7s, 1894152 effective words/s\n",
      "2024-06-06 17:07:01,987 : INFO : EPOCH 4 - PROGRESS: at 14.48% examples, 1829469 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:02,993 : INFO : EPOCH 4 - PROGRESS: at 29.05% examples, 1840720 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:03,999 : INFO : EPOCH 4 - PROGRESS: at 43.80% examples, 1843649 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:05,004 : INFO : EPOCH 4 - PROGRESS: at 57.61% examples, 1825024 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:06,005 : INFO : EPOCH 4 - PROGRESS: at 72.09% examples, 1827822 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:07,008 : INFO : EPOCH 4 - PROGRESS: at 86.99% examples, 1844938 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:07,837 : INFO : EPOCH 4: training on 14167241 raw words (12757587 effective words) took 6.9s, 1862218 effective words/s\n",
      "2024-06-06 17:07:08,840 : INFO : EPOCH 5 - PROGRESS: at 14.95% examples, 1888275 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:09,840 : INFO : EPOCH 5 - PROGRESS: at 29.81% examples, 1897003 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:10,842 : INFO : EPOCH 5 - PROGRESS: at 43.20% examples, 1824233 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:11,843 : INFO : EPOCH 5 - PROGRESS: at 57.09% examples, 1814384 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:12,846 : INFO : EPOCH 5 - PROGRESS: at 71.97% examples, 1828686 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:13,847 : INFO : EPOCH 5 - PROGRESS: at 86.37% examples, 1834888 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:14,830 : INFO : EPOCH 5: training on 14167241 raw words (12757152 effective words) took 7.0s, 1824753 effective words/s\n",
      "2024-06-06 17:07:15,836 : INFO : EPOCH 6 - PROGRESS: at 13.89% examples, 1744356 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:16,838 : INFO : EPOCH 6 - PROGRESS: at 27.28% examples, 1730653 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:17,842 : INFO : EPOCH 6 - PROGRESS: at 42.34% examples, 1783028 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:18,842 : INFO : EPOCH 6 - PROGRESS: at 57.03% examples, 1809167 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:19,846 : INFO : EPOCH 6 - PROGRESS: at 72.43% examples, 1837715 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:20,849 : INFO : EPOCH 6 - PROGRESS: at 86.92% examples, 1844437 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:21,709 : INFO : EPOCH 6: training on 14167241 raw words (12756882 effective words) took 6.9s, 1854939 effective words/s\n",
      "2024-06-06 17:07:22,710 : INFO : EPOCH 7 - PROGRESS: at 15.50% examples, 1957217 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:23,710 : INFO : EPOCH 7 - PROGRESS: at 31.22% examples, 1982635 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:24,713 : INFO : EPOCH 7 - PROGRESS: at 47.13% examples, 1990676 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:25,722 : INFO : EPOCH 7 - PROGRESS: at 63.10% examples, 1998864 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:26,725 : INFO : EPOCH 7 - PROGRESS: at 78.33% examples, 1990523 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:27,728 : INFO : EPOCH 7 - PROGRESS: at 93.16% examples, 1975992 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:28,163 : INFO : EPOCH 7: training on 14167241 raw words (12757095 effective words) took 6.5s, 1977116 effective words/s\n",
      "2024-06-06 17:07:29,167 : INFO : EPOCH 8 - PROGRESS: at 14.02% examples, 1764471 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:30,168 : INFO : EPOCH 8 - PROGRESS: at 26.71% examples, 1694609 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:31,173 : INFO : EPOCH 8 - PROGRESS: at 39.93% examples, 1686991 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:32,173 : INFO : EPOCH 8 - PROGRESS: at 54.04% examples, 1711399 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:33,179 : INFO : EPOCH 8 - PROGRESS: at 67.85% examples, 1721918 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:34,180 : INFO : EPOCH 8 - PROGRESS: at 81.86% examples, 1734649 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:35,187 : INFO : EPOCH 8 - PROGRESS: at 95.63% examples, 1737604 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 17:07:35,529 : INFO : EPOCH 8: training on 14167241 raw words (12758200 effective words) took 7.4s, 1732253 effective words/s\n",
      "2024-06-06 17:07:36,538 : INFO : EPOCH 9 - PROGRESS: at 16.44% examples, 2052703 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:37,545 : INFO : EPOCH 9 - PROGRESS: at 31.88% examples, 2006961 words/s, in_qsize 8, out_qsize 1\n",
      "2024-06-06 17:07:38,553 : INFO : EPOCH 9 - PROGRESS: at 47.12% examples, 1977860 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:39,556 : INFO : EPOCH 9 - PROGRESS: at 62.06% examples, 1960230 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:40,563 : INFO : EPOCH 9 - PROGRESS: at 76.50% examples, 1934819 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:41,563 : INFO : EPOCH 9 - PROGRESS: at 90.93% examples, 1923695 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 17:07:42,159 : INFO : EPOCH 9: training on 14167241 raw words (12757523 effective words) took 6.6s, 1924466 effective words/s\n",
      "2024-06-06 17:07:42,160 : INFO : Doc2Vec lifecycle event {'msg': 'training on 141672410 raw words (127574501 effective words) took 68.3s, 1866759 effective words/s', 'datetime': '2024-06-06T17:07:42.160069', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'doc2vec__epochs': 10, 'doc2vec__min_count': 2, 'doc2vec__vector_size': 200, 'doc2vec__window': 5}\n",
      "Test F1 Score: 0.6712825585229146\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     CARD_ARRHYTHMIA       0.66      0.48      0.56       230\n",
      "       CELL_SKIN_INF       0.82      0.87      0.84       415\n",
      "         CELL_NO_MCC       0.78      0.81      0.80       361\n",
      "         CVA_INFARCT       0.85      0.86      0.85       222\n",
      "        PANCREAS_DIS       0.78      0.70      0.74       249\n",
      "   DIGEST_DIS_NO_MCC       0.62      0.52      0.56       436\n",
      "       HEART_FAILURE       0.72      0.63      0.67       457\n",
      "     HEART_SHOCK_MCC       0.54      0.34      0.41       313\n",
      "          KIDNEY_UTI       0.62      0.48      0.54       251\n",
      "JOINT_REPLACE_NO_MCC       0.90      0.79      0.84       237\n",
      "    DIGEST_DIS_OTHER       0.55      0.50      0.53       250\n",
      "       GASTRO_NAUSEA       0.64      0.44      0.52       286\n",
      "     PNEUMONIA_OTHER       0.62      0.48      0.54       250\n",
      "          PCI_NO_AMI       0.73      0.73      0.73       179\n",
      "           PSYCHOSES       0.95      0.97      0.96       267\n",
      "          SEPTICEMIA       0.72      0.47      0.56       264\n",
      "             SYNCOPE       0.70      0.50      0.58       228\n",
      "\n",
      "           micro avg       0.73      0.62      0.67      4895\n",
      "           macro avg       0.72      0.62      0.66      4895\n",
      "        weighted avg       0.71      0.62      0.66      4895\n",
      "         samples avg       0.59      0.62      0.59      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=2, epochs=10):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=4,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model.build_vocab(documents)\n",
    "        self.model.train(documents, total_examples=self.model.corpus_count, epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc) for doc in X])\n",
    "\n",
    "# Initialize the transformer and classifier\n",
    "doc2vec = Doc2VecTransformer()\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('doc2vec', doc2vec),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'doc2vec__vector_size': [100, 200],\n",
    "    'doc2vec__window': [5, 10],\n",
    "    'doc2vec__min_count': [2],\n",
    "    'doc2vec__epochs': [10]\n",
    "}\n",
    "\n",
    "# Define the scorer\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Test F1 Score: {accuracy}\")\n",
    "\n",
    "# Generate the classification report for each class\n",
    "report = classification_report(y_test, y_pred, target_names=class_columns, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time= 9.4min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=10.0min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=10.1min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time= 9.7min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time=10.2min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time=10.0min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=10.8min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=10.8min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=11.4min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=10.7min\n",
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=10.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END doc2vec__epochs=10, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=12.8min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=18.5min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=18.3min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=18.2min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=20.4min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=20.2min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=10; total time=20.4min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time=17.5min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time=17.4min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=5; total time=17.0min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=15.5min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=15.7min\n",
      "[CV] END doc2vec__epochs=20, doc2vec__min_count=2, doc2vec__vector_size=400, doc2vec__window=10; total time=15.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 18:16:41,150 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc2,s0.001,t4>', 'datetime': '2024-06-06T18:16:41.149979', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 18:16:41,150 : INFO : collecting all words and their counts\n",
      "2024-06-06 18:16:41,150 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-06-06 18:16:42,114 : INFO : PROGRESS: at example #10000, processed 9007167 words (9348543 words/s), 82418 word types, 0 tags\n",
      "2024-06-06 18:16:42,656 : INFO : collected 105907 word types and 15667 unique tags from a corpus of 15667 examples and 14167241 words\n",
      "2024-06-06 18:16:42,657 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 18:16:42,733 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 50049 unique words (47.26% of original 105907, drops 55858)', 'datetime': '2024-06-06T18:16:42.733204', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 18:16:42,733 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 14111383 word corpus (99.61% of original 14167241, drops 55858)', 'datetime': '2024-06-06T18:16:42.733853', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 18:16:42,832 : INFO : deleting the raw counts dictionary of 105907 items\n",
      "2024-06-06 18:16:42,834 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2024-06-06 18:16:42,834 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 12741863.786470093 word corpus (90.3%% of prior 14111383)', 'datetime': '2024-06-06T18:16:42.834410', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 18:16:43,008 : INFO : estimated required memory for 50049 words and 300 dimensions: 167075900 bytes\n",
      "2024-06-06 18:16:43,008 : INFO : resetting layer weights\n",
      "2024-06-06 18:16:43,065 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 50049 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T18:16:43.065810', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 18:16:44,075 : INFO : EPOCH 0 - PROGRESS: at 11.94% examples, 1493296 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:45,088 : INFO : EPOCH 0 - PROGRESS: at 24.02% examples, 1507742 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:46,089 : INFO : EPOCH 0 - PROGRESS: at 36.15% examples, 1521378 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:16:47,091 : INFO : EPOCH 0 - PROGRESS: at 48.41% examples, 1525948 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:48,096 : INFO : EPOCH 0 - PROGRESS: at 60.15% examples, 1521429 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:16:49,097 : INFO : EPOCH 0 - PROGRESS: at 71.48% examples, 1506938 words/s, in_qsize 7, out_qsize 1\n",
      "2024-06-06 18:16:50,098 : INFO : EPOCH 0 - PROGRESS: at 82.38% examples, 1493433 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:16:51,099 : INFO : EPOCH 0 - PROGRESS: at 93.92% examples, 1492164 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:51,620 : INFO : EPOCH 0: training on 14167241 raw words (12756656 effective words) took 8.6s, 1491374 effective words/s\n",
      "2024-06-06 18:16:52,631 : INFO : EPOCH 1 - PROGRESS: at 11.19% examples, 1397849 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:53,636 : INFO : EPOCH 1 - PROGRESS: at 22.65% examples, 1428157 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:54,639 : INFO : EPOCH 1 - PROGRESS: at 33.82% examples, 1422417 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:16:55,653 : INFO : EPOCH 1 - PROGRESS: at 46.26% examples, 1455599 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:56,654 : INFO : EPOCH 1 - PROGRESS: at 58.06% examples, 1469063 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:57,654 : INFO : EPOCH 1 - PROGRESS: at 69.59% examples, 1467075 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:16:58,656 : INFO : EPOCH 1 - PROGRESS: at 81.05% examples, 1468976 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:16:59,656 : INFO : EPOCH 1 - PROGRESS: at 91.99% examples, 1461372 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:00,357 : INFO : EPOCH 1: training on 14167241 raw words (12757542 effective words) took 8.7s, 1460416 effective words/s\n",
      "2024-06-06 18:17:01,359 : INFO : EPOCH 2 - PROGRESS: at 11.83% examples, 1488616 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:02,360 : INFO : EPOCH 2 - PROGRESS: at 22.47% examples, 1425260 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:03,364 : INFO : EPOCH 2 - PROGRESS: at 34.72% examples, 1468507 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:04,365 : INFO : EPOCH 2 - PROGRESS: at 46.26% examples, 1465054 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:05,366 : INFO : EPOCH 2 - PROGRESS: at 57.80% examples, 1469570 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:06,371 : INFO : EPOCH 2 - PROGRESS: at 69.65% examples, 1473582 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:07,382 : INFO : EPOCH 2 - PROGRESS: at 82.00% examples, 1488304 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:08,390 : INFO : EPOCH 2 - PROGRESS: at 94.38% examples, 1500055 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:08,895 : INFO : EPOCH 2: training on 14167241 raw words (12757422 effective words) took 8.5s, 1494416 effective words/s\n",
      "2024-06-06 18:17:09,903 : INFO : EPOCH 3 - PROGRESS: at 12.45% examples, 1562804 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:10,914 : INFO : EPOCH 3 - PROGRESS: at 24.78% examples, 1561147 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:11,921 : INFO : EPOCH 3 - PROGRESS: at 36.28% examples, 1526468 words/s, in_qsize 8, out_qsize 1\n",
      "2024-06-06 18:17:12,929 : INFO : EPOCH 3 - PROGRESS: at 48.75% examples, 1533916 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:13,933 : INFO : EPOCH 3 - PROGRESS: at 61.17% examples, 1544535 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:14,936 : INFO : EPOCH 3 - PROGRESS: at 73.24% examples, 1544348 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:15,940 : INFO : EPOCH 3 - PROGRESS: at 85.05% examples, 1540165 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:16,944 : INFO : EPOCH 3 - PROGRESS: at 97.61% examples, 1547099 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:17,138 : INFO : EPOCH 3: training on 14167241 raw words (12757571 effective words) took 8.2s, 1548068 effective words/s\n",
      "2024-06-06 18:17:18,140 : INFO : EPOCH 4 - PROGRESS: at 12.59% examples, 1588927 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:19,144 : INFO : EPOCH 4 - PROGRESS: at 24.78% examples, 1570418 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:20,145 : INFO : EPOCH 4 - PROGRESS: at 36.41% examples, 1541437 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:21,147 : INFO : EPOCH 4 - PROGRESS: at 48.93% examples, 1549340 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:22,152 : INFO : EPOCH 4 - PROGRESS: at 61.31% examples, 1555200 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:23,164 : INFO : EPOCH 4 - PROGRESS: at 73.68% examples, 1557491 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:24,172 : INFO : EPOCH 4 - PROGRESS: at 85.05% examples, 1542200 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:25,173 : INFO : EPOCH 4 - PROGRESS: at 97.61% examples, 1549538 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:25,361 : INFO : EPOCH 4: training on 14167241 raw words (12756898 effective words) took 8.2s, 1551605 effective words/s\n",
      "2024-06-06 18:17:26,367 : INFO : EPOCH 5 - PROGRESS: at 12.25% examples, 1540001 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:27,372 : INFO : EPOCH 5 - PROGRESS: at 24.02% examples, 1516452 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:28,374 : INFO : EPOCH 5 - PROGRESS: at 36.61% examples, 1546761 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:29,388 : INFO : EPOCH 5 - PROGRESS: at 49.79% examples, 1570182 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:30,392 : INFO : EPOCH 5 - PROGRESS: at 62.55% examples, 1580818 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:31,393 : INFO : EPOCH 5 - PROGRESS: at 75.42% examples, 1591591 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:32,396 : INFO : EPOCH 5 - PROGRESS: at 87.74% examples, 1592846 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:33,366 : INFO : EPOCH 5: training on 14167241 raw words (12757831 effective words) took 8.0s, 1593810 effective words/s\n",
      "2024-06-06 18:17:34,369 : INFO : EPOCH 6 - PROGRESS: at 12.25% examples, 1544439 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:35,371 : INFO : EPOCH 6 - PROGRESS: at 24.17% examples, 1530112 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:36,376 : INFO : EPOCH 6 - PROGRESS: at 36.41% examples, 1540179 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:37,385 : INFO : EPOCH 6 - PROGRESS: at 49.26% examples, 1556708 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:38,390 : INFO : EPOCH 6 - PROGRESS: at 61.73% examples, 1562936 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:39,397 : INFO : EPOCH 6 - PROGRESS: at 73.45% examples, 1551285 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:40,401 : INFO : EPOCH 6 - PROGRESS: at 85.66% examples, 1554301 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:41,403 : INFO : EPOCH 6 - PROGRESS: at 98.40% examples, 1561816 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:41,531 : INFO : EPOCH 6: training on 14167241 raw words (12759380 effective words) took 8.2s, 1562909 effective words/s\n",
      "2024-06-06 18:17:42,534 : INFO : EPOCH 7 - PROGRESS: at 12.59% examples, 1588637 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:43,534 : INFO : EPOCH 7 - PROGRESS: at 25.33% examples, 1608249 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:44,543 : INFO : EPOCH 7 - PROGRESS: at 38.43% examples, 1624281 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:45,547 : INFO : EPOCH 7 - PROGRESS: at 52.10% examples, 1649050 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:46,557 : INFO : EPOCH 7 - PROGRESS: at 65.70% examples, 1662370 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:47,561 : INFO : EPOCH 7 - PROGRESS: at 79.05% examples, 1671519 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:48,564 : INFO : EPOCH 7 - PROGRESS: at 92.44% examples, 1678316 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:49,125 : INFO : EPOCH 7: training on 14167241 raw words (12758251 effective words) took 7.6s, 1680491 effective words/s\n",
      "2024-06-06 18:17:50,128 : INFO : EPOCH 8 - PROGRESS: at 13.62% examples, 1715303 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:51,130 : INFO : EPOCH 8 - PROGRESS: at 27.17% examples, 1724373 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:52,137 : INFO : EPOCH 8 - PROGRESS: at 40.93% examples, 1725639 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:53,145 : INFO : EPOCH 8 - PROGRESS: at 54.63% examples, 1726334 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:54,146 : INFO : EPOCH 8 - PROGRESS: at 67.69% examples, 1714906 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:55,153 : INFO : EPOCH 8 - PROGRESS: at 81.20% examples, 1717026 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:56,155 : INFO : EPOCH 8 - PROGRESS: at 94.96% examples, 1723609 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:17:56,526 : INFO : EPOCH 8: training on 14167241 raw words (12757125 effective words) took 7.4s, 1724011 effective words/s\n",
      "2024-06-06 18:17:57,534 : INFO : EPOCH 9 - PROGRESS: at 13.56% examples, 1697372 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:58,537 : INFO : EPOCH 9 - PROGRESS: at 26.42% examples, 1673093 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:17:59,537 : INFO : EPOCH 9 - PROGRESS: at 40.22% examples, 1697697 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:00,538 : INFO : EPOCH 9 - PROGRESS: at 53.97% examples, 1708756 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:01,545 : INFO : EPOCH 9 - PROGRESS: at 67.54% examples, 1712260 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:02,549 : INFO : EPOCH 9 - PROGRESS: at 81.12% examples, 1717148 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:03,553 : INFO : EPOCH 9 - PROGRESS: at 94.66% examples, 1719631 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:03,941 : INFO : EPOCH 9: training on 14167241 raw words (12757684 effective words) took 7.4s, 1720857 effective words/s\n",
      "2024-06-06 18:18:04,943 : INFO : EPOCH 10 - PROGRESS: at 13.82% examples, 1742019 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:05,944 : INFO : EPOCH 10 - PROGRESS: at 27.43% examples, 1743220 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:06,945 : INFO : EPOCH 10 - PROGRESS: at 41.21% examples, 1741647 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:07,949 : INFO : EPOCH 10 - PROGRESS: at 54.94% examples, 1741950 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:08,952 : INFO : EPOCH 10 - PROGRESS: at 68.62% examples, 1742089 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:09,957 : INFO : EPOCH 10 - PROGRESS: at 82.20% examples, 1741917 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:10,957 : INFO : EPOCH 10 - PROGRESS: at 95.78% examples, 1741933 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:11,264 : INFO : EPOCH 10: training on 14167241 raw words (12757803 effective words) took 7.3s, 1742429 effective words/s\n",
      "2024-06-06 18:18:12,270 : INFO : EPOCH 11 - PROGRESS: at 13.89% examples, 1742973 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:13,276 : INFO : EPOCH 11 - PROGRESS: at 27.72% examples, 1751997 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:14,282 : INFO : EPOCH 11 - PROGRESS: at 41.65% examples, 1750230 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:15,288 : INFO : EPOCH 11 - PROGRESS: at 55.40% examples, 1749885 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:16,299 : INFO : EPOCH 11 - PROGRESS: at 69.22% examples, 1749398 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:17,299 : INFO : EPOCH 11 - PROGRESS: at 82.77% examples, 1748824 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:18,300 : INFO : EPOCH 11 - PROGRESS: at 96.50% examples, 1750237 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:18,552 : INFO : EPOCH 11: training on 14167241 raw words (12757401 effective words) took 7.3s, 1750621 effective words/s\n",
      "2024-06-06 18:18:19,561 : INFO : EPOCH 12 - PROGRESS: at 13.87% examples, 1738558 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:20,566 : INFO : EPOCH 12 - PROGRESS: at 27.72% examples, 1751051 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:21,568 : INFO : EPOCH 12 - PROGRESS: at 41.65% examples, 1751894 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:22,578 : INFO : EPOCH 12 - PROGRESS: at 55.40% examples, 1749442 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:23,580 : INFO : EPOCH 12 - PROGRESS: at 69.09% examples, 1748825 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:24,585 : INFO : EPOCH 12 - PROGRESS: at 82.77% examples, 1749852 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:25,585 : INFO : EPOCH 12 - PROGRESS: at 96.64% examples, 1753691 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:25,830 : INFO : EPOCH 12: training on 14167241 raw words (12758013 effective words) took 7.3s, 1753280 effective words/s\n",
      "2024-06-06 18:18:26,836 : INFO : EPOCH 13 - PROGRESS: at 13.89% examples, 1745089 words/s, in_qsize 7, out_qsize 1\n",
      "2024-06-06 18:18:27,838 : INFO : EPOCH 13 - PROGRESS: at 27.79% examples, 1760100 words/s, in_qsize 6, out_qsize 1\n",
      "2024-06-06 18:18:28,839 : INFO : EPOCH 13 - PROGRESS: at 41.65% examples, 1756085 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:29,844 : INFO : EPOCH 13 - PROGRESS: at 55.40% examples, 1754916 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:30,850 : INFO : EPOCH 13 - PROGRESS: at 69.22% examples, 1754744 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:31,851 : INFO : EPOCH 13 - PROGRESS: at 82.77% examples, 1753196 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:32,852 : INFO : EPOCH 13 - PROGRESS: at 96.50% examples, 1753916 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:33,107 : INFO : EPOCH 13: training on 14167241 raw words (12757872 effective words) took 7.3s, 1753405 effective words/s\n",
      "2024-06-06 18:18:34,108 : INFO : EPOCH 14 - PROGRESS: at 13.94% examples, 1760292 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:35,109 : INFO : EPOCH 14 - PROGRESS: at 27.79% examples, 1765758 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:36,114 : INFO : EPOCH 14 - PROGRESS: at 41.78% examples, 1763138 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:37,115 : INFO : EPOCH 14 - PROGRESS: at 55.40% examples, 1757232 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:38,121 : INFO : EPOCH 14 - PROGRESS: at 69.29% examples, 1758418 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:39,125 : INFO : EPOCH 14 - PROGRESS: at 83.14% examples, 1762168 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:40,131 : INFO : EPOCH 14 - PROGRESS: at 97.10% examples, 1763193 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:40,341 : INFO : EPOCH 14: training on 14167241 raw words (12757319 effective words) took 7.2s, 1763844 effective words/s\n",
      "2024-06-06 18:18:41,342 : INFO : EPOCH 15 - PROGRESS: at 13.94% examples, 1760411 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:42,344 : INFO : EPOCH 15 - PROGRESS: at 27.64% examples, 1755631 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:43,349 : INFO : EPOCH 15 - PROGRESS: at 41.72% examples, 1759957 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:44,363 : INFO : EPOCH 15 - PROGRESS: at 55.66% examples, 1759515 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:45,365 : INFO : EPOCH 15 - PROGRESS: at 69.59% examples, 1762046 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:46,374 : INFO : EPOCH 15 - PROGRESS: at 83.28% examples, 1760345 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:47,375 : INFO : EPOCH 15 - PROGRESS: at 97.15% examples, 1761841 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:47,583 : INFO : EPOCH 15: training on 14167241 raw words (12757848 effective words) took 7.2s, 1761781 effective words/s\n",
      "2024-06-06 18:18:48,588 : INFO : EPOCH 16 - PROGRESS: at 13.89% examples, 1745402 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:49,592 : INFO : EPOCH 16 - PROGRESS: at 27.79% examples, 1759866 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:50,594 : INFO : EPOCH 16 - PROGRESS: at 41.72% examples, 1757983 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:51,607 : INFO : EPOCH 16 - PROGRESS: at 55.69% examples, 1759115 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:52,616 : INFO : EPOCH 16 - PROGRESS: at 69.59% examples, 1758909 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:53,616 : INFO : EPOCH 16 - PROGRESS: at 83.21% examples, 1759207 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:54,618 : INFO : EPOCH 16 - PROGRESS: at 97.02% examples, 1759252 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:54,831 : INFO : EPOCH 16: training on 14167241 raw words (12757555 effective words) took 7.2s, 1760390 effective words/s\n",
      "2024-06-06 18:18:55,833 : INFO : EPOCH 17 - PROGRESS: at 14.02% examples, 1768009 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:18:56,841 : INFO : EPOCH 17 - PROGRESS: at 27.91% examples, 1766654 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:57,848 : INFO : EPOCH 17 - PROGRESS: at 42.04% examples, 1768539 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:58,852 : INFO : EPOCH 17 - PROGRESS: at 55.92% examples, 1768503 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:18:59,854 : INFO : EPOCH 17 - PROGRESS: at 69.86% examples, 1769107 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:00,856 : INFO : EPOCH 17 - PROGRESS: at 83.55% examples, 1768540 words/s, in_qsize 7, out_qsize 1\n",
      "2024-06-06 18:19:01,860 : INFO : EPOCH 17 - PROGRESS: at 97.37% examples, 1766668 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:02,056 : INFO : EPOCH 17: training on 14167241 raw words (12757413 effective words) took 7.2s, 1766175 effective words/s\n",
      "2024-06-06 18:19:03,064 : INFO : EPOCH 18 - PROGRESS: at 13.87% examples, 1739434 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:04,066 : INFO : EPOCH 18 - PROGRESS: at 27.72% examples, 1753812 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:05,067 : INFO : EPOCH 18 - PROGRESS: at 41.86% examples, 1763729 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:06,067 : INFO : EPOCH 18 - PROGRESS: at 55.33% examples, 1753665 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:07,068 : INFO : EPOCH 18 - PROGRESS: at 68.90% examples, 1749070 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:08,068 : INFO : EPOCH 18 - PROGRESS: at 82.57% examples, 1751613 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:09,069 : INFO : EPOCH 18 - PROGRESS: at 96.31% examples, 1752460 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:09,334 : INFO : EPOCH 18: training on 14167241 raw words (12757615 effective words) took 7.3s, 1753089 effective words/s\n",
      "2024-06-06 18:19:10,336 : INFO : EPOCH 19 - PROGRESS: at 13.94% examples, 1760415 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:11,341 : INFO : EPOCH 19 - PROGRESS: at 27.72% examples, 1757738 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:12,345 : INFO : EPOCH 19 - PROGRESS: at 41.79% examples, 1761275 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:13,345 : INFO : EPOCH 19 - PROGRESS: at 55.75% examples, 1766819 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:14,347 : INFO : EPOCH 19 - PROGRESS: at 69.65% examples, 1767909 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 18:19:15,351 : INFO : EPOCH 19 - PROGRESS: at 83.49% examples, 1769771 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:16,363 : INFO : EPOCH 19 - PROGRESS: at 97.37% examples, 1766803 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 18:19:16,555 : INFO : EPOCH 19: training on 14167241 raw words (12758239 effective words) took 7.2s, 1767170 effective words/s\n",
      "2024-06-06 18:19:16,556 : INFO : Doc2Vec lifecycle event {'msg': 'training on 283344820 raw words (255153438 effective words) took 153.5s, 1662349 effective words/s', 'datetime': '2024-06-06T18:19:16.556131', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'doc2vec__epochs': 20, 'doc2vec__min_count': 2, 'doc2vec__vector_size': 300, 'doc2vec__window': 5}\n",
      "Test F1 Score: 0.7036514020576962\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     CARD_ARRHYTHMIA       0.64      0.55      0.59       230\n",
      "       CELL_SKIN_INF       0.81      0.93      0.86       415\n",
      "         CELL_NO_MCC       0.76      0.91      0.83       361\n",
      "         CVA_INFARCT       0.83      0.90      0.86       222\n",
      "        PANCREAS_DIS       0.74      0.80      0.76       249\n",
      "   DIGEST_DIS_NO_MCC       0.59      0.64      0.61       436\n",
      "       HEART_FAILURE       0.71      0.72      0.71       457\n",
      "     HEART_SHOCK_MCC       0.56      0.43      0.49       313\n",
      "          KIDNEY_UTI       0.63      0.59      0.61       251\n",
      "JOINT_REPLACE_NO_MCC       0.92      0.89      0.90       237\n",
      "    DIGEST_DIS_OTHER       0.50      0.61      0.55       250\n",
      "       GASTRO_NAUSEA       0.61      0.57      0.59       286\n",
      "     PNEUMONIA_OTHER       0.57      0.58      0.57       250\n",
      "          PCI_NO_AMI       0.70      0.78      0.74       179\n",
      "           PSYCHOSES       0.89      0.96      0.93       267\n",
      "          SEPTICEMIA       0.66      0.56      0.60       264\n",
      "             SYNCOPE       0.67      0.66      0.66       228\n",
      "\n",
      "           micro avg       0.69      0.71      0.70      4895\n",
      "           macro avg       0.69      0.71      0.70      4895\n",
      "        weighted avg       0.69      0.71      0.70      4895\n",
      "         samples avg       0.64      0.71      0.65      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=2, epochs=10):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=4,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model.build_vocab(documents)\n",
    "        self.model.train(documents, total_examples=self.model.corpus_count, epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc) for doc in X])\n",
    "\n",
    "# Initialize the transformer and classifier\n",
    "doc2vec = Doc2VecTransformer()\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('doc2vec', doc2vec),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'doc2vec__vector_size': [300, 400],\n",
    "    'doc2vec__window': [5, 10],\n",
    "    'doc2vec__min_count': [2],\n",
    "    'doc2vec__epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# Define the scorer\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=9)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Test F1 Score: {accuracy}\")\n",
    "\n",
    "# Generate the classification report for each class\n",
    "report = classification_report(y_test, y_pred, target_names=class_columns, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END doc2vec__epochs=30, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=63.7min\n",
      "[CV] END doc2vec__epochs=30, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=63.6min\n",
      "[CV] END doc2vec__epochs=30, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=63.8min\n",
      "[CV] END doc2vec__epochs=40, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=70.2min\n",
      "[CV] END doc2vec__epochs=40, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=70.8min\n",
      "[CV] END doc2vec__epochs=40, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=71.5min\n",
      "[CV] END doc2vec__epochs=50, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=76.2min\n",
      "[CV] END doc2vec__epochs=50, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=76.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 20:17:40,986 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc2,s0.001,t4>', 'datetime': '2024-06-06T20:17:40.986682', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END doc2vec__epochs=50, doc2vec__min_count=2, doc2vec__vector_size=300, doc2vec__window=5; total time=76.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 20:17:40,987 : INFO : collecting all words and their counts\n",
      "2024-06-06 20:17:40,988 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-06-06 20:17:42,022 : INFO : PROGRESS: at example #10000, processed 9007167 words (8707259 words/s), 82418 word types, 0 tags\n",
      "2024-06-06 20:17:42,613 : INFO : collected 105907 word types and 15667 unique tags from a corpus of 15667 examples and 14167241 words\n",
      "2024-06-06 20:17:42,614 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 20:17:42,685 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 50049 unique words (47.26% of original 105907, drops 55858)', 'datetime': '2024-06-06T20:17:42.685691', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 20:17:42,686 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 14111383 word corpus (99.61% of original 14167241, drops 55858)', 'datetime': '2024-06-06T20:17:42.686031', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 20:17:42,774 : INFO : deleting the raw counts dictionary of 105907 items\n",
      "2024-06-06 20:17:42,775 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2024-06-06 20:17:42,776 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 12741863.786470093 word corpus (90.3%% of prior 14111383)', 'datetime': '2024-06-06T20:17:42.776243', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 20:17:42,938 : INFO : estimated required memory for 50049 words and 300 dimensions: 167075900 bytes\n",
      "2024-06-06 20:17:42,938 : INFO : resetting layer weights\n",
      "2024-06-06 20:17:42,992 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 50049 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T20:17:42.992029', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 20:17:44,002 : INFO : EPOCH 0 - PROGRESS: at 12.01% examples, 1500261 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:45,004 : INFO : EPOCH 0 - PROGRESS: at 23.31% examples, 1472947 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:46,012 : INFO : EPOCH 0 - PROGRESS: at 35.15% examples, 1480597 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:47,020 : INFO : EPOCH 0 - PROGRESS: at 47.12% examples, 1484677 words/s, in_qsize 8, out_qsize 1\n",
      "2024-06-06 20:17:48,021 : INFO : EPOCH 0 - PROGRESS: at 59.55% examples, 1506483 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:49,023 : INFO : EPOCH 0 - PROGRESS: at 72.22% examples, 1523964 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:17:50,030 : INFO : EPOCH 0 - PROGRESS: at 84.84% examples, 1537745 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:51,035 : INFO : EPOCH 0 - PROGRESS: at 97.91% examples, 1552514 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:51,200 : INFO : EPOCH 0: training on 14167241 raw words (12758185 effective words) took 8.2s, 1554581 effective words/s\n",
      "2024-06-06 20:17:52,202 : INFO : EPOCH 1 - PROGRESS: at 13.21% examples, 1665495 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:17:53,212 : INFO : EPOCH 1 - PROGRESS: at 26.09% examples, 1651123 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:17:54,227 : INFO : EPOCH 1 - PROGRESS: at 39.25% examples, 1649092 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:55,229 : INFO : EPOCH 1 - PROGRESS: at 52.38% examples, 1652031 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:17:56,232 : INFO : EPOCH 1 - PROGRESS: at 65.04% examples, 1643103 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:17:57,240 : INFO : EPOCH 1 - PROGRESS: at 77.69% examples, 1639013 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:58,247 : INFO : EPOCH 1 - PROGRESS: at 90.21% examples, 1635057 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:17:58,985 : INFO : EPOCH 1: training on 14167241 raw words (12757500 effective words) took 7.8s, 1638953 effective words/s\n",
      "2024-06-06 20:17:59,988 : INFO : EPOCH 2 - PROGRESS: at 13.08% examples, 1647455 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:00,989 : INFO : EPOCH 2 - PROGRESS: at 26.09% examples, 1657596 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:01,997 : INFO : EPOCH 2 - PROGRESS: at 39.25% examples, 1657332 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:03,001 : INFO : EPOCH 2 - PROGRESS: at 52.66% examples, 1665715 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:04,005 : INFO : EPOCH 2 - PROGRESS: at 65.78% examples, 1665742 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:05,008 : INFO : EPOCH 2 - PROGRESS: at 78.78% examples, 1667426 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:06,011 : INFO : EPOCH 2 - PROGRESS: at 91.61% examples, 1664004 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:06,649 : INFO : EPOCH 2: training on 14167241 raw words (12756752 effective words) took 7.7s, 1664797 effective words/s\n",
      "2024-06-06 20:18:07,655 : INFO : EPOCH 3 - PROGRESS: at 13.35% examples, 1675130 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:08,660 : INFO : EPOCH 3 - PROGRESS: at 26.58% examples, 1681720 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:09,664 : INFO : EPOCH 3 - PROGRESS: at 39.95% examples, 1684496 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:10,665 : INFO : EPOCH 3 - PROGRESS: at 53.18% examples, 1682680 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:11,666 : INFO : EPOCH 3 - PROGRESS: at 66.42% examples, 1683528 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:12,668 : INFO : EPOCH 3 - PROGRESS: at 79.70% examples, 1688157 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:13,671 : INFO : EPOCH 3 - PROGRESS: at 92.75% examples, 1686252 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:14,206 : INFO : EPOCH 3: training on 14167241 raw words (12757008 effective words) took 7.6s, 1688292 effective words/s\n",
      "2024-06-06 20:18:15,209 : INFO : EPOCH 4 - PROGRESS: at 13.35% examples, 1682125 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:16,214 : INFO : EPOCH 4 - PROGRESS: at 26.83% examples, 1700451 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:17,215 : INFO : EPOCH 4 - PROGRESS: at 40.29% examples, 1701868 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:18,216 : INFO : EPOCH 4 - PROGRESS: at 53.67% examples, 1700713 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:19,217 : INFO : EPOCH 4 - PROGRESS: at 66.94% examples, 1699469 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:20,220 : INFO : EPOCH 4 - PROGRESS: at 80.09% examples, 1698222 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:21,225 : INFO : EPOCH 4 - PROGRESS: at 93.50% examples, 1700635 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:21,702 : INFO : EPOCH 4: training on 14167241 raw words (12757518 effective words) took 7.5s, 1702049 effective words/s\n",
      "2024-06-06 20:18:22,707 : INFO : EPOCH 5 - PROGRESS: at 13.56% examples, 1704446 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:23,712 : INFO : EPOCH 5 - PROGRESS: at 26.89% examples, 1703568 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:24,720 : INFO : EPOCH 5 - PROGRESS: at 40.35% examples, 1699875 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:25,722 : INFO : EPOCH 5 - PROGRESS: at 54.04% examples, 1707479 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:26,725 : INFO : EPOCH 5 - PROGRESS: at 67.43% examples, 1707365 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:27,730 : INFO : EPOCH 5 - PROGRESS: at 80.64% examples, 1705694 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:28,733 : INFO : EPOCH 5 - PROGRESS: at 94.04% examples, 1707746 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:29,172 : INFO : EPOCH 5: training on 14167241 raw words (12758155 effective words) took 7.5s, 1708334 effective words/s\n",
      "2024-06-06 20:18:30,173 : INFO : EPOCH 6 - PROGRESS: at 13.49% examples, 1701402 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:31,180 : INFO : EPOCH 6 - PROGRESS: at 26.89% examples, 1704042 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:32,189 : INFO : EPOCH 6 - PROGRESS: at 40.64% examples, 1710440 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:33,194 : INFO : EPOCH 6 - PROGRESS: at 54.34% examples, 1716757 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:34,200 : INFO : EPOCH 6 - PROGRESS: at 67.92% examples, 1719344 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:35,205 : INFO : EPOCH 6 - PROGRESS: at 81.39% examples, 1719960 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:36,209 : INFO : EPOCH 6 - PROGRESS: at 94.81% examples, 1719538 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:36,588 : INFO : EPOCH 6: training on 14167241 raw words (12757529 effective words) took 7.4s, 1720332 effective words/s\n",
      "2024-06-06 20:18:37,591 : INFO : EPOCH 7 - PROGRESS: at 13.62% examples, 1716788 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:38,594 : INFO : EPOCH 7 - PROGRESS: at 27.17% examples, 1723986 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:39,595 : INFO : EPOCH 7 - PROGRESS: at 40.93% examples, 1728542 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:40,597 : INFO : EPOCH 7 - PROGRESS: at 54.63% examples, 1731603 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:41,597 : INFO : EPOCH 7 - PROGRESS: at 68.28% examples, 1734682 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:42,604 : INFO : EPOCH 7 - PROGRESS: at 81.73% examples, 1732116 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:43,608 : INFO : EPOCH 7 - PROGRESS: at 95.39% examples, 1733679 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:43,948 : INFO : EPOCH 7: training on 14167241 raw words (12758021 effective words) took 7.4s, 1733702 effective words/s\n",
      "2024-06-06 20:18:44,954 : INFO : EPOCH 8 - PROGRESS: at 13.82% examples, 1736486 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:45,955 : INFO : EPOCH 8 - PROGRESS: at 27.36% examples, 1735699 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:46,958 : INFO : EPOCH 8 - PROGRESS: at 41.28% examples, 1741581 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:47,961 : INFO : EPOCH 8 - PROGRESS: at 54.94% examples, 1740189 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:48,966 : INFO : EPOCH 8 - PROGRESS: at 68.62% examples, 1740132 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:49,970 : INFO : EPOCH 8 - PROGRESS: at 82.20% examples, 1740219 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:50,973 : INFO : EPOCH 8 - PROGRESS: at 95.78% examples, 1739811 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:51,279 : INFO : EPOCH 8: training on 14167241 raw words (12757766 effective words) took 7.3s, 1740647 effective words/s\n",
      "2024-06-06 20:18:52,284 : INFO : EPOCH 9 - PROGRESS: at 13.82% examples, 1736257 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:53,292 : INFO : EPOCH 9 - PROGRESS: at 27.43% examples, 1734195 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:54,293 : INFO : EPOCH 9 - PROGRESS: at 41.35% examples, 1741945 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:55,303 : INFO : EPOCH 9 - PROGRESS: at 55.13% examples, 1741445 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:56,310 : INFO : EPOCH 9 - PROGRESS: at 69.02% examples, 1745553 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:57,314 : INFO : EPOCH 9 - PROGRESS: at 82.57% examples, 1744508 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:18:58,318 : INFO : EPOCH 9 - PROGRESS: at 96.25% examples, 1744739 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:18:58,588 : INFO : EPOCH 9: training on 14167241 raw words (12756980 effective words) took 7.3s, 1745636 effective words/s\n",
      "2024-06-06 20:18:59,589 : INFO : EPOCH 10 - PROGRESS: at 13.94% examples, 1759989 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:00,594 : INFO : EPOCH 10 - PROGRESS: at 27.72% examples, 1757327 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:01,595 : INFO : EPOCH 10 - PROGRESS: at 41.72% examples, 1759782 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:02,597 : INFO : EPOCH 10 - PROGRESS: at 55.40% examples, 1756671 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:03,602 : INFO : EPOCH 10 - PROGRESS: at 69.22% examples, 1756530 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:04,603 : INFO : EPOCH 10 - PROGRESS: at 82.91% examples, 1757487 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:05,603 : INFO : EPOCH 10 - PROGRESS: at 96.50% examples, 1755417 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:05,852 : INFO : EPOCH 10: training on 14167241 raw words (12757071 effective words) took 7.3s, 1756442 effective words/s\n",
      "2024-06-06 20:19:06,866 : INFO : EPOCH 11 - PROGRESS: at 13.87% examples, 1729921 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:07,867 : INFO : EPOCH 11 - PROGRESS: at 27.64% examples, 1745680 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:08,868 : INFO : EPOCH 11 - PROGRESS: at 41.49% examples, 1745847 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:09,868 : INFO : EPOCH 11 - PROGRESS: at 55.20% examples, 1746731 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:10,871 : INFO : EPOCH 11 - PROGRESS: at 68.95% examples, 1748234 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:11,871 : INFO : EPOCH 11 - PROGRESS: at 82.49% examples, 1747969 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:12,871 : INFO : EPOCH 11 - PROGRESS: at 96.25% examples, 1749662 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:13,138 : INFO : EPOCH 11: training on 14167241 raw words (12757008 effective words) took 7.3s, 1751197 effective words/s\n",
      "2024-06-06 20:19:14,141 : INFO : EPOCH 12 - PROGRESS: at 13.95% examples, 1758159 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:15,141 : INFO : EPOCH 12 - PROGRESS: at 27.72% examples, 1760449 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:16,143 : INFO : EPOCH 12 - PROGRESS: at 41.78% examples, 1764585 words/s, in_qsize 7, out_qsize 1\n",
      "2024-06-06 20:19:17,145 : INFO : EPOCH 12 - PROGRESS: at 55.69% examples, 1766213 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:18,150 : INFO : EPOCH 12 - PROGRESS: at 69.80% examples, 1771505 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:19,159 : INFO : EPOCH 12 - PROGRESS: at 83.55% examples, 1769812 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:20,159 : INFO : EPOCH 12 - PROGRESS: at 96.85% examples, 1760140 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:20,379 : INFO : EPOCH 12: training on 14167241 raw words (12757869 effective words) took 7.2s, 1762192 effective words/s\n",
      "2024-06-06 20:19:21,384 : INFO : EPOCH 13 - PROGRESS: at 14.16% examples, 1778056 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:22,386 : INFO : EPOCH 13 - PROGRESS: at 27.99% examples, 1773517 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:23,391 : INFO : EPOCH 13 - PROGRESS: at 42.06% examples, 1771142 words/s, in_qsize 6, out_qsize 1\n",
      "2024-06-06 20:19:24,394 : INFO : EPOCH 13 - PROGRESS: at 55.92% examples, 1771024 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:25,395 : INFO : EPOCH 13 - PROGRESS: at 69.92% examples, 1772986 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:26,399 : INFO : EPOCH 13 - PROGRESS: at 83.73% examples, 1774045 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:27,400 : INFO : EPOCH 13 - PROGRESS: at 97.61% examples, 1773106 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:27,566 : INFO : EPOCH 13: training on 14167241 raw words (12756842 effective words) took 7.2s, 1775215 effective words/s\n",
      "2024-06-06 20:19:28,567 : INFO : EPOCH 14 - PROGRESS: at 14.09% examples, 1777159 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:29,568 : INFO : EPOCH 14 - PROGRESS: at 27.91% examples, 1773542 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:30,580 : INFO : EPOCH 14 - PROGRESS: at 42.04% examples, 1770062 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:31,580 : INFO : EPOCH 14 - PROGRESS: at 55.98% examples, 1773723 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:32,584 : INFO : EPOCH 14 - PROGRESS: at 69.99% examples, 1774157 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:33,587 : INFO : EPOCH 14 - PROGRESS: at 83.73% examples, 1773977 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:34,595 : INFO : EPOCH 14 - PROGRESS: at 97.68% examples, 1772611 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:34,755 : INFO : EPOCH 14: training on 14167241 raw words (12757864 effective words) took 7.2s, 1774773 effective words/s\n",
      "2024-06-06 20:19:35,757 : INFO : EPOCH 15 - PROGRESS: at 14.02% examples, 1768801 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:36,760 : INFO : EPOCH 15 - PROGRESS: at 27.91% examples, 1771696 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:37,767 : INFO : EPOCH 15 - PROGRESS: at 42.04% examples, 1771479 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:38,767 : INFO : EPOCH 15 - PROGRESS: at 55.98% examples, 1774817 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:39,772 : INFO : EPOCH 15 - PROGRESS: at 70.22% examples, 1779927 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:40,775 : INFO : EPOCH 15 - PROGRESS: at 84.00% examples, 1780171 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:41,777 : INFO : EPOCH 15 - PROGRESS: at 97.87% examples, 1777863 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:41,931 : INFO : EPOCH 15: training on 14167241 raw words (12757709 effective words) took 7.2s, 1778157 effective words/s\n",
      "2024-06-06 20:19:42,937 : INFO : EPOCH 16 - PROGRESS: at 14.09% examples, 1769478 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:43,942 : INFO : EPOCH 16 - PROGRESS: at 28.19% examples, 1783672 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:44,945 : INFO : EPOCH 16 - PROGRESS: at 42.52% examples, 1789961 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:45,950 : INFO : EPOCH 16 - PROGRESS: at 56.48% examples, 1789011 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:46,951 : INFO : EPOCH 16 - PROGRESS: at 70.59% examples, 1789193 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:47,953 : INFO : EPOCH 16 - PROGRESS: at 84.28% examples, 1786236 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:48,958 : INFO : EPOCH 16 - PROGRESS: at 98.40% examples, 1786174 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:49,073 : INFO : EPOCH 16: training on 14167241 raw words (12757814 effective words) took 7.1s, 1786666 effective words/s\n",
      "2024-06-06 20:19:50,075 : INFO : EPOCH 17 - PROGRESS: at 14.23% examples, 1793548 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:51,077 : INFO : EPOCH 17 - PROGRESS: at 28.33% examples, 1797693 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:52,086 : INFO : EPOCH 17 - PROGRESS: at 42.60% examples, 1793991 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:53,088 : INFO : EPOCH 17 - PROGRESS: at 56.55% examples, 1792766 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:54,093 : INFO : EPOCH 17 - PROGRESS: at 70.59% examples, 1788884 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:55,094 : INFO : EPOCH 17 - PROGRESS: at 84.34% examples, 1788025 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:56,102 : INFO : EPOCH 17 - PROGRESS: at 98.40% examples, 1785465 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:19:56,219 : INFO : EPOCH 17: training on 14167241 raw words (12757906 effective words) took 7.1s, 1785715 effective words/s\n",
      "2024-06-06 20:19:57,227 : INFO : EPOCH 18 - PROGRESS: at 14.16% examples, 1773850 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:58,228 : INFO : EPOCH 18 - PROGRESS: at 28.26% examples, 1789129 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:19:59,233 : INFO : EPOCH 18 - PROGRESS: at 42.60% examples, 1792794 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:00,234 : INFO : EPOCH 18 - PROGRESS: at 56.55% examples, 1792576 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:01,237 : INFO : EPOCH 18 - PROGRESS: at 70.72% examples, 1792826 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:02,238 : INFO : EPOCH 18 - PROGRESS: at 84.70% examples, 1795280 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:03,240 : INFO : EPOCH 18 - PROGRESS: at 98.74% examples, 1793566 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:03,329 : INFO : EPOCH 18: training on 14167241 raw words (12757822 effective words) took 7.1s, 1794416 effective words/s\n",
      "2024-06-06 20:20:04,332 : INFO : EPOCH 19 - PROGRESS: at 14.16% examples, 1783645 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:05,333 : INFO : EPOCH 19 - PROGRESS: at 28.19% examples, 1789166 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:06,335 : INFO : EPOCH 19 - PROGRESS: at 42.34% examples, 1786513 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:07,345 : INFO : EPOCH 19 - PROGRESS: at 56.41% examples, 1788144 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:08,346 : INFO : EPOCH 19 - PROGRESS: at 70.59% examples, 1789931 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:09,348 : INFO : EPOCH 19 - PROGRESS: at 84.48% examples, 1791283 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:10,351 : INFO : EPOCH 19 - PROGRESS: at 98.61% examples, 1790953 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:10,455 : INFO : EPOCH 19: training on 14167241 raw words (12757736 effective words) took 7.1s, 1790661 effective words/s\n",
      "2024-06-06 20:20:11,457 : INFO : EPOCH 20 - PROGRESS: at 14.16% examples, 1784220 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:12,463 : INFO : EPOCH 20 - PROGRESS: at 28.26% examples, 1790368 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:13,470 : INFO : EPOCH 20 - PROGRESS: at 42.59% examples, 1791968 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:14,471 : INFO : EPOCH 20 - PROGRESS: at 56.68% examples, 1796685 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:15,476 : INFO : EPOCH 20 - PROGRESS: at 70.86% examples, 1795549 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:16,479 : INFO : EPOCH 20 - PROGRESS: at 84.77% examples, 1795306 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:17,482 : INFO : EPOCH 20 - PROGRESS: at 99.00% examples, 1796869 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:17,553 : INFO : EPOCH 20: training on 14167241 raw words (12758698 effective words) took 7.1s, 1797762 effective words/s\n",
      "2024-06-06 20:20:18,559 : INFO : EPOCH 21 - PROGRESS: at 14.16% examples, 1777899 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:19,564 : INFO : EPOCH 21 - PROGRESS: at 28.26% examples, 1787460 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:20,573 : INFO : EPOCH 21 - PROGRESS: at 42.60% examples, 1789275 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:21,586 : INFO : EPOCH 21 - PROGRESS: at 56.69% examples, 1788581 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:22,587 : INFO : EPOCH 21 - PROGRESS: at 70.86% examples, 1790705 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:23,589 : INFO : EPOCH 21 - PROGRESS: at 84.91% examples, 1794457 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:24,590 : INFO : EPOCH 21 - PROGRESS: at 99.00% examples, 1794313 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:24,663 : INFO : EPOCH 21: training on 14167241 raw words (12757641 effective words) took 7.1s, 1794515 effective words/s\n",
      "2024-06-06 20:20:25,668 : INFO : EPOCH 22 - PROGRESS: at 14.23% examples, 1789187 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:26,671 : INFO : EPOCH 22 - PROGRESS: at 28.46% examples, 1802624 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:27,677 : INFO : EPOCH 22 - PROGRESS: at 42.87% examples, 1804329 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:28,683 : INFO : EPOCH 22 - PROGRESS: at 56.95% examples, 1803203 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:29,684 : INFO : EPOCH 22 - PROGRESS: at 71.07% examples, 1800690 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:30,684 : INFO : EPOCH 22 - PROGRESS: at 84.98% examples, 1800581 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:31,686 : INFO : EPOCH 22 - PROGRESS: at 99.00% examples, 1798180 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:31,757 : INFO : EPOCH 22: training on 14167241 raw words (12758448 effective words) took 7.1s, 1798915 effective words/s\n",
      "2024-06-06 20:20:32,763 : INFO : EPOCH 23 - PROGRESS: at 14.37% examples, 1803649 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:33,767 : INFO : EPOCH 23 - PROGRESS: at 28.19% examples, 1783618 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:34,769 : INFO : EPOCH 23 - PROGRESS: at 42.48% examples, 1788441 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:35,771 : INFO : EPOCH 23 - PROGRESS: at 56.41% examples, 1788810 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:36,771 : INFO : EPOCH 23 - PROGRESS: at 70.54% examples, 1789053 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:37,779 : INFO : EPOCH 23 - PROGRESS: at 84.48% examples, 1790196 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:38,779 : INFO : EPOCH 23 - PROGRESS: at 98.68% examples, 1792159 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:38,874 : INFO : EPOCH 23: training on 14167241 raw words (12757106 effective words) took 7.1s, 1792646 effective words/s\n",
      "2024-06-06 20:20:39,878 : INFO : EPOCH 24 - PROGRESS: at 14.23% examples, 1790676 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:40,880 : INFO : EPOCH 24 - PROGRESS: at 28.32% examples, 1796629 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:41,881 : INFO : EPOCH 24 - PROGRESS: at 42.59% examples, 1797316 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:42,882 : INFO : EPOCH 24 - PROGRESS: at 56.68% examples, 1800506 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:43,891 : INFO : EPOCH 24 - PROGRESS: at 71.07% examples, 1801927 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:44,892 : INFO : EPOCH 24 - PROGRESS: at 85.10% examples, 1804405 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:45,892 : INFO : EPOCH 24 - PROGRESS: at 99.27% examples, 1804254 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:45,941 : INFO : EPOCH 24: training on 14167241 raw words (12758268 effective words) took 7.1s, 1805629 effective words/s\n",
      "2024-06-06 20:20:46,942 : INFO : EPOCH 25 - PROGRESS: at 14.16% examples, 1786222 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:47,945 : INFO : EPOCH 25 - PROGRESS: at 28.25% examples, 1793374 words/s, in_qsize 8, out_qsize 1\n",
      "2024-06-06 20:20:48,951 : INFO : EPOCH 25 - PROGRESS: at 42.60% examples, 1795582 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:49,951 : INFO : EPOCH 25 - PROGRESS: at 56.80% examples, 1803343 words/s, in_qsize 6, out_qsize 0\n",
      "2024-06-06 20:20:50,954 : INFO : EPOCH 25 - PROGRESS: at 70.93% examples, 1799995 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:51,954 : INFO : EPOCH 25 - PROGRESS: at 84.91% examples, 1801537 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:52,956 : INFO : EPOCH 25 - PROGRESS: at 99.00% examples, 1799855 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:53,029 : INFO : EPOCH 25: training on 14167241 raw words (12757142 effective words) took 7.1s, 1800040 effective words/s\n",
      "2024-06-06 20:20:54,033 : INFO : EPOCH 26 - PROGRESS: at 14.37% examples, 1808075 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:20:55,035 : INFO : EPOCH 26 - PROGRESS: at 28.46% examples, 1804264 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:56,036 : INFO : EPOCH 26 - PROGRESS: at 42.60% examples, 1797424 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:57,036 : INFO : EPOCH 26 - PROGRESS: at 56.80% examples, 1805015 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:58,042 : INFO : EPOCH 26 - PROGRESS: at 71.15% examples, 1804913 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:20:59,045 : INFO : EPOCH 26 - PROGRESS: at 85.11% examples, 1804839 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:00,045 : INFO : EPOCH 26 - PROGRESS: at 99.41% examples, 1807057 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:00,088 : INFO : EPOCH 26: training on 14167241 raw words (12757022 effective words) took 7.1s, 1807548 effective words/s\n",
      "2024-06-06 20:21:01,091 : INFO : EPOCH 27 - PROGRESS: at 14.30% examples, 1801406 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:02,097 : INFO : EPOCH 27 - PROGRESS: at 28.46% examples, 1801123 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:03,100 : INFO : EPOCH 27 - PROGRESS: at 42.87% examples, 1805391 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:04,101 : INFO : EPOCH 27 - PROGRESS: at 56.95% examples, 1806180 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:05,107 : INFO : EPOCH 27 - PROGRESS: at 71.42% examples, 1809371 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:06,108 : INFO : EPOCH 27 - PROGRESS: at 85.27% examples, 1807525 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:07,109 : INFO : EPOCH 27 - PROGRESS: at 99.48% examples, 1806852 words/s, in_qsize 7, out_qsize 1\n",
      "2024-06-06 20:21:07,148 : INFO : EPOCH 27: training on 14167241 raw words (12757303 effective words) took 7.1s, 1807201 effective words/s\n",
      "2024-06-06 20:21:08,150 : INFO : EPOCH 28 - PROGRESS: at 14.30% examples, 1802955 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:09,163 : INFO : EPOCH 28 - PROGRESS: at 28.46% examples, 1796387 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:10,168 : INFO : EPOCH 28 - PROGRESS: at 42.88% examples, 1800861 words/s, in_qsize 8, out_qsize 1\n",
      "2024-06-06 20:21:11,171 : INFO : EPOCH 28 - PROGRESS: at 56.95% examples, 1802165 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:12,179 : INFO : EPOCH 28 - PROGRESS: at 71.42% examples, 1805323 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:13,180 : INFO : EPOCH 28 - PROGRESS: at 85.33% examples, 1805584 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:14,185 : INFO : EPOCH 28 - PROGRESS: at 99.71% examples, 1807841 words/s, in_qsize 5, out_qsize 0\n",
      "2024-06-06 20:21:14,204 : INFO : EPOCH 28: training on 14167241 raw words (12757488 effective words) took 7.1s, 1808377 effective words/s\n",
      "2024-06-06 20:21:15,206 : INFO : EPOCH 29 - PROGRESS: at 14.30% examples, 1802607 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:16,214 : INFO : EPOCH 29 - PROGRESS: at 28.46% examples, 1800835 words/s, in_qsize 8, out_qsize 0\n",
      "2024-06-06 20:21:17,218 : INFO : EPOCH 29 - PROGRESS: at 42.87% examples, 1803760 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:18,224 : INFO : EPOCH 29 - PROGRESS: at 56.95% examples, 1802821 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:19,227 : INFO : EPOCH 29 - PROGRESS: at 71.35% examples, 1806060 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:20,234 : INFO : EPOCH 29 - PROGRESS: at 85.33% examples, 1805860 words/s, in_qsize 7, out_qsize 0\n",
      "2024-06-06 20:21:21,236 : INFO : EPOCH 29 - PROGRESS: at 99.65% examples, 1807907 words/s, in_qsize 6, out_qsize 0\n",
      "2024-06-06 20:21:21,261 : INFO : EPOCH 29: training on 14167241 raw words (12756973 effective words) took 7.1s, 1807958 effective words/s\n",
      "2024-06-06 20:21:21,261 : INFO : Doc2Vec lifecycle event {'msg': 'training on 425017230 raw words (382727144 effective words) took 218.3s, 1753462 effective words/s', 'datetime': '2024-06-06T20:21:21.261860', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'doc2vec__epochs': 30, 'doc2vec__min_count': 2, 'doc2vec__vector_size': 300, 'doc2vec__window': 5}\n",
      "Test F1 Score: 0.7075053058074474\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     CARD_ARRHYTHMIA       0.58      0.62      0.60       230\n",
      "       CELL_SKIN_INF       0.80      0.93      0.86       415\n",
      "         CELL_NO_MCC       0.73      0.91      0.81       361\n",
      "         CVA_INFARCT       0.77      0.91      0.83       222\n",
      "        PANCREAS_DIS       0.75      0.82      0.78       249\n",
      "   DIGEST_DIS_NO_MCC       0.60      0.69      0.64       436\n",
      "       HEART_FAILURE       0.72      0.76      0.74       457\n",
      "     HEART_SHOCK_MCC       0.55      0.50      0.53       313\n",
      "          KIDNEY_UTI       0.60      0.63      0.61       251\n",
      "JOINT_REPLACE_NO_MCC       0.88      0.92      0.90       237\n",
      "    DIGEST_DIS_OTHER       0.47      0.62      0.54       250\n",
      "       GASTRO_NAUSEA       0.57      0.64      0.60       286\n",
      "     PNEUMONIA_OTHER       0.55      0.65      0.59       250\n",
      "          PCI_NO_AMI       0.65      0.83      0.73       179\n",
      "           PSYCHOSES       0.85      0.97      0.90       267\n",
      "          SEPTICEMIA       0.61      0.60      0.61       264\n",
      "             SYNCOPE       0.67      0.69      0.68       228\n",
      "\n",
      "           micro avg       0.67      0.75      0.71      4895\n",
      "           macro avg       0.67      0.75      0.70      4895\n",
      "        weighted avg       0.67      0.75      0.71      4895\n",
      "         samples avg       0.65      0.75      0.68      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=2, epochs=10):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=4,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model.build_vocab(documents)\n",
    "        self.model.train(documents, total_examples=self.model.corpus_count, epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc) for doc in X])\n",
    "\n",
    "# Initialize the transformer and classifier\n",
    "doc2vec = Doc2VecTransformer()\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('doc2vec', doc2vec),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'doc2vec__vector_size': [300],\n",
    "    'doc2vec__window': [5],\n",
    "    'doc2vec__min_count': [2],\n",
    "    'doc2vec__epochs': [40, 50]\n",
    "}\n",
    "\n",
    "# Define the scorer\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=9)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Test F1 Score: {accuracy}\")\n",
    "\n",
    "# Generate the classification report for each class\n",
    "report = classification_report(y_test, y_pred, target_names=class_columns, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=2, epochs=10):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=4,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model.build_vocab(documents)\n",
    "        self.model.train(documents, total_examples=self.model.corpus_count, epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc) for doc in X])\n",
    "\n",
    "# Initialize the transformer and classifier\n",
    "doc2vec = Doc2VecTransformer()\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('doc2vec', doc2vec),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'doc2vec__vector_size': [300],\n",
    "    'doc2vec__window': [5],\n",
    "    'doc2vec__min_count': [2],\n",
    "    'doc2vec__epochs': [40, 60, 80]\n",
    "}\n",
    "\n",
    "# Define the scorer\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=6)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Test F1 Score: {accuracy}\")\n",
    "\n",
    "# Generate the classification report for each class\n",
    "report = classification_report(y_test, y_pred, target_names=class_columns, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/training_text2.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = remove_stopwords(text)  # Remove stopwords\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['tokens'] = df['training_text'].apply(preprocess_text)\n",
    "\n",
    "# List of class columns\n",
    "class_columns = [\n",
    "    'CARD_ARRHYTHMIA', 'CELL_SKIN_INF', 'CELL_NO_MCC', \n",
    "    'CVA_INFARCT', 'PANCREAS_DIS', 'DIGEST_DIS_NO_MCC', \n",
    "    'HEART_FAILURE', 'HEART_SHOCK_MCC', 'KIDNEY_UTI', \n",
    "    'JOINT_REPLACE_NO_MCC', 'DIGEST_DIS_OTHER', 'GASTRO_NAUSEA', \n",
    "    'PNEUMONIA_OTHER', 'PCI_NO_AMI', 'PSYCHOSES', \n",
    "    'SEPTICEMIA', 'SYNCOPE'\n",
    "]\n",
    "\n",
    "# Remove rows where all class columns are 0 (no diagnosis)\n",
    "df = df[df[class_columns].sum(axis=1) > 0]\n",
    "\n",
    "# Prepare the data\n",
    "X = df['tokens']\n",
    "y = df[class_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=2, epochs=10):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=4,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model.build_vocab(documents)\n",
    "        self.model.train(documents, total_examples=self.model.corpus_count, epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc) for doc in X])\n",
    "\n",
    "# Initialize the transformer and classifier\n",
    "doc2vec = Doc2VecTransformer()\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('doc2vec', doc2vec),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'doc2vec__vector_size': [100, 200, 300],\n",
    "    'doc2vec__window': [5, 10, 15],\n",
    "    'doc2vec__min_count': [2],\n",
    "    'doc2vec__epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# Define the scorer\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Test F1 Score: {accuracy}\")\n",
    "\n",
    "# Generate the classification report for each class\n",
    "report = classification_report(y_test, y_pred, target_names=class_columns, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Create TaggedDocument\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:06:46,781 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:06:46.781923', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:06:46,806 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:06:46,806 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Documents\n",
      "Initialized model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:06:47,718 : INFO : PROGRESS: at example #10000, processed 8060579 words (8842094 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:06:47,741 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:06:47,742 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:06:47,811 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:06:47.811669', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:06:47,812 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:06:47.812268', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:06:47,894 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:06:47,895 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:06:47,896 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:06:47.896034', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:06:48,032 : INFO : estimated required memory for 40031 words and 300 dimensions: 130399300 bytes\n",
      "2024-06-06 11:06:48,033 : INFO : resetting layer weights\n",
      "2024-06-06 11:06:48,094 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:06:48.094188', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:06:49,103 : INFO : EPOCH 0 - PROGRESS: at 23.39% examples, 1736533 words/s, in_qsize 17, out_qsize 2\n",
      "2024-06-06 11:06:50,107 : INFO : EPOCH 0 - PROGRESS: at 51.05% examples, 1890524 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:06:51,108 : INFO : EPOCH 0 - PROGRESS: at 77.74% examples, 1920381 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:06:51,897 : INFO : EPOCH 0: training on 8234555 raw words (7444238 effective words) took 3.8s, 1959434 effective words/s\n",
      "2024-06-06 11:06:52,902 : INFO : EPOCH 1 - PROGRESS: at 27.49% examples, 2031130 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:06:53,910 : INFO : EPOCH 1 - PROGRESS: at 53.09% examples, 1961208 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:06:54,914 : INFO : EPOCH 1 - PROGRESS: at 76.01% examples, 1876280 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:06:55,921 : INFO : EPOCH 1 - PROGRESS: at 97.69% examples, 1809004 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:06:55,998 : INFO : EPOCH 1: training on 8234555 raw words (7443541 effective words) took 4.1s, 1815760 effective words/s\n",
      "2024-06-06 11:06:57,002 : INFO : EPOCH 2 - PROGRESS: at 23.90% examples, 1774181 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:06:58,013 : INFO : EPOCH 2 - PROGRESS: at 49.92% examples, 1843215 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:06:59,014 : INFO : EPOCH 2 - PROGRESS: at 73.04% examples, 1806238 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:00,024 : INFO : EPOCH 2 - PROGRESS: at 94.67% examples, 1751963 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:00,239 : INFO : EPOCH 2: training on 8234555 raw words (7443558 effective words) took 4.2s, 1755544 effective words/s\n",
      "2024-06-06 11:07:01,246 : INFO : EPOCH 3 - PROGRESS: at 22.93% examples, 1699119 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:02,251 : INFO : EPOCH 3 - PROGRESS: at 48.41% examples, 1792027 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:03,254 : INFO : EPOCH 3 - PROGRESS: at 76.86% examples, 1897625 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:04,106 : INFO : EPOCH 3: training on 8234555 raw words (7443505 effective words) took 3.9s, 1925780 effective words/s\n",
      "2024-06-06 11:07:05,109 : INFO : EPOCH 4 - PROGRESS: at 22.40% examples, 1663775 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:07:06,110 : INFO : EPOCH 4 - PROGRESS: at 43.15% examples, 1605155 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:07,112 : INFO : EPOCH 4 - PROGRESS: at 66.11% examples, 1633939 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:08,122 : INFO : EPOCH 4 - PROGRESS: at 90.29% examples, 1674932 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:08,587 : INFO : EPOCH 4: training on 8234555 raw words (7443922 effective words) took 4.5s, 1661694 effective words/s\n",
      "2024-06-06 11:07:09,592 : INFO : EPOCH 5 - PROGRESS: at 19.29% examples, 1438861 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:10,595 : INFO : EPOCH 5 - PROGRESS: at 42.87% examples, 1590740 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:07:11,596 : INFO : EPOCH 5 - PROGRESS: at 64.22% examples, 1587238 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:12,596 : INFO : EPOCH 5 - PROGRESS: at 86.40% examples, 1607847 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:13,161 : INFO : EPOCH 5: training on 8234555 raw words (7443166 effective words) took 4.6s, 1627779 effective words/s\n",
      "2024-06-06 11:07:14,167 : INFO : EPOCH 6 - PROGRESS: at 22.50% examples, 1668252 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:15,170 : INFO : EPOCH 6 - PROGRESS: at 47.74% examples, 1768901 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:16,170 : INFO : EPOCH 6 - PROGRESS: at 71.48% examples, 1771037 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:17,178 : INFO : EPOCH 6 - PROGRESS: at 95.58% examples, 1773355 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:17,348 : INFO : EPOCH 6: training on 8234555 raw words (7443603 effective words) took 4.2s, 1778446 effective words/s\n",
      "2024-06-06 11:07:18,354 : INFO : EPOCH 7 - PROGRESS: at 23.69% examples, 1755762 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:19,354 : INFO : EPOCH 7 - PROGRESS: at 46.85% examples, 1740865 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:20,359 : INFO : EPOCH 7 - PROGRESS: at 71.29% examples, 1764450 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:21,361 : INFO : EPOCH 7 - PROGRESS: at 95.66% examples, 1777666 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:21,506 : INFO : EPOCH 7: training on 8234555 raw words (7444122 effective words) took 4.2s, 1791387 effective words/s\n",
      "2024-06-06 11:07:22,510 : INFO : EPOCH 8 - PROGRESS: at 23.30% examples, 1731232 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:23,512 : INFO : EPOCH 8 - PROGRESS: at 47.27% examples, 1753553 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:24,515 : INFO : EPOCH 8 - PROGRESS: at 71.20% examples, 1762070 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:25,516 : INFO : EPOCH 8 - PROGRESS: at 93.86% examples, 1744081 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:25,744 : INFO : EPOCH 8: training on 8234555 raw words (7443988 effective words) took 4.2s, 1756860 effective words/s\n",
      "2024-06-06 11:07:26,749 : INFO : EPOCH 9 - PROGRESS: at 22.59% examples, 1679352 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:27,760 : INFO : EPOCH 9 - PROGRESS: at 46.54% examples, 1720505 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:28,762 : INFO : EPOCH 9 - PROGRESS: at 68.60% examples, 1690645 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:07:29,764 : INFO : EPOCH 9 - PROGRESS: at 92.17% examples, 1707937 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:07:30,046 : INFO : EPOCH 9: training on 8234555 raw words (7443495 effective words) took 4.3s, 1731011 effective words/s\n",
      "2024-06-06 11:07:30,047 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74437138 effective words) took 42.0s, 1774304 effective words/s', 'datetime': '2024-06-06T11:07:30.047309', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 41.95 seconds.\n",
      "Inferred X_train_vectors\n",
      "Inferred X_test_vectors\n",
      "Vectors inferred for training and testing data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "print('Tagged Documents')\n",
    "\n",
    "# Train Doc2Vec model\n",
    "model = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10,\n",
    "    epochs=10,\n",
    "    alpha=0.025,\n",
    "    min_alpha=0.0001,\n",
    "    dm=1,  # PV-DM\n",
    "    dbow_words=1  # If using PV-DBOW (dm=0)\n",
    ")\n",
    "print('Initialized model')\n",
    "\n",
    "# Build vocabulary\n",
    "model.build_vocab(train_documents)\n",
    "\n",
    "print('Built vocabulary')\n",
    "\n",
    "# Train the model with progress tracking\n",
    "start_time = time.time()\n",
    "model.train(\n",
    "    train_documents,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=model.epochs,\n",
    "    start_alpha=model.alpha,\n",
    "    end_alpha=model.min_alpha\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Infer vectors for the training documents\n",
    "X_train_vectors = [model.infer_vector(doc) for doc in X_train]\n",
    "print('Inferred X_train_vectors')\n",
    "\n",
    "# Infer vectors for the testing documents\n",
    "X_test_vectors = [model.infer_vector(doc) for doc in X_test]\n",
    "print('Inferred X_test_vectors')\n",
    "\n",
    "print('Vectors inferred for training and testing data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Kmeans\n",
      "Predicted clusters\n",
      "Classification Report (Training Data):\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      " Minimal Care/Recovery at Home       0.74      1.00      0.85      7592\n",
      "Moderate Care/Support Required       0.00      0.00      0.00      2188\n",
      "                Severe Outcome       0.00      0.00      0.00       441\n",
      "\n",
      "                      accuracy                           0.74     10221\n",
      "                     macro avg       0.25      0.33      0.28     10221\n",
      "                  weighted avg       0.55      0.74      0.63     10221\n",
      "\n",
      "\n",
      "Classification Report (Testing Data):\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      " Minimal Care/Recovery at Home       0.75      1.00      0.86      1916\n",
      "Moderate Care/Support Required       0.00      0.00      0.00       535\n",
      "                Severe Outcome       0.00      0.00      0.00       105\n",
      "\n",
      "                      accuracy                           0.75      2556\n",
      "                     macro avg       0.25      0.33      0.29      2556\n",
      "                  weighted avg       0.56      0.75      0.64      2556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define number of clusters\n",
    "num_clusters = 3  # This should be tuned based on your data\n",
    "\n",
    "# Train K-Means model on training data vectors\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X_train_vectors)\n",
    "\n",
    "print('Fit Kmeans')\n",
    "\n",
    "# Predict clusters for training and testing data\n",
    "train_clusters = kmeans.predict(X_train_vectors)\n",
    "test_clusters = kmeans.predict(X_test_vectors)\n",
    "\n",
    "print('Predicted clusters')\n",
    "\n",
    "# Create a mapping from clusters to severity levels using training data\n",
    "cluster_mapping = {}\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = y_train[train_clusters == cluster]\n",
    "    common_severity_level = cluster_data.mode().values[0]\n",
    "    cluster_mapping[cluster] = common_severity_level\n",
    "\n",
    "# Map clusters to severity levels for training data\n",
    "y_train_pred = [cluster_mapping[cluster] for cluster in train_clusters]\n",
    "\n",
    "# Map clusters to severity levels for testing data\n",
    "y_test_pred = [cluster_mapping[cluster] for cluster in test_clusters]\n",
    "\n",
    "# Evaluate the classification on training data\n",
    "print(\"Classification Report (Training Data):\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Evaluate the classification on testing data\n",
    "print(\"\\nClassification Report (Testing Data):\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:13:53,362 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:13:53.362122', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:13:53,362 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:13:53,363 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 2, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:13:54,188 : INFO : PROGRESS: at example #10000, processed 8060579 words (9766024 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:13:54,207 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:13:54,207 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:13:54,270 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:13:54.270819', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:13:54,271 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:13:54.271209', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:13:54,352 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:13:54,353 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:13:54,353 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:13:54.353745', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:13:54,484 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 11:13:54,484 : INFO : resetting layer weights\n",
      "2024-06-06 11:13:54,513 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:13:54.513614', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:13:55,521 : INFO : EPOCH 0 - PROGRESS: at 31.20% examples, 2314831 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:13:56,525 : INFO : EPOCH 0 - PROGRESS: at 62.78% examples, 2320200 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:13:57,529 : INFO : EPOCH 0 - PROGRESS: at 91.00% examples, 2248442 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:13:57,829 : INFO : EPOCH 0: training on 8234555 raw words (7444139 effective words) took 3.3s, 2246049 effective words/s\n",
      "2024-06-06 11:13:58,832 : INFO : EPOCH 1 - PROGRESS: at 30.98% examples, 2307516 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:13:59,844 : INFO : EPOCH 1 - PROGRESS: at 62.68% examples, 2311543 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:00,861 : INFO : EPOCH 1 - PROGRESS: at 92.80% examples, 2281418 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:01,170 : INFO : EPOCH 1: training on 8234555 raw words (7443125 effective words) took 3.3s, 2228892 effective words/s\n",
      "2024-06-06 11:14:02,175 : INFO : EPOCH 2 - PROGRESS: at 23.78% examples, 1764950 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:03,188 : INFO : EPOCH 2 - PROGRESS: at 49.92% examples, 1841186 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:04,190 : INFO : EPOCH 2 - PROGRESS: at 75.16% examples, 1855141 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:05,070 : INFO : EPOCH 2: training on 8234555 raw words (7443707 effective words) took 3.9s, 1909488 effective words/s\n",
      "2024-06-06 11:14:06,079 : INFO : EPOCH 3 - PROGRESS: at 24.27% examples, 1794147 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:07,087 : INFO : EPOCH 3 - PROGRESS: at 51.94% examples, 1919954 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:08,091 : INFO : EPOCH 3 - PROGRESS: at 76.86% examples, 1894546 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:08,913 : INFO : EPOCH 3: training on 8234555 raw words (7444045 effective words) took 3.8s, 1938138 effective words/s\n",
      "2024-06-06 11:14:09,917 : INFO : EPOCH 4 - PROGRESS: at 30.38% examples, 2264078 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:10,918 : INFO : EPOCH 4 - PROGRESS: at 59.49% examples, 2205774 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:11,918 : INFO : EPOCH 4 - PROGRESS: at 84.99% examples, 2108052 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:12,420 : INFO : EPOCH 4: training on 8234555 raw words (7444411 effective words) took 3.5s, 2123782 effective words/s\n",
      "2024-06-06 11:14:13,421 : INFO : EPOCH 5 - PROGRESS: at 28.57% examples, 2131107 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:14,423 : INFO : EPOCH 5 - PROGRESS: at 57.18% examples, 2117246 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:15,427 : INFO : EPOCH 5 - PROGRESS: at 86.17% examples, 2138033 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:15,885 : INFO : EPOCH 5: training on 8234555 raw words (7442763 effective words) took 3.5s, 2148663 effective words/s\n",
      "2024-06-06 11:14:16,892 : INFO : EPOCH 6 - PROGRESS: at 31.08% examples, 2309012 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:17,895 : INFO : EPOCH 6 - PROGRESS: at 63.18% examples, 2335270 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:18,897 : INFO : EPOCH 6 - PROGRESS: at 94.79% examples, 2345395 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:19,043 : INFO : EPOCH 6: training on 8234555 raw words (7444737 effective words) took 3.2s, 2358755 effective words/s\n",
      "2024-06-06 11:14:20,046 : INFO : EPOCH 7 - PROGRESS: at 33.29% examples, 2478459 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:21,049 : INFO : EPOCH 7 - PROGRESS: at 67.40% examples, 2496216 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:22,033 : INFO : EPOCH 7: training on 8234555 raw words (7443887 effective words) took 3.0s, 2490663 effective words/s\n",
      "2024-06-06 11:14:23,043 : INFO : EPOCH 8 - PROGRESS: at 27.45% examples, 2021277 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:24,046 : INFO : EPOCH 8 - PROGRESS: at 54.93% examples, 2026563 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:25,048 : INFO : EPOCH 8 - PROGRESS: at 80.66% examples, 1992764 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:14:25,819 : INFO : EPOCH 8: training on 8234555 raw words (7443594 effective words) took 3.8s, 1966783 effective words/s\n",
      "2024-06-06 11:14:26,825 : INFO : EPOCH 9 - PROGRESS: at 27.92% examples, 2064670 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:14:27,833 : INFO : EPOCH 9 - PROGRESS: at 54.31% examples, 2004354 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:28,834 : INFO : EPOCH 9 - PROGRESS: at 81.29% examples, 2010001 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:14:29,480 : INFO : EPOCH 9: training on 8234555 raw words (7443039 effective words) took 3.7s, 2034086 effective words/s\n",
      "2024-06-06 11:14:29,481 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74437447 effective words) took 35.0s, 2128781 effective words/s', 'datetime': '2024-06-06T11:14:29.481311', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:16:41,421 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:16:41.421809', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:16:41,422 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:16:41,422 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 1 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:16:42,133 : INFO : PROGRESS: at example #10000, processed 8060579 words (11332746 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:16:42,151 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:16:42,152 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:16:42,217 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:16:42.217058', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:16:42,217 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:16:42.217645', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:16:42,289 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:16:42,290 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:16:42,291 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:16:42.291149', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:16:42,411 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 11:16:42,411 : INFO : resetting layer weights\n",
      "2024-06-06 11:16:42,440 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T11:16:42.440501', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:16:43,443 : INFO : EPOCH 0 - PROGRESS: at 48.61% examples, 3613153 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:44,444 : INFO : EPOCH 0 - PROGRESS: at 97.41% examples, 3621325 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:16:44,490 : INFO : EPOCH 0: training on 8234555 raw words (7443086 effective words) took 2.0s, 3634139 effective words/s\n",
      "2024-06-06 11:16:45,492 : INFO : EPOCH 1 - PROGRESS: at 48.19% examples, 3580709 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:16:46,493 : INFO : EPOCH 1 - PROGRESS: at 95.47% examples, 3552405 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:16:46,578 : INFO : EPOCH 1: training on 8234555 raw words (7443334 effective words) took 2.1s, 3566360 effective words/s\n",
      "2024-06-06 11:16:47,581 : INFO : EPOCH 2 - PROGRESS: at 43.19% examples, 3210078 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:48,582 : INFO : EPOCH 2 - PROGRESS: at 82.01% examples, 3050418 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:49,000 : INFO : EPOCH 2: training on 8234555 raw words (7443083 effective words) took 2.4s, 3074660 effective words/s\n",
      "2024-06-06 11:16:50,006 : INFO : EPOCH 3 - PROGRESS: at 38.63% examples, 2854024 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:16:51,007 : INFO : EPOCH 3 - PROGRESS: at 77.33% examples, 2868582 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:51,520 : INFO : EPOCH 3: training on 8234555 raw words (7443216 effective words) took 2.5s, 2956255 effective words/s\n",
      "2024-06-06 11:16:52,525 : INFO : EPOCH 4 - PROGRESS: at 40.09% examples, 2968882 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:53,527 : INFO : EPOCH 4 - PROGRESS: at 82.12% examples, 3050421 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:16:53,934 : INFO : EPOCH 4: training on 8234555 raw words (7443500 effective words) took 2.4s, 3085469 effective words/s\n",
      "2024-06-06 11:16:54,941 : INFO : EPOCH 5 - PROGRESS: at 46.51% examples, 3446829 words/s, in_qsize 16, out_qsize 3\n",
      "2024-06-06 11:16:55,946 : INFO : EPOCH 5 - PROGRESS: at 91.13% examples, 3375614 words/s, in_qsize 19, out_qsize 2\n",
      "2024-06-06 11:16:56,173 : INFO : EPOCH 5: training on 8234555 raw words (7444097 effective words) took 2.2s, 3326725 effective words/s\n",
      "2024-06-06 11:16:57,180 : INFO : EPOCH 6 - PROGRESS: at 43.61% examples, 3234109 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:16:58,183 : INFO : EPOCH 6 - PROGRESS: at 86.06% examples, 3196978 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:16:58,466 : INFO : EPOCH 6: training on 8234555 raw words (7443510 effective words) took 2.3s, 3249661 effective words/s\n",
      "2024-06-06 11:16:59,470 : INFO : EPOCH 7 - PROGRESS: at 41.68% examples, 3095762 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:17:00,473 : INFO : EPOCH 7 - PROGRESS: at 85.21% examples, 3165337 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:17:00,797 : INFO : EPOCH 7: training on 8234555 raw words (7442979 effective words) took 2.3s, 3194678 effective words/s\n",
      "2024-06-06 11:17:01,802 : INFO : EPOCH 8 - PROGRESS: at 45.38% examples, 3367320 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:17:02,811 : INFO : EPOCH 8 - PROGRESS: at 93.29% examples, 3452403 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:17:02,935 : INFO : EPOCH 8: training on 8234555 raw words (7443885 effective words) took 2.1s, 3485411 effective words/s\n",
      "2024-06-06 11:17:03,937 : INFO : EPOCH 9 - PROGRESS: at 44.23% examples, 3288938 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:17:04,940 : INFO : EPOCH 9 - PROGRESS: at 87.50% examples, 3252759 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:17:05,318 : INFO : EPOCH 9: training on 8234555 raw words (7444028 effective words) took 2.4s, 3125167 effective words/s\n",
      "2024-06-06 11:17:05,318 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74434718 effective words) took 22.9s, 3253560 effective words/s', 'datetime': '2024-06-06T11:17:05.318851', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:18:41,798 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d300,n5,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:18:41.798401', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:18:41,798 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:18:41,798 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 2 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 300, 'window': 5, 'min_count': 2, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:18:42,525 : INFO : PROGRESS: at example #10000, processed 8060579 words (11101833 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:18:42,543 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:18:42,544 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:18:42,601 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:18:42.601720', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:18:42,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:18:42.602057', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:18:42,692 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:18:42,693 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:18:42,694 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:18:42.694059', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:18:42,828 : INFO : estimated required memory for 40031 words and 300 dimensions: 130399300 bytes\n",
      "2024-06-06 11:18:42,828 : INFO : resetting layer weights\n",
      "2024-06-06 11:18:42,870 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T11:18:42.870737', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:18:43,873 : INFO : EPOCH 0 - PROGRESS: at 40.57% examples, 3016966 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:18:44,873 : INFO : EPOCH 0 - PROGRESS: at 82.01% examples, 3051606 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:45,293 : INFO : EPOCH 0: training on 8234555 raw words (7443994 effective words) took 2.4s, 3074017 effective words/s\n",
      "2024-06-06 11:18:46,302 : INFO : EPOCH 1 - PROGRESS: at 41.90% examples, 3102334 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:47,303 : INFO : EPOCH 1 - PROGRESS: at 82.68% examples, 3067200 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:18:47,786 : INFO : EPOCH 1: training on 8234555 raw words (7443323 effective words) took 2.5s, 2987852 effective words/s\n",
      "2024-06-06 11:18:48,790 : INFO : EPOCH 2 - PROGRESS: at 30.51% examples, 2273125 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:49,791 : INFO : EPOCH 2 - PROGRESS: at 59.36% examples, 2201760 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:50,791 : INFO : EPOCH 2 - PROGRESS: at 93.60% examples, 2321637 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:18:50,953 : INFO : EPOCH 2: training on 8234555 raw words (7443812 effective words) took 3.2s, 2351832 effective words/s\n",
      "2024-06-06 11:18:51,964 : INFO : EPOCH 3 - PROGRESS: at 33.18% examples, 2450299 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:52,965 : INFO : EPOCH 3 - PROGRESS: at 65.03% examples, 2403883 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:53,966 : INFO : EPOCH 3 - PROGRESS: at 97.51% examples, 2410631 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:18:54,036 : INFO : EPOCH 3: training on 8234555 raw words (7443032 effective words) took 3.1s, 2415745 effective words/s\n",
      "2024-06-06 11:18:55,049 : INFO : EPOCH 4 - PROGRESS: at 31.33% examples, 2310953 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:18:56,053 : INFO : EPOCH 4 - PROGRESS: at 59.71% examples, 2200654 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:18:57,055 : INFO : EPOCH 4 - PROGRESS: at 91.02% examples, 2245865 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:57,306 : INFO : EPOCH 4: training on 8234555 raw words (7443619 effective words) took 3.3s, 2277556 effective words/s\n",
      "2024-06-06 11:18:58,312 : INFO : EPOCH 5 - PROGRESS: at 31.08% examples, 2311001 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:18:59,322 : INFO : EPOCH 5 - PROGRESS: at 55.24% examples, 2036923 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:00,333 : INFO : EPOCH 5 - PROGRESS: at 86.06% examples, 2121557 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:19:00,719 : INFO : EPOCH 5: training on 8234555 raw words (7444232 effective words) took 3.4s, 2182341 effective words/s\n",
      "2024-06-06 11:19:01,723 : INFO : EPOCH 6 - PROGRESS: at 34.75% examples, 2586476 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:02,745 : INFO : EPOCH 6 - PROGRESS: at 54.45% examples, 1996367 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:03,752 : INFO : EPOCH 6 - PROGRESS: at 75.62% examples, 1858178 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:04,620 : INFO : EPOCH 6: training on 8234555 raw words (7443527 effective words) took 3.9s, 1908804 effective words/s\n",
      "2024-06-06 11:19:05,625 : INFO : EPOCH 7 - PROGRESS: at 26.89% examples, 1989156 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:19:06,630 : INFO : EPOCH 7 - PROGRESS: at 53.59% examples, 1982160 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:19:07,632 : INFO : EPOCH 7 - PROGRESS: at 81.90% examples, 2026392 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:19:08,552 : INFO : EPOCH 7: training on 8234555 raw words (7443240 effective words) took 3.9s, 1893994 effective words/s\n",
      "2024-06-06 11:19:09,584 : INFO : EPOCH 8 - PROGRESS: at 22.79% examples, 1667350 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:19:10,599 : INFO : EPOCH 8 - PROGRESS: at 48.94% examples, 1791980 words/s, in_qsize 17, out_qsize 3\n",
      "2024-06-06 11:19:11,601 : INFO : EPOCH 8 - PROGRESS: at 70.75% examples, 1735232 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:19:12,603 : INFO : EPOCH 8 - PROGRESS: at 94.67% examples, 1745964 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:19:12,761 : INFO : EPOCH 8: training on 8234555 raw words (7443363 effective words) took 4.2s, 1773885 effective words/s\n",
      "2024-06-06 11:19:13,766 : INFO : EPOCH 9 - PROGRESS: at 29.28% examples, 2181568 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:14,768 : INFO : EPOCH 9 - PROGRESS: at 58.64% examples, 2171666 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:19:15,771 : INFO : EPOCH 9 - PROGRESS: at 86.40% examples, 2143399 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:19:16,243 : INFO : EPOCH 9: training on 8234555 raw words (7444698 effective words) took 3.5s, 2140190 effective words/s\n",
      "2024-06-06 11:19:16,243 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74436840 effective words) took 33.4s, 2230486 effective words/s', 'datetime': '2024-06-06T11:19:16.243705', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:21:34,583 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w10,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:21:34.583513', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:21:34,583 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:21:34,584 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 3 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 10, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:21:35,307 : INFO : PROGRESS: at example #10000, processed 8060579 words (11145046 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:21:35,325 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:21:35,326 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:21:35,366 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:21:35.366783', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:21:35,367 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:21:35.367344', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:21:35,410 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:21:35,410 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:21:35,411 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:21:35.411248', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:21:35,482 : INFO : estimated required memory for 23203 words and 400 dimensions: 104248900 bytes\n",
      "2024-06-06 11:21:35,482 : INFO : resetting layer weights\n",
      "2024-06-06 11:21:35,519 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:21:35.519618', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:21:36,524 : INFO : EPOCH 0 - PROGRESS: at 24.27% examples, 1789405 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:37,531 : INFO : EPOCH 0 - PROGRESS: at 49.92% examples, 1834639 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:38,541 : INFO : EPOCH 0 - PROGRESS: at 75.62% examples, 1853827 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:39,478 : INFO : EPOCH 0: training on 8234555 raw words (7397062 effective words) took 4.0s, 1869064 effective words/s\n",
      "2024-06-06 11:21:40,480 : INFO : EPOCH 1 - PROGRESS: at 25.49% examples, 1880599 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:41,480 : INFO : EPOCH 1 - PROGRESS: at 51.82% examples, 1917217 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:42,496 : INFO : EPOCH 1 - PROGRESS: at 75.62% examples, 1855726 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:21:43,501 : INFO : EPOCH 1 - PROGRESS: at 93.17% examples, 1714396 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:21:43,799 : INFO : EPOCH 1: training on 8234555 raw words (7397199 effective words) took 4.3s, 1712525 effective words/s\n",
      "2024-06-06 11:21:44,803 : INFO : EPOCH 2 - PROGRESS: at 20.44% examples, 1517521 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:21:45,809 : INFO : EPOCH 2 - PROGRESS: at 42.95% examples, 1583374 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:46,816 : INFO : EPOCH 2 - PROGRESS: at 63.36% examples, 1550722 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:47,821 : INFO : EPOCH 2 - PROGRESS: at 84.51% examples, 1556662 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:48,488 : INFO : EPOCH 2: training on 8234555 raw words (7397243 effective words) took 4.7s, 1578237 effective words/s\n",
      "2024-06-06 11:21:49,492 : INFO : EPOCH 3 - PROGRESS: at 21.92% examples, 1617247 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:50,496 : INFO : EPOCH 3 - PROGRESS: at 46.50% examples, 1715543 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:21:51,500 : INFO : EPOCH 3 - PROGRESS: at 68.40% examples, 1677671 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:21:52,502 : INFO : EPOCH 3 - PROGRESS: at 91.04% examples, 1678837 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:52,875 : INFO : EPOCH 3: training on 8234555 raw words (7397616 effective words) took 4.4s, 1686865 effective words/s\n",
      "2024-06-06 11:21:53,877 : INFO : EPOCH 4 - PROGRESS: at 22.74% examples, 1680378 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:54,884 : INFO : EPOCH 4 - PROGRESS: at 46.40% examples, 1710614 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:55,889 : INFO : EPOCH 4 - PROGRESS: at 68.19% examples, 1670833 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:21:56,896 : INFO : EPOCH 4 - PROGRESS: at 91.00% examples, 1675241 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:21:57,313 : INFO : EPOCH 4: training on 8234555 raw words (7397225 effective words) took 4.4s, 1667494 effective words/s\n",
      "2024-06-06 11:21:58,315 : INFO : EPOCH 5 - PROGRESS: at 21.33% examples, 1576744 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:21:59,316 : INFO : EPOCH 5 - PROGRESS: at 44.74% examples, 1651544 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:00,320 : INFO : EPOCH 5 - PROGRESS: at 65.12% examples, 1600679 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:01,323 : INFO : EPOCH 5 - PROGRESS: at 86.75% examples, 1603287 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:01,882 : INFO : EPOCH 5: training on 8234555 raw words (7396744 effective words) took 4.6s, 1619521 effective words/s\n",
      "2024-06-06 11:22:02,886 : INFO : EPOCH 6 - PROGRESS: at 23.57% examples, 1738359 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:03,892 : INFO : EPOCH 6 - PROGRESS: at 47.36% examples, 1743990 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:04,895 : INFO : EPOCH 6 - PROGRESS: at 66.56% examples, 1631629 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:05,896 : INFO : EPOCH 6 - PROGRESS: at 89.32% examples, 1646356 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:06,343 : INFO : EPOCH 6: training on 8234555 raw words (7397381 effective words) took 4.5s, 1659091 effective words/s\n",
      "2024-06-06 11:22:07,350 : INFO : EPOCH 7 - PROGRESS: at 24.66% examples, 1809840 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:22:08,352 : INFO : EPOCH 7 - PROGRESS: at 50.91% examples, 1875608 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:09,355 : INFO : EPOCH 7 - PROGRESS: at 72.95% examples, 1793971 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:10,357 : INFO : EPOCH 7 - PROGRESS: at 93.15% examples, 1718013 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:10,657 : INFO : EPOCH 7: training on 8234555 raw words (7397513 effective words) took 4.3s, 1715275 effective words/s\n",
      "2024-06-06 11:22:11,660 : INFO : EPOCH 8 - PROGRESS: at 21.56% examples, 1595982 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:12,668 : INFO : EPOCH 8 - PROGRESS: at 44.59% examples, 1641254 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:13,671 : INFO : EPOCH 8 - PROGRESS: at 68.51% examples, 1679221 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:14,676 : INFO : EPOCH 8 - PROGRESS: at 91.00% examples, 1676514 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:22:15,000 : INFO : EPOCH 8: training on 8234555 raw words (7398259 effective words) took 4.3s, 1704463 effective words/s\n",
      "2024-06-06 11:22:16,002 : INFO : EPOCH 9 - PROGRESS: at 23.15% examples, 1715389 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:17,010 : INFO : EPOCH 9 - PROGRESS: at 46.40% examples, 1709091 words/s, in_qsize 18, out_qsize 3\n",
      "2024-06-06 11:22:18,016 : INFO : EPOCH 9 - PROGRESS: at 67.85% examples, 1660683 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:22:19,027 : INFO : EPOCH 9 - PROGRESS: at 91.38% examples, 1678966 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:22:19,421 : INFO : EPOCH 9: training on 8234555 raw words (7397226 effective words) took 4.4s, 1673615 effective words/s\n",
      "2024-06-06 11:22:19,421 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73973468 effective words) took 43.9s, 1684974 effective words/s', 'datetime': '2024-06-06T11:22:19.421978', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:25:23,964 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:25:23.963972', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:25:23,965 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:25:23,966 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 4 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:25:24,707 : INFO : PROGRESS: at example #10000, processed 8060579 words (10876411 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:25:24,726 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:25:24,726 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:25:24,766 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:25:24.766141', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:25:24,766 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:25:24.766619', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:25:24,808 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:25:24,809 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:25:24,809 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:25:24.809827', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:25:24,882 : INFO : estimated required memory for 23203 words and 200 dimensions: 58947300 bytes\n",
      "2024-06-06 11:25:24,882 : INFO : resetting layer weights\n",
      "2024-06-06 11:25:24,901 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:25:24.901743', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:25:25,904 : INFO : EPOCH 0 - PROGRESS: at 31.43% examples, 2330964 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:26,911 : INFO : EPOCH 0 - PROGRESS: at 64.23% examples, 2363093 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:27,924 : INFO : EPOCH 0 - PROGRESS: at 96.04% examples, 2354112 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:25:28,051 : INFO : EPOCH 0: training on 8234555 raw words (7397002 effective words) took 3.1s, 2350340 effective words/s\n",
      "2024-06-06 11:25:29,055 : INFO : EPOCH 1 - PROGRESS: at 33.67% examples, 2494199 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:30,057 : INFO : EPOCH 1 - PROGRESS: at 68.19% examples, 2511883 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:31,062 : INFO : EPOCH 1 - PROGRESS: at 98.14% examples, 2414687 words/s, in_qsize 16, out_qsize 0\n",
      "2024-06-06 11:25:31,117 : INFO : EPOCH 1: training on 8234555 raw words (7397072 effective words) took 3.1s, 2414693 effective words/s\n",
      "2024-06-06 11:25:32,120 : INFO : EPOCH 2 - PROGRESS: at 26.35% examples, 1938509 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:33,122 : INFO : EPOCH 2 - PROGRESS: at 52.48% examples, 1935829 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:34,124 : INFO : EPOCH 2 - PROGRESS: at 79.80% examples, 1962640 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:34,846 : INFO : EPOCH 2: training on 8234555 raw words (7397417 effective words) took 3.7s, 1984640 effective words/s\n",
      "2024-06-06 11:25:35,849 : INFO : EPOCH 3 - PROGRESS: at 28.29% examples, 2090966 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:36,851 : INFO : EPOCH 3 - PROGRESS: at 55.91% examples, 2056560 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:37,853 : INFO : EPOCH 3 - PROGRESS: at 84.96% examples, 2093770 words/s, in_qsize 19, out_qsize 2\n",
      "2024-06-06 11:25:38,373 : INFO : EPOCH 3: training on 8234555 raw words (7397661 effective words) took 3.5s, 2098682 effective words/s\n",
      "2024-06-06 11:25:39,374 : INFO : EPOCH 4 - PROGRESS: at 26.14% examples, 1924750 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:40,379 : INFO : EPOCH 4 - PROGRESS: at 52.21% examples, 1926231 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:41,387 : INFO : EPOCH 4 - PROGRESS: at 80.00% examples, 1963498 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:42,050 : INFO : EPOCH 4: training on 8234555 raw words (7397531 effective words) took 3.7s, 2012294 effective words/s\n",
      "2024-06-06 11:25:43,053 : INFO : EPOCH 5 - PROGRESS: at 25.87% examples, 1905394 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:44,055 : INFO : EPOCH 5 - PROGRESS: at 54.44% examples, 2005278 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:45,057 : INFO : EPOCH 5 - PROGRESS: at 83.37% examples, 2054565 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:45,616 : INFO : EPOCH 5: training on 8234555 raw words (7397695 effective words) took 3.6s, 2075526 effective words/s\n",
      "2024-06-06 11:25:46,619 : INFO : EPOCH 6 - PROGRESS: at 28.32% examples, 2092017 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:47,625 : INFO : EPOCH 6 - PROGRESS: at 56.24% examples, 2065332 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:48,629 : INFO : EPOCH 6 - PROGRESS: at 85.84% examples, 2112437 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:49,092 : INFO : EPOCH 6: training on 8234555 raw words (7397457 effective words) took 3.5s, 2129083 effective words/s\n",
      "2024-06-06 11:25:50,094 : INFO : EPOCH 7 - PROGRESS: at 28.03% examples, 2068063 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:51,094 : INFO : EPOCH 7 - PROGRESS: at 57.53% examples, 2118820 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:52,095 : INFO : EPOCH 7 - PROGRESS: at 85.19% examples, 2102153 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:52,612 : INFO : EPOCH 7: training on 8234555 raw words (7396638 effective words) took 3.5s, 2102236 effective words/s\n",
      "2024-06-06 11:25:53,620 : INFO : EPOCH 8 - PROGRESS: at 29.41% examples, 2165751 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:54,623 : INFO : EPOCH 8 - PROGRESS: at 59.14% examples, 2172691 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:55,626 : INFO : EPOCH 8 - PROGRESS: at 92.73% examples, 2278149 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:55,834 : INFO : EPOCH 8: training on 8234555 raw words (7396448 effective words) took 3.2s, 2297248 effective words/s\n",
      "2024-06-06 11:25:56,840 : INFO : EPOCH 9 - PROGRESS: at 30.99% examples, 2285257 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:57,850 : INFO : EPOCH 9 - PROGRESS: at 58.16% examples, 2128309 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:25:58,853 : INFO : EPOCH 9 - PROGRESS: at 86.15% examples, 2115551 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:25:59,304 : INFO : EPOCH 9: training on 8234555 raw words (7395965 effective words) took 3.5s, 2132103 effective words/s\n",
      "2024-06-06 11:25:59,305 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73970886 effective words) took 34.4s, 2150137 effective words/s', 'datetime': '2024-06-06T11:25:59.305089', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:28:06,358 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w5,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:28:06.358237', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:28:06,358 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:28:06,358 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 5 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 5, 'min_count': 2, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:28:07,124 : INFO : PROGRESS: at example #10000, processed 8060579 words (10529706 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:28:07,141 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:28:07,141 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:28:07,198 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:28:07.198017', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:28:07,198 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:28:07.198300', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:28:07,273 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:28:07,274 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:28:07,274 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:28:07.274562', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:28:07,398 : INFO : estimated required memory for 40031 words and 400 dimensions: 166512500 bytes\n",
      "2024-06-06 11:28:07,399 : INFO : resetting layer weights\n",
      "2024-06-06 11:28:07,452 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T11:28:07.452969', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:28:08,464 : INFO : EPOCH 0 - PROGRESS: at 28.82% examples, 2128055 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:09,464 : INFO : EPOCH 0 - PROGRESS: at 58.05% examples, 2143140 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:10,467 : INFO : EPOCH 0 - PROGRESS: at 85.40% examples, 2113392 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:10,976 : INFO : EPOCH 0: training on 8234555 raw words (7443914 effective words) took 3.5s, 2113408 effective words/s\n",
      "2024-06-06 11:28:11,978 : INFO : EPOCH 1 - PROGRESS: at 29.07% examples, 2167060 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:12,998 : INFO : EPOCH 1 - PROGRESS: at 53.70% examples, 1975047 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:13,999 : INFO : EPOCH 1 - PROGRESS: at 76.86% examples, 1892853 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:14,924 : INFO : EPOCH 1: training on 8234555 raw words (7444364 effective words) took 3.9s, 1886510 effective words/s\n",
      "2024-06-06 11:28:15,933 : INFO : EPOCH 2 - PROGRESS: at 25.38% examples, 1868831 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:16,943 : INFO : EPOCH 2 - PROGRESS: at 47.73% examples, 1759737 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:17,946 : INFO : EPOCH 2 - PROGRESS: at 74.21% examples, 1831534 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:18,877 : INFO : EPOCH 2: training on 8234555 raw words (7443950 effective words) took 4.0s, 1883805 effective words/s\n",
      "2024-06-06 11:28:19,883 : INFO : EPOCH 3 - PROGRESS: at 25.99% examples, 1919248 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:20,889 : INFO : EPOCH 3 - PROGRESS: at 51.14% examples, 1892858 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:21,889 : INFO : EPOCH 3 - PROGRESS: at 76.36% examples, 1887670 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:22,816 : INFO : EPOCH 3: training on 8234555 raw words (7443267 effective words) took 3.9s, 1890296 effective words/s\n",
      "2024-06-06 11:28:23,821 : INFO : EPOCH 4 - PROGRESS: at 28.82% examples, 2142392 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:24,822 : INFO : EPOCH 4 - PROGRESS: at 53.35% examples, 1977238 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:25,825 : INFO : EPOCH 4 - PROGRESS: at 79.70% examples, 1971024 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:26,609 : INFO : EPOCH 4: training on 8234555 raw words (7443669 effective words) took 3.8s, 1963283 effective words/s\n",
      "2024-06-06 11:28:27,620 : INFO : EPOCH 5 - PROGRESS: at 22.83% examples, 1685530 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:28,625 : INFO : EPOCH 5 - PROGRESS: at 49.92% examples, 1843289 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:29,631 : INFO : EPOCH 5 - PROGRESS: at 75.41% examples, 1860275 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:30,609 : INFO : EPOCH 5: training on 8234555 raw words (7443385 effective words) took 4.0s, 1862024 effective words/s\n",
      "2024-06-06 11:28:31,615 : INFO : EPOCH 6 - PROGRESS: at 24.03% examples, 1780097 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:32,617 : INFO : EPOCH 6 - PROGRESS: at 49.10% examples, 1820669 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:33,622 : INFO : EPOCH 6 - PROGRESS: at 74.21% examples, 1836887 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:34,573 : INFO : EPOCH 6: training on 8234555 raw words (7443866 effective words) took 4.0s, 1878745 effective words/s\n",
      "2024-06-06 11:28:35,577 : INFO : EPOCH 7 - PROGRESS: at 22.93% examples, 1704666 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:36,578 : INFO : EPOCH 7 - PROGRESS: at 48.71% examples, 1811006 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:37,580 : INFO : EPOCH 7 - PROGRESS: at 74.31% examples, 1842947 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:38,484 : INFO : EPOCH 7: training on 8234555 raw words (7443463 effective words) took 3.9s, 1903667 effective words/s\n",
      "2024-06-06 11:28:39,486 : INFO : EPOCH 8 - PROGRESS: at 24.54% examples, 1823296 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:40,488 : INFO : EPOCH 8 - PROGRESS: at 50.36% examples, 1871268 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:41,489 : INFO : EPOCH 8 - PROGRESS: at 76.12% examples, 1887444 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:42,336 : INFO : EPOCH 8: training on 8234555 raw words (7444063 effective words) took 3.9s, 1933503 effective words/s\n",
      "2024-06-06 11:28:43,352 : INFO : EPOCH 9 - PROGRESS: at 29.83% examples, 2196091 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:28:44,356 : INFO : EPOCH 9 - PROGRESS: at 59.83% examples, 2202188 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:45,363 : INFO : EPOCH 9 - PROGRESS: at 82.64% examples, 2036020 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:28:46,073 : INFO : EPOCH 9: training on 8234555 raw words (7443719 effective words) took 3.7s, 1992998 effective words/s\n",
      "2024-06-06 11:28:46,073 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74437660 effective words) took 38.6s, 1927437 effective words/s', 'datetime': '2024-06-06T11:28:46.073469', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:31:36,059 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:31:36.059522', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:31:36,059 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:31:36,060 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 6 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 300, 'window': 5, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:31:36,781 : INFO : PROGRESS: at example #10000, processed 8060579 words (11178362 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:31:36,799 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:31:36,799 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:31:36,838 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:31:36.838919', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:31:36,839 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:31:36.839326', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:31:36,880 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:31:36,881 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:31:36,882 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:31:36.882280', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:31:36,955 : INFO : estimated required memory for 23203 words and 300 dimensions: 81598100 bytes\n",
      "2024-06-06 11:31:36,955 : INFO : resetting layer weights\n",
      "2024-06-06 11:31:36,984 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T11:31:36.984823', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:31:37,989 : INFO : EPOCH 0 - PROGRESS: at 28.46% examples, 2104631 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:31:38,995 : INFO : EPOCH 0 - PROGRESS: at 58.94% examples, 2164264 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:40,001 : INFO : EPOCH 0 - PROGRESS: at 86.07% examples, 2115665 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:40,444 : INFO : EPOCH 0: training on 8234555 raw words (7397543 effective words) took 3.5s, 2139200 effective words/s\n",
      "2024-06-06 11:31:41,448 : INFO : EPOCH 1 - PROGRESS: at 30.05% examples, 2228710 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:42,452 : INFO : EPOCH 1 - PROGRESS: at 60.27% examples, 2219696 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:43,454 : INFO : EPOCH 1 - PROGRESS: at 85.83% examples, 2115257 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:31:44,149 : INFO : EPOCH 1: training on 8234555 raw words (7397026 effective words) took 3.7s, 1998260 effective words/s\n",
      "2024-06-06 11:31:45,167 : INFO : EPOCH 2 - PROGRESS: at 25.87% examples, 1874051 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:46,172 : INFO : EPOCH 2 - PROGRESS: at 48.37% examples, 1770394 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:31:47,173 : INFO : EPOCH 2 - PROGRESS: at 73.54% examples, 1803710 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:48,179 : INFO : EPOCH 2 - PROGRESS: at 97.92% examples, 1799140 words/s, in_qsize 18, out_qsize 0\n",
      "2024-06-06 11:31:48,247 : INFO : EPOCH 2: training on 8234555 raw words (7396847 effective words) took 4.1s, 1805454 effective words/s\n",
      "2024-06-06 11:31:49,258 : INFO : EPOCH 3 - PROGRESS: at 23.50% examples, 1725766 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:31:50,261 : INFO : EPOCH 3 - PROGRESS: at 48.50% examples, 1782839 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:31:51,265 : INFO : EPOCH 3 - PROGRESS: at 67.54% examples, 1651081 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:52,283 : INFO : EPOCH 3 - PROGRESS: at 89.84% examples, 1647483 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:31:52,725 : INFO : EPOCH 3: training on 8234555 raw words (7397045 effective words) took 4.5s, 1652552 effective words/s\n",
      "2024-06-06 11:31:53,734 : INFO : EPOCH 4 - PROGRESS: at 25.13% examples, 1841830 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:54,751 : INFO : EPOCH 4 - PROGRESS: at 49.81% examples, 1818549 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:55,752 : INFO : EPOCH 4 - PROGRESS: at 78.47% examples, 1916275 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:56,544 : INFO : EPOCH 4: training on 8234555 raw words (7397253 effective words) took 3.8s, 1938130 effective words/s\n",
      "2024-06-06 11:31:57,547 : INFO : EPOCH 5 - PROGRESS: at 29.61% examples, 2193251 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:58,550 : INFO : EPOCH 5 - PROGRESS: at 51.12% examples, 1887675 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:31:59,553 : INFO : EPOCH 5 - PROGRESS: at 74.39% examples, 1830282 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:00,506 : INFO : EPOCH 5: training on 8234555 raw words (7397765 effective words) took 4.0s, 1868127 effective words/s\n",
      "2024-06-06 11:32:01,508 : INFO : EPOCH 6 - PROGRESS: at 23.28% examples, 1725251 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:02,525 : INFO : EPOCH 6 - PROGRESS: at 45.38% examples, 1663839 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:03,527 : INFO : EPOCH 6 - PROGRESS: at 70.75% examples, 1733289 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:04,462 : INFO : EPOCH 6: training on 8234555 raw words (7397802 effective words) took 4.0s, 1870821 effective words/s\n",
      "2024-06-06 11:32:05,466 : INFO : EPOCH 7 - PROGRESS: at 31.08% examples, 2299607 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:06,474 : INFO : EPOCH 7 - PROGRESS: at 56.35% examples, 2067133 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:07,483 : INFO : EPOCH 7 - PROGRESS: at 80.01% examples, 1959984 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:08,232 : INFO : EPOCH 7: training on 8234555 raw words (7398780 effective words) took 3.8s, 1963597 effective words/s\n",
      "2024-06-06 11:32:09,243 : INFO : EPOCH 8 - PROGRESS: at 26.70% examples, 1948655 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:10,246 : INFO : EPOCH 8 - PROGRESS: at 47.97% examples, 1762545 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:11,248 : INFO : EPOCH 8 - PROGRESS: at 73.97% examples, 1818253 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:12,168 : INFO : EPOCH 8: training on 8234555 raw words (7397748 effective words) took 3.9s, 1880211 effective words/s\n",
      "2024-06-06 11:32:13,171 : INFO : EPOCH 9 - PROGRESS: at 26.22% examples, 1931183 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:32:14,195 : INFO : EPOCH 9 - PROGRESS: at 52.73% examples, 1923952 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:15,195 : INFO : EPOCH 9 - PROGRESS: at 76.97% examples, 1881409 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:32:15,930 : INFO : EPOCH 9: training on 8234555 raw words (7397498 effective words) took 3.8s, 1967380 effective words/s\n",
      "2024-06-06 11:32:15,931 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73975307 effective words) took 38.9s, 1899438 effective words/s', 'datetime': '2024-06-06T11:32:15.931284', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:34:51,906 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w10,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:34:51.906179', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:34:51,906 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:34:51,906 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 7 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 10, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:34:52,612 : INFO : PROGRESS: at example #10000, processed 8060579 words (11421253 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:34:52,631 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:34:52,631 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:34:52,671 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:34:52.671675', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:34:52,672 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:34:52.672189', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:34:52,715 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:34:52,716 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:34:52,716 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:34:52.716619', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:34:52,790 : INFO : estimated required memory for 23203 words and 400 dimensions: 104248900 bytes\n",
      "2024-06-06 11:34:52,790 : INFO : resetting layer weights\n",
      "2024-06-06 11:34:52,828 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:34:52.828729', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:34:53,836 : INFO : EPOCH 0 - PROGRESS: at 26.35% examples, 1929182 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:34:54,839 : INFO : EPOCH 0 - PROGRESS: at 53.21% examples, 1955980 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:34:55,840 : INFO : EPOCH 0 - PROGRESS: at 80.15% examples, 1968247 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:34:56,556 : INFO : EPOCH 0: training on 8234555 raw words (7397269 effective words) took 3.7s, 1984989 effective words/s\n",
      "2024-06-06 11:34:57,558 : INFO : EPOCH 1 - PROGRESS: at 26.70% examples, 1965494 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:34:58,559 : INFO : EPOCH 1 - PROGRESS: at 47.93% examples, 1771561 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:34:59,563 : INFO : EPOCH 1 - PROGRESS: at 69.59% examples, 1710954 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:00,567 : INFO : EPOCH 1 - PROGRESS: at 89.96% examples, 1660358 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:01,000 : INFO : EPOCH 1: training on 8234555 raw words (7397576 effective words) took 4.4s, 1665182 effective words/s\n",
      "2024-06-06 11:35:02,005 : INFO : EPOCH 2 - PROGRESS: at 19.94% examples, 1480435 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:03,005 : INFO : EPOCH 2 - PROGRESS: at 43.25% examples, 1599157 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:35:04,006 : INFO : EPOCH 2 - PROGRESS: at 64.55% examples, 1587105 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:05,008 : INFO : EPOCH 2 - PROGRESS: at 88.01% examples, 1625263 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:05,680 : INFO : EPOCH 2: training on 8234555 raw words (7396836 effective words) took 4.7s, 1580944 effective words/s\n",
      "2024-06-06 11:35:06,684 : INFO : EPOCH 3 - PROGRESS: at 23.90% examples, 1766272 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:07,689 : INFO : EPOCH 3 - PROGRESS: at 48.19% examples, 1775590 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:35:08,691 : INFO : EPOCH 3 - PROGRESS: at 70.54% examples, 1733920 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:09,697 : INFO : EPOCH 3 - PROGRESS: at 92.85% examples, 1711415 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:35:09,975 : INFO : EPOCH 3: training on 8234555 raw words (7397607 effective words) took 4.3s, 1723529 effective words/s\n",
      "2024-06-06 11:35:10,984 : INFO : EPOCH 4 - PROGRESS: at 22.83% examples, 1677084 words/s, in_qsize 20, out_qsize 2\n",
      "2024-06-06 11:35:12,001 : INFO : EPOCH 4 - PROGRESS: at 46.50% examples, 1700085 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:13,009 : INFO : EPOCH 4 - PROGRESS: at 69.79% examples, 1700755 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:14,011 : INFO : EPOCH 4 - PROGRESS: at 93.74% examples, 1720025 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:14,223 : INFO : EPOCH 4: training on 8234555 raw words (7397898 effective words) took 4.2s, 1742142 effective words/s\n",
      "2024-06-06 11:35:15,230 : INFO : EPOCH 5 - PROGRESS: at 23.15% examples, 1707002 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:16,232 : INFO : EPOCH 5 - PROGRESS: at 47.86% examples, 1761625 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:17,233 : INFO : EPOCH 5 - PROGRESS: at 71.51% examples, 1759474 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:18,236 : INFO : EPOCH 5 - PROGRESS: at 96.81% examples, 1785242 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:18,376 : INFO : EPOCH 5: training on 8234555 raw words (7396671 effective words) took 4.2s, 1781842 effective words/s\n",
      "2024-06-06 11:35:19,386 : INFO : EPOCH 6 - PROGRESS: at 23.52% examples, 1726807 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:20,387 : INFO : EPOCH 6 - PROGRESS: at 47.64% examples, 1751259 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:21,388 : INFO : EPOCH 6 - PROGRESS: at 73.04% examples, 1797001 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:22,389 : INFO : EPOCH 6 - PROGRESS: at 100.00% examples, 1844163 words/s, in_qsize 0, out_qsize 1\n",
      "2024-06-06 11:35:22,389 : INFO : EPOCH 6: training on 8234555 raw words (7396985 effective words) took 4.0s, 1843991 effective words/s\n",
      "2024-06-06 11:35:23,397 : INFO : EPOCH 7 - PROGRESS: at 23.18% examples, 1705505 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:24,398 : INFO : EPOCH 7 - PROGRESS: at 47.97% examples, 1766370 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:35:25,399 : INFO : EPOCH 7 - PROGRESS: at 73.61% examples, 1812923 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:26,331 : INFO : EPOCH 7: training on 8234555 raw words (7397417 effective words) took 3.9s, 1877314 effective words/s\n",
      "2024-06-06 11:35:27,333 : INFO : EPOCH 8 - PROGRESS: at 23.18% examples, 1715049 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:28,335 : INFO : EPOCH 8 - PROGRESS: at 45.63% examples, 1684710 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:29,344 : INFO : EPOCH 8 - PROGRESS: at 68.41% examples, 1676366 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:30,350 : INFO : EPOCH 8 - PROGRESS: at 93.05% examples, 1714595 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:30,616 : INFO : EPOCH 8: training on 8234555 raw words (7397233 effective words) took 4.3s, 1726994 effective words/s\n",
      "2024-06-06 11:35:31,623 : INFO : EPOCH 9 - PROGRESS: at 21.09% examples, 1553395 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:32,624 : INFO : EPOCH 9 - PROGRESS: at 45.07% examples, 1659811 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:33,638 : INFO : EPOCH 9 - PROGRESS: at 69.08% examples, 1688682 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:35:34,639 : INFO : EPOCH 9 - PROGRESS: at 95.19% examples, 1751235 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:35:34,797 : INFO : EPOCH 9: training on 8234555 raw words (7398151 effective words) took 4.2s, 1769997 effective words/s\n",
      "2024-06-06 11:35:34,798 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73973643 effective words) took 42.0s, 1762579 effective words/s', 'datetime': '2024-06-06T11:35:34.798229', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:38:36,318 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:38:36.318905', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:38:36,319 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:38:36,319 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 8 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:38:37,041 : INFO : PROGRESS: at example #10000, processed 8060579 words (11164914 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:38:37,058 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:38:37,058 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:38:37,097 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:38:37.097050', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:38:37,097 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:38:37.097405', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:38:37,141 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:38:37,142 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:38:37,142 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:38:37.142898', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:38:37,214 : INFO : estimated required memory for 23203 words and 200 dimensions: 58947300 bytes\n",
      "2024-06-06 11:38:37,214 : INFO : resetting layer weights\n",
      "2024-06-06 11:38:37,233 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:38:37.233080', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:38:38,243 : INFO : EPOCH 0 - PROGRESS: at 32.15% examples, 2362848 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:39,245 : INFO : EPOCH 0 - PROGRESS: at 64.90% examples, 2384476 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:40,252 : INFO : EPOCH 0 - PROGRESS: at 98.14% examples, 2407112 words/s, in_qsize 16, out_qsize 0\n",
      "2024-06-06 11:38:40,296 : INFO : EPOCH 0: training on 8234555 raw words (7397388 effective words) took 3.1s, 2415951 effective words/s\n",
      "2024-06-06 11:38:41,299 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 2396810 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:42,305 : INFO : EPOCH 1 - PROGRESS: at 62.78% examples, 2307433 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:43,306 : INFO : EPOCH 1 - PROGRESS: at 88.20% examples, 2169884 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:43,716 : INFO : EPOCH 1: training on 8234555 raw words (7396825 effective words) took 3.4s, 2164076 effective words/s\n",
      "2024-06-06 11:38:44,722 : INFO : EPOCH 2 - PROGRESS: at 25.40% examples, 1862510 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:38:45,723 : INFO : EPOCH 2 - PROGRESS: at 52.45% examples, 1933395 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:46,725 : INFO : EPOCH 2 - PROGRESS: at 79.70% examples, 1958157 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:47,473 : INFO : EPOCH 2: training on 8234555 raw words (7396198 effective words) took 3.8s, 1969385 effective words/s\n",
      "2024-06-06 11:38:48,475 : INFO : EPOCH 3 - PROGRESS: at 28.71% examples, 2125947 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:49,479 : INFO : EPOCH 3 - PROGRESS: at 58.05% examples, 2135073 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:50,481 : INFO : EPOCH 3 - PROGRESS: at 85.40% examples, 2104104 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:50,956 : INFO : EPOCH 3: training on 8234555 raw words (7396960 effective words) took 3.5s, 2124205 effective words/s\n",
      "2024-06-06 11:38:51,959 : INFO : EPOCH 4 - PROGRESS: at 28.13% examples, 2074073 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:52,970 : INFO : EPOCH 4 - PROGRESS: at 55.50% examples, 2033901 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:53,975 : INFO : EPOCH 4 - PROGRESS: at 85.16% examples, 2091435 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:38:54,461 : INFO : EPOCH 4: training on 8234555 raw words (7397985 effective words) took 3.5s, 2111862 effective words/s\n",
      "2024-06-06 11:38:55,463 : INFO : EPOCH 5 - PROGRESS: at 27.91% examples, 2058586 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:56,464 : INFO : EPOCH 5 - PROGRESS: at 61.48% examples, 2267691 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:57,464 : INFO : EPOCH 5 - PROGRESS: at 89.84% examples, 2214371 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:38:57,785 : INFO : EPOCH 5: training on 8234555 raw words (7397181 effective words) took 3.3s, 2226487 effective words/s\n",
      "2024-06-06 11:38:58,787 : INFO : EPOCH 6 - PROGRESS: at 29.19% examples, 2161353 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:38:59,787 : INFO : EPOCH 6 - PROGRESS: at 60.39% examples, 2229543 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:00,795 : INFO : EPOCH 6 - PROGRESS: at 94.10% examples, 2315172 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:00,957 : INFO : EPOCH 6: training on 8234555 raw words (7397679 effective words) took 3.2s, 2332931 effective words/s\n",
      "2024-06-06 11:39:01,963 : INFO : EPOCH 7 - PROGRESS: at 32.75% examples, 2413785 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:39:02,965 : INFO : EPOCH 7 - PROGRESS: at 57.81% examples, 2125477 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:03,966 : INFO : EPOCH 7 - PROGRESS: at 87.28% examples, 2148667 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:04,385 : INFO : EPOCH 7: training on 8234555 raw words (7397818 effective words) took 3.4s, 2158877 effective words/s\n",
      "2024-06-06 11:39:05,389 : INFO : EPOCH 8 - PROGRESS: at 27.91% examples, 2054387 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:06,391 : INFO : EPOCH 8 - PROGRESS: at 58.41% examples, 2149749 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:07,392 : INFO : EPOCH 8 - PROGRESS: at 87.28% examples, 2150078 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:39:07,760 : INFO : EPOCH 8: training on 8234555 raw words (7396934 effective words) took 3.4s, 2193056 effective words/s\n",
      "2024-06-06 11:39:08,762 : INFO : EPOCH 9 - PROGRESS: at 33.59% examples, 2488174 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:09,770 : INFO : EPOCH 9 - PROGRESS: at 65.47% examples, 2408081 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:10,770 : INFO : EPOCH 9 - PROGRESS: at 94.75% examples, 2331827 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:39:10,919 : INFO : EPOCH 9: training on 8234555 raw words (7397231 effective words) took 3.2s, 2342074 effective words/s\n",
      "2024-06-06 11:39:10,920 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73972199 effective words) took 33.7s, 2195850 effective words/s', 'datetime': '2024-06-06T11:39:10.920428', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:41:16,457 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc5,s0.001,t10>', 'datetime': '2024-06-06T11:41:16.457614', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:41:16,457 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:41:16,458 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 9 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 300, 'window': 5, 'min_count': 5, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:41:17,183 : INFO : PROGRESS: at example #10000, processed 8060579 words (11110499 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:41:17,200 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:41:17,201 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:41:17,239 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23203 unique words (29.75% of original 77987, drops 54784)', 'datetime': '2024-06-06T11:41:17.239945', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:41:17,240 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 8152606 word corpus (99.00% of original 8234555, drops 81949)', 'datetime': '2024-06-06T11:41:17.240337', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:41:17,284 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:41:17,285 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2024-06-06 11:41:17,286 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7387210.292550728 word corpus (90.6%% of prior 8152606)', 'datetime': '2024-06-06T11:41:17.286103', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:41:17,356 : INFO : estimated required memory for 23203 words and 300 dimensions: 81598100 bytes\n",
      "2024-06-06 11:41:17,356 : INFO : resetting layer weights\n",
      "2024-06-06 11:41:17,385 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 23203 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T11:41:17.385104', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:41:18,394 : INFO : EPOCH 0 - PROGRESS: at 31.08% examples, 2288377 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:19,395 : INFO : EPOCH 0 - PROGRESS: at 62.22% examples, 2284899 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:20,406 : INFO : EPOCH 0 - PROGRESS: at 93.96% examples, 2303939 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:20,590 : INFO : EPOCH 0: training on 8234555 raw words (7397747 effective words) took 3.2s, 2308999 effective words/s\n",
      "2024-06-06 11:41:21,598 : INFO : EPOCH 1 - PROGRESS: at 31.08% examples, 2291569 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:22,602 : INFO : EPOCH 1 - PROGRESS: at 63.06% examples, 2312778 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:23,609 : INFO : EPOCH 1 - PROGRESS: at 91.66% examples, 2248518 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:24,042 : INFO : EPOCH 1: training on 8234555 raw words (7397353 effective words) took 3.5s, 2143610 effective words/s\n",
      "2024-06-06 11:41:25,046 : INFO : EPOCH 2 - PROGRESS: at 26.12% examples, 1920551 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:26,053 : INFO : EPOCH 2 - PROGRESS: at 51.48% examples, 1895521 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 11:41:27,055 : INFO : EPOCH 2 - PROGRESS: at 73.88% examples, 1817208 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:28,046 : INFO : EPOCH 2: training on 8234555 raw words (7397593 effective words) took 4.0s, 1848667 effective words/s\n",
      "2024-06-06 11:41:29,052 : INFO : EPOCH 3 - PROGRESS: at 27.36% examples, 2007049 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:30,056 : INFO : EPOCH 3 - PROGRESS: at 58.05% examples, 2131355 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:31,058 : INFO : EPOCH 3 - PROGRESS: at 83.57% examples, 2055514 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:31,642 : INFO : EPOCH 3: training on 8234555 raw words (7397004 effective words) took 3.6s, 2057729 effective words/s\n",
      "2024-06-06 11:41:32,647 : INFO : EPOCH 4 - PROGRESS: at 25.87% examples, 1900402 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:33,650 : INFO : EPOCH 4 - PROGRESS: at 54.31% examples, 1997542 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:34,650 : INFO : EPOCH 4 - PROGRESS: at 80.09% examples, 1970149 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:35,400 : INFO : EPOCH 4: training on 8234555 raw words (7397464 effective words) took 3.8s, 1969189 effective words/s\n",
      "2024-06-06 11:41:36,404 : INFO : EPOCH 5 - PROGRESS: at 27.82% examples, 2046195 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:37,408 : INFO : EPOCH 5 - PROGRESS: at 55.15% examples, 2027400 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:38,410 : INFO : EPOCH 5 - PROGRESS: at 81.90% examples, 2014534 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:39,075 : INFO : EPOCH 5: training on 8234555 raw words (7396862 effective words) took 3.7s, 2014011 effective words/s\n",
      "2024-06-06 11:41:40,078 : INFO : EPOCH 6 - PROGRESS: at 26.46% examples, 1946300 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:41,084 : INFO : EPOCH 6 - PROGRESS: at 54.69% examples, 2008694 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:42,089 : INFO : EPOCH 6 - PROGRESS: at 80.66% examples, 1980890 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:42,762 : INFO : EPOCH 6: training on 8234555 raw words (7396684 effective words) took 3.7s, 2006957 effective words/s\n",
      "2024-06-06 11:41:43,766 : INFO : EPOCH 7 - PROGRESS: at 28.43% examples, 2097378 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:41:44,771 : INFO : EPOCH 7 - PROGRESS: at 57.28% examples, 2103167 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:45,783 : INFO : EPOCH 7 - PROGRESS: at 84.99% examples, 2084100 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:46,313 : INFO : EPOCH 7: training on 8234555 raw words (7398273 effective words) took 3.5s, 2084664 effective words/s\n",
      "2024-06-06 11:41:47,316 : INFO : EPOCH 8 - PROGRESS: at 28.24% examples, 2082780 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:48,319 : INFO : EPOCH 8 - PROGRESS: at 59.50% examples, 2190720 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:49,324 : INFO : EPOCH 8 - PROGRESS: at 89.28% examples, 2195421 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:49,811 : INFO : EPOCH 8: training on 8234555 raw words (7397643 effective words) took 3.5s, 2115600 effective words/s\n",
      "2024-06-06 11:41:50,814 : INFO : EPOCH 9 - PROGRESS: at 27.13% examples, 1998454 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:41:51,817 : INFO : EPOCH 9 - PROGRESS: at 54.69% examples, 2012532 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:52,819 : INFO : EPOCH 9 - PROGRESS: at 82.01% examples, 2019092 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:41:53,417 : INFO : EPOCH 9: training on 8234555 raw words (7397536 effective words) took 3.6s, 2052521 effective words/s\n",
      "2024-06-06 11:41:53,418 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (73974159 effective words) took 36.0s, 2052970 effective words/s', 'datetime': '2024-06-06T11:41:53.418063', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 11:44:31,470 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:44:31.470919', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:44:31,471 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:44:31,471 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 - Train F1 Score: 0.6331577663310187\n",
      "Iteration 10 - Test F1 Score: 0.6423302286387776\n",
      "Best Hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 2, 'epochs': 10, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n",
      "Best Train F1 Score: 0.6331577663310187\n",
      "Best Test F1 Score: 0.6423302286387776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:44:32,195 : INFO : PROGRESS: at example #10000, processed 8060579 words (11138187 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:44:32,211 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:44:32,212 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:44:32,272 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:44:32.272275', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:44:32,272 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:44:32.272668', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:44:32,345 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:44:32,346 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:44:32,347 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:44:32.347092', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:44:32,469 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 11:44:32,470 : INFO : resetting layer weights\n",
      "2024-06-06 11:44:32,498 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:44:32.498820', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:44:33,523 : INFO : EPOCH 0 - PROGRESS: at 32.28% examples, 2352410 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:34,526 : INFO : EPOCH 0 - PROGRESS: at 64.90% examples, 2380997 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:35,528 : INFO : EPOCH 0 - PROGRESS: at 97.39% examples, 2395004 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:35,603 : INFO : EPOCH 0: training on 8234555 raw words (7443932 effective words) took 3.1s, 2398564 effective words/s\n",
      "2024-06-06 11:44:36,609 : INFO : EPOCH 1 - PROGRESS: at 31.92% examples, 2372751 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:44:37,612 : INFO : EPOCH 1 - PROGRESS: at 63.92% examples, 2366286 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:38,614 : INFO : EPOCH 1 - PROGRESS: at 86.62% examples, 2146427 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:39,090 : INFO : EPOCH 1: training on 8234555 raw words (7444093 effective words) took 3.5s, 2135840 effective words/s\n",
      "2024-06-06 11:44:40,093 : INFO : EPOCH 2 - PROGRESS: at 26.22% examples, 1941610 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:41,095 : INFO : EPOCH 2 - PROGRESS: at 51.95% examples, 1931551 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:42,096 : INFO : EPOCH 2 - PROGRESS: at 78.19% examples, 1935171 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:42,871 : INFO : EPOCH 2: training on 8234555 raw words (7443625 effective words) took 3.8s, 1969438 effective words/s\n",
      "2024-06-06 11:44:43,884 : INFO : EPOCH 3 - PROGRESS: at 26.80% examples, 1964415 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:44,886 : INFO : EPOCH 3 - PROGRESS: at 55.38% examples, 2040832 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:45,890 : INFO : EPOCH 3 - PROGRESS: at 81.79% examples, 2018673 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:46,487 : INFO : EPOCH 3: training on 8234555 raw words (7443970 effective words) took 3.6s, 2059851 effective words/s\n",
      "2024-06-06 11:44:47,490 : INFO : EPOCH 4 - PROGRESS: at 28.22% examples, 2094862 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:48,493 : INFO : EPOCH 4 - PROGRESS: at 53.35% examples, 1977093 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:49,493 : INFO : EPOCH 4 - PROGRESS: at 81.29% examples, 2015535 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:50,131 : INFO : EPOCH 4: training on 8234555 raw words (7443228 effective words) took 3.6s, 2043185 effective words/s\n",
      "2024-06-06 11:44:51,136 : INFO : EPOCH 5 - PROGRESS: at 30.15% examples, 2247160 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:52,139 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 2315796 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:53,144 : INFO : EPOCH 5 - PROGRESS: at 89.67% examples, 2215994 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:53,548 : INFO : EPOCH 5: training on 8234555 raw words (7444265 effective words) took 3.4s, 2180009 effective words/s\n",
      "2024-06-06 11:44:54,557 : INFO : EPOCH 6 - PROGRESS: at 28.32% examples, 2091318 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:55,560 : INFO : EPOCH 6 - PROGRESS: at 55.51% examples, 2048047 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:56,565 : INFO : EPOCH 6 - PROGRESS: at 84.98% examples, 2099665 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:44:57,080 : INFO : EPOCH 6: training on 8234555 raw words (7443624 effective words) took 3.5s, 2107815 effective words/s\n",
      "2024-06-06 11:44:58,083 : INFO : EPOCH 7 - PROGRESS: at 26.22% examples, 1943024 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:44:59,091 : INFO : EPOCH 7 - PROGRESS: at 56.24% examples, 2076028 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:45:00,105 : INFO : EPOCH 7 - PROGRESS: at 84.85% examples, 2091453 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:45:00,645 : INFO : EPOCH 7: training on 8234555 raw words (7443742 effective words) took 3.6s, 2088941 effective words/s\n",
      "2024-06-06 11:45:01,655 : INFO : EPOCH 8 - PROGRESS: at 28.09% examples, 2070521 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:45:02,667 : INFO : EPOCH 8 - PROGRESS: at 55.50% examples, 2038472 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:45:03,669 : INFO : EPOCH 8 - PROGRESS: at 82.01% examples, 2020756 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:45:04,280 : INFO : EPOCH 8: training on 8234555 raw words (7443019 effective words) took 3.6s, 2048534 effective words/s\n",
      "2024-06-06 11:45:05,284 : INFO : EPOCH 9 - PROGRESS: at 27.13% examples, 2007376 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:45:06,285 : INFO : EPOCH 9 - PROGRESS: at 54.92% examples, 2034319 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:45:07,293 : INFO : EPOCH 9 - PROGRESS: at 80.90% examples, 1999766 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:45:07,926 : INFO : EPOCH 9: training on 8234555 raw words (7443412 effective words) took 3.6s, 2042625 effective words/s\n",
      "2024-06-06 11:45:07,926 : INFO : Doc2Vec lifecycle event {'msg': 'training on 82345550 raw words (74436910 effective words) took 35.4s, 2101105 effective words/s', 'datetime': '2024-06-06T11:45:07.926583', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m train_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_train_vectors, y_train, num_clusters)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Training Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_train, \u001b[43m[\u001b[49m\u001b[43mtrain_report\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajority_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    103\u001b[0m test_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_test_vectors, y_test, num_clusters)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Testing Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 101\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     99\u001b[0m train_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_train_vectors, y_train, num_clusters)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Training Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_train, [\u001b[43mtrain_report\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajority_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clusters)]))\n\u001b[1;32m    103\u001b[0m test_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_test_vectors, y_test, num_clusters)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Testing Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "\n",
    "# Function to train Doc2Vec model with given hyperparameters\n",
    "def train_doc2vec(X_train, X_test, vector_size, window, min_count, epochs, alpha, min_alpha, dm):\n",
    "    \n",
    "    \n",
    "    model = Doc2Vec(\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=10,\n",
    "        epochs=epochs,\n",
    "        alpha=alpha,\n",
    "        min_alpha=min_alpha,\n",
    "        dm=dm\n",
    "    )\n",
    "    \n",
    "    model.build_vocab(train_documents)\n",
    "    model.train(train_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    # Infer vectors for training and testing data\n",
    "    X_train_vectors = [model.infer_vector(doc) for doc in X_train]\n",
    "    X_test_vectors = [model.infer_vector(doc) for doc in X_test]\n",
    "    \n",
    "    return X_train_vectors, X_test_vectors\n",
    "\n",
    "# Function to perform K-Means clustering and evaluation\n",
    "def evaluate_model(X_vectors, y_true, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_vectors)\n",
    "    \n",
    "    cluster_mapping = {}\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_data = y_true[clusters == cluster]\n",
    "        common_severity_level = cluster_data.mode().values[0]\n",
    "        cluster_mapping[cluster] = common_severity_level\n",
    "    \n",
    "    y_pred = [cluster_mapping[cluster] for cluster in clusters]\n",
    "    return classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Hyperparameter ranges\n",
    "param_grid = {\n",
    "    'vector_size': [200, 300, 400],\n",
    "    'window': [5, 10],\n",
    "    'min_count': [2, 5],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'alpha': [0.025],\n",
    "    'min_alpha': [0.0001],\n",
    "    'dm': [0, 1]\n",
    "}\n",
    "\n",
    "# Generate random hyperparameter combinations\n",
    "def random_search(param_grid, n_iter=10):\n",
    "    keys = list(param_grid.keys())\n",
    "    hyperparams_list = []\n",
    "    for _ in range(n_iter):\n",
    "        params = {key: random.choice(param_grid[key]) for key in keys}\n",
    "        hyperparams_list.append(params)\n",
    "    return hyperparams_list\n",
    "\n",
    "# Perform randomized grid search\n",
    "random_hyperparams = random_search(param_grid, n_iter=10)\n",
    "num_clusters = 3\n",
    "best_train_score = 0\n",
    "best_test_score = 0\n",
    "best_params = None\n",
    "\n",
    "for i, params in enumerate(random_hyperparams):\n",
    "    print(f\"Training model with hyperparameters: {params}\")\n",
    "    X_train_vectors, X_test_vectors = train_doc2vec(X_train, X_test, **params)\n",
    "    \n",
    "    train_result = evaluate_model(X_train_vectors, y_train, num_clusters)\n",
    "    train_score = train_result['weighted avg']['f1-score']\n",
    "    print(f\"Iteration {i+1} - Train F1 Score: {train_score}\")\n",
    "    \n",
    "    test_result = evaluate_model(X_test_vectors, y_test, num_clusters)\n",
    "    test_score = test_result['weighted avg']['f1-score']\n",
    "    print(f\"Iteration {i+1} - Test F1 Score: {test_score}\")\n",
    "    \n",
    "    if test_score > best_test_score:\n",
    "        best_train_score = train_score\n",
    "        best_test_score = test_score\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train F1 Score: {best_train_score}\")\n",
    "print(f\"Best Test F1 Score: {best_test_score}\")\n",
    "\n",
    "# Retrain with best hyperparameters and evaluate\n",
    "if best_params:\n",
    "    X_train_vectors, X_test_vectors = train_doc2vec(X_train, X_test, **best_params)\n",
    "    \n",
    "    train_report = evaluate_model(X_train_vectors, y_train, num_clusters)\n",
    "    print(\"\\nFinal Training Classification Report:\")\n",
    "    print(classification_report(y_train, [train_report[i]['majority_label'] for i in range(num_clusters)]))\n",
    "    \n",
    "    test_report = evaluate_model(X_test_vectors, y_test, num_clusters)\n",
    "    print(\"\\nFinal Testing Classification Report:\")\n",
    "    print(classification_report(y_test, [test_report[i]['majority_label'] for i in range(num_clusters)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector_size': 200,\n",
       " 'window': 10,\n",
       " 'min_count': 2,\n",
       " 'epochs': 10,\n",
       " 'alpha': 0.025,\n",
       " 'min_alpha': 0.0001,\n",
       " 'dm': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:56:08,591 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T11:56:08.591123', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 11:56:08,591 : INFO : collecting all words and their counts\n",
      "2024-06-06 11:56:08,591 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparameters: {'vector_size': 400, 'window': 10, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:56:09,378 : INFO : PROGRESS: at example #10000, processed 8060579 words (10248775 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 11:56:09,395 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 11:56:09,396 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 11:56:09,456 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T11:56:09.456675', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:56:09,457 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T11:56:09.457072', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:56:09,536 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 11:56:09,537 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 11:56:09,537 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T11:56:09.537438', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 11:56:09,671 : INFO : estimated required memory for 40031 words and 400 dimensions: 166512500 bytes\n",
      "2024-06-06 11:56:09,672 : INFO : resetting layer weights\n",
      "2024-06-06 11:56:09,735 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T11:56:09.735771', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 11:56:10,740 : INFO : EPOCH 0 - PROGRESS: at 24.39% examples, 1810482 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:11,744 : INFO : EPOCH 0 - PROGRESS: at 47.64% examples, 1765015 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:56:12,746 : INFO : EPOCH 0 - PROGRESS: at 63.48% examples, 1566445 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:56:13,750 : INFO : EPOCH 0 - PROGRESS: at 86.48% examples, 1607693 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:14,337 : INFO : EPOCH 0: training on 8234555 raw words (7442775 effective words) took 4.6s, 1618214 effective words/s\n",
      "2024-06-06 11:56:15,341 : INFO : EPOCH 1 - PROGRESS: at 20.07% examples, 1498705 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:16,342 : INFO : EPOCH 1 - PROGRESS: at 42.93% examples, 1596446 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:17,349 : INFO : EPOCH 1 - PROGRESS: at 65.26% examples, 1610882 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:18,351 : INFO : EPOCH 1 - PROGRESS: at 91.13% examples, 1691075 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:18,667 : INFO : EPOCH 1: training on 8234555 raw words (7443657 effective words) took 4.3s, 1719636 effective words/s\n",
      "2024-06-06 11:56:19,675 : INFO : EPOCH 2 - PROGRESS: at 26.92% examples, 1983021 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:20,683 : INFO : EPOCH 2 - PROGRESS: at 52.09% examples, 1924119 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:21,687 : INFO : EPOCH 2 - PROGRESS: at 72.74% examples, 1795851 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:22,691 : INFO : EPOCH 2 - PROGRESS: at 92.73% examples, 1716584 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:22,993 : INFO : EPOCH 2: training on 8234555 raw words (7443671 effective words) took 4.3s, 1721189 effective words/s\n",
      "2024-06-06 11:56:24,003 : INFO : EPOCH 3 - PROGRESS: at 20.30% examples, 1510356 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:25,006 : INFO : EPOCH 3 - PROGRESS: at 39.34% examples, 1452246 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:26,010 : INFO : EPOCH 3 - PROGRESS: at 60.86% examples, 1500641 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:27,019 : INFO : EPOCH 3 - PROGRESS: at 82.64% examples, 1531184 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:27,973 : INFO : EPOCH 3: training on 8234555 raw words (7443715 effective words) took 5.0s, 1495582 effective words/s\n",
      "2024-06-06 11:56:28,978 : INFO : EPOCH 4 - PROGRESS: at 22.50% examples, 1668322 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:29,984 : INFO : EPOCH 4 - PROGRESS: at 45.65% examples, 1689555 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:30,992 : INFO : EPOCH 4 - PROGRESS: at 65.53% examples, 1613564 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:31,999 : INFO : EPOCH 4 - PROGRESS: at 88.02% examples, 1628807 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:32,486 : INFO : EPOCH 4: training on 8234555 raw words (7444631 effective words) took 4.5s, 1650028 effective words/s\n",
      "2024-06-06 11:56:33,489 : INFO : EPOCH 5 - PROGRESS: at 24.67% examples, 1830947 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:34,492 : INFO : EPOCH 5 - PROGRESS: at 45.26% examples, 1681038 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:35,493 : INFO : EPOCH 5 - PROGRESS: at 68.41% examples, 1690669 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:36,495 : INFO : EPOCH 5 - PROGRESS: at 89.72% examples, 1666993 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:36,957 : INFO : EPOCH 5: training on 8234555 raw words (7442821 effective words) took 4.5s, 1665292 effective words/s\n",
      "2024-06-06 11:56:37,964 : INFO : EPOCH 6 - PROGRESS: at 22.59% examples, 1674550 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:38,968 : INFO : EPOCH 6 - PROGRESS: at 43.98% examples, 1630203 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:39,973 : INFO : EPOCH 6 - PROGRESS: at 63.47% examples, 1563858 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:40,973 : INFO : EPOCH 6 - PROGRESS: at 82.44% examples, 1530286 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:41,775 : INFO : EPOCH 6: training on 8234555 raw words (7443662 effective words) took 4.8s, 1545575 effective words/s\n",
      "2024-06-06 11:56:42,778 : INFO : EPOCH 7 - PROGRESS: at 21.68% examples, 1612476 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:43,779 : INFO : EPOCH 7 - PROGRESS: at 41.99% examples, 1565147 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:44,781 : INFO : EPOCH 7 - PROGRESS: at 64.13% examples, 1586143 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:45,787 : INFO : EPOCH 7 - PROGRESS: at 85.72% examples, 1594472 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 11:56:46,455 : INFO : EPOCH 7: training on 8234555 raw words (7443582 effective words) took 4.7s, 1591473 effective words/s\n",
      "2024-06-06 11:56:47,459 : INFO : EPOCH 8 - PROGRESS: at 23.86% examples, 1775565 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:48,464 : INFO : EPOCH 8 - PROGRESS: at 46.19% examples, 1712571 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:49,467 : INFO : EPOCH 8 - PROGRESS: at 65.43% examples, 1613545 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:50,468 : INFO : EPOCH 8 - PROGRESS: at 87.93% examples, 1631165 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:50,995 : INFO : EPOCH 8: training on 8234555 raw words (7443601 effective words) took 4.5s, 1640136 effective words/s\n",
      "2024-06-06 11:56:51,997 : INFO : EPOCH 9 - PROGRESS: at 21.46% examples, 1594759 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:53,000 : INFO : EPOCH 9 - PROGRESS: at 44.38% examples, 1647433 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:54,002 : INFO : EPOCH 9 - PROGRESS: at 68.91% examples, 1704430 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:55,003 : INFO : EPOCH 9 - PROGRESS: at 93.03% examples, 1729296 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:55,238 : INFO : EPOCH 9: training on 8234555 raw words (7443665 effective words) took 4.2s, 1754829 effective words/s\n",
      "2024-06-06 11:56:56,243 : INFO : EPOCH 10 - PROGRESS: at 27.36% examples, 2022926 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:57,247 : INFO : EPOCH 10 - PROGRESS: at 55.50% examples, 2051129 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:56:58,249 : INFO : EPOCH 10 - PROGRESS: at 83.13% examples, 2058397 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:56:58,852 : INFO : EPOCH 10: training on 8234555 raw words (7444033 effective words) took 3.6s, 2060577 effective words/s\n",
      "2024-06-06 11:56:59,864 : INFO : EPOCH 11 - PROGRESS: at 26.46% examples, 1941014 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:00,866 : INFO : EPOCH 11 - PROGRESS: at 48.41% examples, 1789446 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:01,867 : INFO : EPOCH 11 - PROGRESS: at 73.16% examples, 1809283 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:02,870 : INFO : EPOCH 11 - PROGRESS: at 95.91% examples, 1779177 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:03,086 : INFO : EPOCH 11: training on 8234555 raw words (7444319 effective words) took 4.2s, 1758569 effective words/s\n",
      "2024-06-06 11:57:04,093 : INFO : EPOCH 12 - PROGRESS: at 20.73% examples, 1538677 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:05,098 : INFO : EPOCH 12 - PROGRESS: at 43.61% examples, 1617080 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:06,109 : INFO : EPOCH 12 - PROGRESS: at 66.44% examples, 1633611 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:07,114 : INFO : EPOCH 12 - PROGRESS: at 84.99% examples, 1572664 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:07,771 : INFO : EPOCH 12: training on 8234555 raw words (7443653 effective words) took 4.7s, 1589555 effective words/s\n",
      "2024-06-06 11:57:08,773 : INFO : EPOCH 13 - PROGRESS: at 23.64% examples, 1762253 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:09,777 : INFO : EPOCH 13 - PROGRESS: at 48.96% examples, 1819503 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:10,792 : INFO : EPOCH 13 - PROGRESS: at 72.40% examples, 1787024 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:11,794 : INFO : EPOCH 13 - PROGRESS: at 96.57% examples, 1788448 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:11,914 : INFO : EPOCH 13: training on 8234555 raw words (7444121 effective words) took 4.1s, 1797539 effective words/s\n",
      "2024-06-06 11:57:12,920 : INFO : EPOCH 14 - PROGRESS: at 24.67% examples, 1827487 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:13,923 : INFO : EPOCH 14 - PROGRESS: at 49.89% examples, 1849861 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:14,929 : INFO : EPOCH 14 - PROGRESS: at 73.25% examples, 1813357 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:15,934 : INFO : EPOCH 14 - PROGRESS: at 95.58% examples, 1772666 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:16,128 : INFO : EPOCH 14: training on 8234555 raw words (7443757 effective words) took 4.2s, 1767728 effective words/s\n",
      "2024-06-06 11:57:17,132 : INFO : EPOCH 15 - PROGRESS: at 23.05% examples, 1713385 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:18,136 : INFO : EPOCH 15 - PROGRESS: at 46.31% examples, 1717493 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:19,141 : INFO : EPOCH 15 - PROGRESS: at 65.99% examples, 1626906 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:20,148 : INFO : EPOCH 15 - PROGRESS: at 88.55% examples, 1641021 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:20,582 : INFO : EPOCH 15: training on 8234555 raw words (7443723 effective words) took 4.5s, 1671689 effective words/s\n",
      "2024-06-06 11:57:21,585 : INFO : EPOCH 16 - PROGRESS: at 23.78% examples, 1769160 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:22,591 : INFO : EPOCH 16 - PROGRESS: at 47.36% examples, 1755800 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:23,596 : INFO : EPOCH 16 - PROGRESS: at 65.76% examples, 1620884 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:24,600 : INFO : EPOCH 16 - PROGRESS: at 81.99% examples, 1520623 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:25,403 : INFO : EPOCH 16: training on 8234555 raw words (7443625 effective words) took 4.8s, 1544467 effective words/s\n",
      "2024-06-06 11:57:26,405 : INFO : EPOCH 17 - PROGRESS: at 23.90% examples, 1779435 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:27,408 : INFO : EPOCH 17 - PROGRESS: at 46.61% examples, 1733223 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:28,410 : INFO : EPOCH 17 - PROGRESS: at 70.44% examples, 1744052 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:29,421 : INFO : EPOCH 17 - PROGRESS: at 97.39% examples, 1805473 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:29,496 : INFO : EPOCH 17: training on 8234555 raw words (7443490 effective words) took 4.1s, 1819436 effective words/s\n",
      "2024-06-06 11:57:30,501 : INFO : EPOCH 18 - PROGRESS: at 24.15% examples, 1792409 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:31,510 : INFO : EPOCH 18 - PROGRESS: at 48.72% examples, 1803089 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:32,511 : INFO : EPOCH 18 - PROGRESS: at 72.63% examples, 1795703 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:33,512 : INFO : EPOCH 18 - PROGRESS: at 97.17% examples, 1802235 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:33,610 : INFO : EPOCH 18: training on 8234555 raw words (7444100 effective words) took 4.1s, 1810123 effective words/s\n",
      "2024-06-06 11:57:34,615 : INFO : EPOCH 19 - PROGRESS: at 26.68% examples, 1972850 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 11:57:35,615 : INFO : EPOCH 19 - PROGRESS: at 49.78% examples, 1848997 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:36,620 : INFO : EPOCH 19 - PROGRESS: at 70.67% examples, 1747960 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 11:57:37,623 : INFO : EPOCH 19 - PROGRESS: at 92.11% examples, 1710659 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 11:57:37,982 : INFO : EPOCH 19: training on 8234555 raw words (7443863 effective words) took 4.4s, 1703299 effective words/s\n",
      "2024-06-06 11:57:37,982 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148874464 effective words) took 88.2s, 1687017 effective words/s', 'datetime': '2024-06-06T11:57:37.982975', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:04:06,422 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w5,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:04:06.422959', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:04:06,423 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:04:06,423 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 5, 'min_count': 2, 'epochs': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:04:07,252 : INFO : PROGRESS: at example #10000, processed 8060579 words (9731902 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:04:07,273 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:04:07,274 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:04:07,343 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:04:07.343718', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:04:07,344 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:04:07.344302', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:04:07,430 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:04:07,431 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:04:07,432 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:04:07.432184', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:04:07,569 : INFO : estimated required memory for 40031 words and 400 dimensions: 166512500 bytes\n",
      "2024-06-06 12:04:07,569 : INFO : resetting layer weights\n",
      "2024-06-06 12:04:07,673 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T12:04:07.673292', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:04:08,676 : INFO : EPOCH 0 - PROGRESS: at 24.03% examples, 1787272 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:09,676 : INFO : EPOCH 0 - PROGRESS: at 51.35% examples, 1910868 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:10,679 : INFO : EPOCH 0 - PROGRESS: at 78.37% examples, 1938573 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:11,688 : INFO : EPOCH 0 - PROGRESS: at 98.69% examples, 1832793 words/s, in_qsize 11, out_qsize 0\n",
      "2024-06-06 12:04:11,749 : INFO : EPOCH 0: training on 8234555 raw words (7443563 effective words) took 4.1s, 1827288 effective words/s\n",
      "2024-06-06 12:04:12,764 : INFO : EPOCH 1 - PROGRESS: at 17.92% examples, 1324436 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:13,779 : INFO : EPOCH 1 - PROGRESS: at 32.91% examples, 1207957 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:14,781 : INFO : EPOCH 1 - PROGRESS: at 51.81% examples, 1273503 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:15,782 : INFO : EPOCH 1 - PROGRESS: at 66.78% examples, 1230871 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:16,805 : INFO : EPOCH 1 - PROGRESS: at 82.32% examples, 1213725 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:17,809 : INFO : EPOCH 1 - PROGRESS: at 95.66% examples, 1176892 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:18,111 : INFO : EPOCH 1: training on 8234555 raw words (7443375 effective words) took 6.4s, 1170509 effective words/s\n",
      "2024-06-06 12:04:19,114 : INFO : EPOCH 2 - PROGRESS: at 18.95% examples, 1414285 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:20,114 : INFO : EPOCH 2 - PROGRESS: at 38.16% examples, 1415064 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:21,119 : INFO : EPOCH 2 - PROGRESS: at 59.03% examples, 1458136 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:22,131 : INFO : EPOCH 2 - PROGRESS: at 77.61% examples, 1436039 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:23,111 : INFO : EPOCH 2: training on 8234555 raw words (7443915 effective words) took 5.0s, 1489080 effective words/s\n",
      "2024-06-06 12:04:24,117 : INFO : EPOCH 3 - PROGRESS: at 21.33% examples, 1582701 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:25,124 : INFO : EPOCH 3 - PROGRESS: at 40.06% examples, 1479697 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:26,125 : INFO : EPOCH 3 - PROGRESS: at 57.81% examples, 1425046 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:27,126 : INFO : EPOCH 3 - PROGRESS: at 78.09% examples, 1446600 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:28,128 : INFO : EPOCH 3 - PROGRESS: at 97.46% examples, 1447753 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:28,234 : INFO : EPOCH 3: training on 8234555 raw words (7443638 effective words) took 5.1s, 1453503 effective words/s\n",
      "2024-06-06 12:04:29,240 : INFO : EPOCH 4 - PROGRESS: at 21.44% examples, 1590585 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:30,251 : INFO : EPOCH 4 - PROGRESS: at 43.17% examples, 1595765 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:31,259 : INFO : EPOCH 4 - PROGRESS: at 62.31% examples, 1530742 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:32,263 : INFO : EPOCH 4 - PROGRESS: at 86.75% examples, 1606269 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:32,734 : INFO : EPOCH 4: training on 8234555 raw words (7443969 effective words) took 4.5s, 1654997 effective words/s\n",
      "2024-06-06 12:04:33,744 : INFO : EPOCH 5 - PROGRESS: at 19.83% examples, 1474700 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 12:04:34,745 : INFO : EPOCH 5 - PROGRESS: at 43.04% examples, 1595787 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:35,751 : INFO : EPOCH 5 - PROGRESS: at 64.22% examples, 1583601 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:36,751 : INFO : EPOCH 5 - PROGRESS: at 85.08% examples, 1579245 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:37,383 : INFO : EPOCH 5: training on 8234555 raw words (7443773 effective words) took 4.6s, 1602059 effective words/s\n",
      "2024-06-06 12:04:38,391 : INFO : EPOCH 6 - PROGRESS: at 23.40% examples, 1734010 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:39,398 : INFO : EPOCH 6 - PROGRESS: at 46.68% examples, 1724488 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:04:40,404 : INFO : EPOCH 6 - PROGRESS: at 69.49% examples, 1710591 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:41,404 : INFO : EPOCH 6 - PROGRESS: at 92.62% examples, 1716137 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:41,777 : INFO : EPOCH 6: training on 8234555 raw words (7444064 effective words) took 4.4s, 1694527 effective words/s\n",
      "2024-06-06 12:04:42,789 : INFO : EPOCH 7 - PROGRESS: at 23.18% examples, 1711413 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:43,791 : INFO : EPOCH 7 - PROGRESS: at 48.72% examples, 1804285 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:44,795 : INFO : EPOCH 7 - PROGRESS: at 72.27% examples, 1786268 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:45,798 : INFO : EPOCH 7 - PROGRESS: at 98.46% examples, 1826271 words/s, in_qsize 13, out_qsize 0\n",
      "2024-06-06 12:04:45,838 : INFO : EPOCH 7: training on 8234555 raw words (7443807 effective words) took 4.1s, 1834503 effective words/s\n",
      "2024-06-06 12:04:46,845 : INFO : EPOCH 8 - PROGRESS: at 19.83% examples, 1479130 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:47,847 : INFO : EPOCH 8 - PROGRESS: at 37.31% examples, 1382008 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:48,857 : INFO : EPOCH 8 - PROGRESS: at 58.92% examples, 1450712 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:49,858 : INFO : EPOCH 8 - PROGRESS: at 80.77% examples, 1496633 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:50,864 : INFO : EPOCH 8 - PROGRESS: at 98.03% examples, 1453533 words/s, in_qsize 17, out_qsize 0\n",
      "2024-06-06 12:04:50,940 : INFO : EPOCH 8: training on 8234555 raw words (7444379 effective words) took 5.1s, 1459585 effective words/s\n",
      "2024-06-06 12:04:51,945 : INFO : EPOCH 9 - PROGRESS: at 19.94% examples, 1490434 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:52,948 : INFO : EPOCH 9 - PROGRESS: at 40.09% examples, 1484669 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:53,953 : INFO : EPOCH 9 - PROGRESS: at 57.42% examples, 1413675 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:54,958 : INFO : EPOCH 9 - PROGRESS: at 78.47% examples, 1452213 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:55,961 : INFO : EPOCH 9 - PROGRESS: at 96.56% examples, 1432795 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:04:56,117 : INFO : EPOCH 9: training on 8234555 raw words (7443367 effective words) took 5.2s, 1438492 effective words/s\n",
      "2024-06-06 12:04:57,123 : INFO : EPOCH 10 - PROGRESS: at 14.35% examples, 1055094 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:58,136 : INFO : EPOCH 10 - PROGRESS: at 33.90% examples, 1255469 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:04:59,147 : INFO : EPOCH 10 - PROGRESS: at 54.69% examples, 1340540 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:00,147 : INFO : EPOCH 10 - PROGRESS: at 75.25% examples, 1392247 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:01,149 : INFO : EPOCH 10 - PROGRESS: at 93.29% examples, 1381140 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:01,537 : INFO : EPOCH 10: training on 8234555 raw words (7443376 effective words) took 5.4s, 1373852 effective words/s\n",
      "2024-06-06 12:05:02,540 : INFO : EPOCH 11 - PROGRESS: at 19.07% examples, 1423758 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:03,544 : INFO : EPOCH 11 - PROGRESS: at 35.63% examples, 1323351 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:04,552 : INFO : EPOCH 11 - PROGRESS: at 56.86% examples, 1398562 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:05,556 : INFO : EPOCH 11 - PROGRESS: at 77.33% examples, 1432015 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:06,564 : INFO : EPOCH 11 - PROGRESS: at 98.14% examples, 1454644 words/s, in_qsize 16, out_qsize 0\n",
      "2024-06-06 12:05:06,634 : INFO : EPOCH 11: training on 8234555 raw words (7442708 effective words) took 5.1s, 1460663 effective words/s\n",
      "2024-06-06 12:05:07,641 : INFO : EPOCH 12 - PROGRESS: at 18.31% examples, 1362293 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:08,650 : INFO : EPOCH 12 - PROGRESS: at 39.18% examples, 1445309 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:09,656 : INFO : EPOCH 12 - PROGRESS: at 59.16% examples, 1455211 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:05:10,662 : INFO : EPOCH 12 - PROGRESS: at 78.66% examples, 1453074 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:11,665 : INFO : EPOCH 12 - PROGRESS: at 98.97% examples, 1466036 words/s, in_qsize 9, out_qsize 1\n",
      "2024-06-06 12:05:11,688 : INFO : EPOCH 12: training on 8234555 raw words (7443466 effective words) took 5.1s, 1473470 effective words/s\n",
      "2024-06-06 12:05:12,699 : INFO : EPOCH 13 - PROGRESS: at 20.18% examples, 1500701 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:13,703 : INFO : EPOCH 13 - PROGRESS: at 43.50% examples, 1611430 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:14,706 : INFO : EPOCH 13 - PROGRESS: at 67.04% examples, 1651615 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:15,710 : INFO : EPOCH 13 - PROGRESS: at 80.90% examples, 1498611 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:16,676 : INFO : EPOCH 13: training on 8234555 raw words (7443190 effective words) took 5.0s, 1493204 effective words/s\n",
      "2024-06-06 12:05:17,687 : INFO : EPOCH 14 - PROGRESS: at 16.06% examples, 1186641 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:18,714 : INFO : EPOCH 14 - PROGRESS: at 35.25% examples, 1291413 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:19,722 : INFO : EPOCH 14 - PROGRESS: at 56.26% examples, 1370392 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:20,723 : INFO : EPOCH 14 - PROGRESS: at 77.20% examples, 1420396 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:21,629 : INFO : EPOCH 14: training on 8234555 raw words (7443809 effective words) took 4.9s, 1503859 effective words/s\n",
      "2024-06-06 12:05:22,635 : INFO : EPOCH 15 - PROGRESS: at 22.93% examples, 1701685 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:23,653 : INFO : EPOCH 15 - PROGRESS: at 42.95% examples, 1581377 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:24,656 : INFO : EPOCH 15 - PROGRESS: at 65.65% examples, 1611748 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:25,669 : INFO : EPOCH 15 - PROGRESS: at 87.02% examples, 1605759 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:26,234 : INFO : EPOCH 15: training on 8234555 raw words (7444213 effective words) took 4.6s, 1617052 effective words/s\n",
      "2024-06-06 12:05:27,240 : INFO : EPOCH 16 - PROGRESS: at 22.83% examples, 1694448 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:28,247 : INFO : EPOCH 16 - PROGRESS: at 42.15% examples, 1561145 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:29,248 : INFO : EPOCH 16 - PROGRESS: at 65.14% examples, 1608068 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:30,249 : INFO : EPOCH 16 - PROGRESS: at 89.42% examples, 1659184 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:30,666 : INFO : EPOCH 16: training on 8234555 raw words (7443747 effective words) took 4.4s, 1680640 effective words/s\n",
      "2024-06-06 12:05:31,678 : INFO : EPOCH 17 - PROGRESS: at 24.42% examples, 1799408 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:32,680 : INFO : EPOCH 17 - PROGRESS: at 47.10% examples, 1743212 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:33,681 : INFO : EPOCH 17 - PROGRESS: at 66.67% examples, 1644386 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:34,705 : INFO : EPOCH 17 - PROGRESS: at 88.20% examples, 1627716 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:05:35,268 : INFO : EPOCH 17: training on 8234555 raw words (7444501 effective words) took 4.6s, 1618725 effective words/s\n",
      "2024-06-06 12:05:36,273 : INFO : EPOCH 18 - PROGRESS: at 20.57% examples, 1532740 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:05:37,274 : INFO : EPOCH 18 - PROGRESS: at 43.04% examples, 1599652 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:38,275 : INFO : EPOCH 18 - PROGRESS: at 65.14% examples, 1610805 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:39,285 : INFO : EPOCH 18 - PROGRESS: at 87.54% examples, 1623413 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:39,847 : INFO : EPOCH 18: training on 8234555 raw words (7444062 effective words) took 4.6s, 1625981 effective words/s\n",
      "2024-06-06 12:05:40,850 : INFO : EPOCH 19 - PROGRESS: at 17.40% examples, 1298177 words/s, in_qsize 17, out_qsize 2\n",
      "2024-06-06 12:05:41,853 : INFO : EPOCH 19 - PROGRESS: at 40.66% examples, 1510896 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:42,863 : INFO : EPOCH 19 - PROGRESS: at 65.60% examples, 1617969 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:43,870 : INFO : EPOCH 19 - PROGRESS: at 84.99% examples, 1574593 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:44,533 : INFO : EPOCH 19: training on 8234555 raw words (7443287 effective words) took 4.7s, 1589108 effective words/s\n",
      "2024-06-06 12:05:45,538 : INFO : EPOCH 20 - PROGRESS: at 22.85% examples, 1695469 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:05:46,538 : INFO : EPOCH 20 - PROGRESS: at 45.99% examples, 1707000 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:47,540 : INFO : EPOCH 20 - PROGRESS: at 65.47% examples, 1619624 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:48,548 : INFO : EPOCH 20 - PROGRESS: at 84.01% examples, 1560326 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:49,281 : INFO : EPOCH 20: training on 8234555 raw words (7442880 effective words) took 4.7s, 1568150 effective words/s\n",
      "2024-06-06 12:05:50,285 : INFO : EPOCH 21 - PROGRESS: at 24.65% examples, 1830076 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:05:51,292 : INFO : EPOCH 21 - PROGRESS: at 52.32% examples, 1938198 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:52,301 : INFO : EPOCH 21 - PROGRESS: at 76.25% examples, 1881259 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:53,308 : INFO : EPOCH 21 - PROGRESS: at 95.47% examples, 1767224 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:53,495 : INFO : EPOCH 21: training on 8234555 raw words (7443962 effective words) took 4.2s, 1767265 effective words/s\n",
      "2024-06-06 12:05:54,506 : INFO : EPOCH 22 - PROGRESS: at 22.40% examples, 1652428 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:55,515 : INFO : EPOCH 22 - PROGRESS: at 45.30% examples, 1669661 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:56,517 : INFO : EPOCH 22 - PROGRESS: at 67.61% examples, 1662740 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:57,524 : INFO : EPOCH 22 - PROGRESS: at 88.54% examples, 1637863 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:57,988 : INFO : EPOCH 22: training on 8234555 raw words (7443805 effective words) took 4.5s, 1657833 effective words/s\n",
      "2024-06-06 12:05:58,991 : INFO : EPOCH 23 - PROGRESS: at 24.30% examples, 1803864 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:05:59,995 : INFO : EPOCH 23 - PROGRESS: at 47.87% examples, 1774666 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:01,006 : INFO : EPOCH 23 - PROGRESS: at 75.28% examples, 1859713 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:01,944 : INFO : EPOCH 23: training on 8234555 raw words (7443586 effective words) took 4.0s, 1882258 effective words/s\n",
      "2024-06-06 12:06:02,952 : INFO : EPOCH 24 - PROGRESS: at 23.40% examples, 1733398 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:03,954 : INFO : EPOCH 24 - PROGRESS: at 46.65% examples, 1728887 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:04,954 : INFO : EPOCH 24 - PROGRESS: at 70.44% examples, 1741780 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:05,955 : INFO : EPOCH 24 - PROGRESS: at 94.21% examples, 1750035 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:06,220 : INFO : EPOCH 24: training on 8234555 raw words (7443679 effective words) took 4.3s, 1741355 effective words/s\n",
      "2024-06-06 12:06:07,227 : INFO : EPOCH 25 - PROGRESS: at 24.03% examples, 1782187 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:08,230 : INFO : EPOCH 25 - PROGRESS: at 47.73% examples, 1768795 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:09,230 : INFO : EPOCH 25 - PROGRESS: at 73.25% examples, 1816296 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:10,118 : INFO : EPOCH 25: training on 8234555 raw words (7443586 effective words) took 3.9s, 1911126 effective words/s\n",
      "2024-06-06 12:06:11,128 : INFO : EPOCH 26 - PROGRESS: at 25.74% examples, 1893246 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:12,134 : INFO : EPOCH 26 - PROGRESS: at 52.45% examples, 1936868 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:13,135 : INFO : EPOCH 26 - PROGRESS: at 78.37% examples, 1931407 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:13,887 : INFO : EPOCH 26: training on 8234555 raw words (7443872 effective words) took 3.8s, 1975802 effective words/s\n",
      "2024-06-06 12:06:14,892 : INFO : EPOCH 27 - PROGRESS: at 27.01% examples, 1997756 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:06:15,903 : INFO : EPOCH 27 - PROGRESS: at 50.36% examples, 1859256 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:16,905 : INFO : EPOCH 27 - PROGRESS: at 73.12% examples, 1807681 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:17,906 : INFO : EPOCH 27 - PROGRESS: at 97.60% examples, 1809208 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:18,026 : INFO : EPOCH 27: training on 8234555 raw words (7443629 effective words) took 4.1s, 1799348 effective words/s\n",
      "2024-06-06 12:06:19,029 : INFO : EPOCH 28 - PROGRESS: at 26.92% examples, 1994074 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:20,039 : INFO : EPOCH 28 - PROGRESS: at 57.42% examples, 2116537 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:21,040 : INFO : EPOCH 28 - PROGRESS: at 84.46% examples, 2090565 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:21,677 : INFO : EPOCH 28: training on 8234555 raw words (7443481 effective words) took 3.6s, 2039765 effective words/s\n",
      "2024-06-06 12:06:22,681 : INFO : EPOCH 29 - PROGRESS: at 23.64% examples, 1757790 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:23,682 : INFO : EPOCH 29 - PROGRESS: at 45.26% examples, 1681049 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:24,688 : INFO : EPOCH 29 - PROGRESS: at 68.82% examples, 1699753 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:25,691 : INFO : EPOCH 29 - PROGRESS: at 93.17% examples, 1729264 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:25,955 : INFO : EPOCH 29: training on 8234555 raw words (7443273 effective words) took 4.3s, 1740308 effective words/s\n",
      "2024-06-06 12:06:26,961 : INFO : EPOCH 30 - PROGRESS: at 19.94% examples, 1487893 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:27,968 : INFO : EPOCH 30 - PROGRESS: at 44.70% examples, 1653753 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:28,971 : INFO : EPOCH 30 - PROGRESS: at 69.06% examples, 1702481 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:29,972 : INFO : EPOCH 30 - PROGRESS: at 93.41% examples, 1732130 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:30,307 : INFO : EPOCH 30: training on 8234555 raw words (7443170 effective words) took 4.4s, 1711036 effective words/s\n",
      "2024-06-06 12:06:31,312 : INFO : EPOCH 31 - PROGRESS: at 22.59% examples, 1678056 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:32,317 : INFO : EPOCH 31 - PROGRESS: at 48.30% examples, 1789650 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:33,322 : INFO : EPOCH 31 - PROGRESS: at 75.62% examples, 1869514 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:06:34,128 : INFO : EPOCH 31: training on 8234555 raw words (7443642 effective words) took 3.8s, 1949335 effective words/s\n",
      "2024-06-06 12:06:35,132 : INFO : EPOCH 32 - PROGRESS: at 30.85% examples, 2297131 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:36,132 : INFO : EPOCH 32 - PROGRESS: at 62.45% examples, 2314267 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:37,133 : INFO : EPOCH 32 - PROGRESS: at 93.29% examples, 2312125 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:37,333 : INFO : EPOCH 32: training on 8234555 raw words (7443222 effective words) took 3.2s, 2323275 effective words/s\n",
      "2024-06-06 12:06:38,338 : INFO : EPOCH 33 - PROGRESS: at 28.94% examples, 2151302 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:39,339 : INFO : EPOCH 33 - PROGRESS: at 53.35% examples, 1976893 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:40,346 : INFO : EPOCH 33 - PROGRESS: at 81.55% examples, 2017085 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:41,020 : INFO : EPOCH 33: training on 8234555 raw words (7444119 effective words) took 3.7s, 2019851 effective words/s\n",
      "2024-06-06 12:06:42,025 : INFO : EPOCH 34 - PROGRESS: at 30.38% examples, 2262737 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:43,027 : INFO : EPOCH 34 - PROGRESS: at 62.22% examples, 2302738 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:44,028 : INFO : EPOCH 34 - PROGRESS: at 93.51% examples, 2316359 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:44,223 : INFO : EPOCH 34: training on 8234555 raw words (7443325 effective words) took 3.2s, 2325212 effective words/s\n",
      "2024-06-06 12:06:45,225 : INFO : EPOCH 35 - PROGRESS: at 30.88% examples, 2302116 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:46,230 : INFO : EPOCH 35 - PROGRESS: at 62.18% examples, 2302424 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:06:47,230 : INFO : EPOCH 35 - PROGRESS: at 92.85% examples, 2299860 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:47,444 : INFO : EPOCH 35: training on 8234555 raw words (7444039 effective words) took 3.2s, 2312164 effective words/s\n",
      "2024-06-06 12:06:48,445 : INFO : EPOCH 36 - PROGRESS: at 31.08% examples, 2318678 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:49,446 : INFO : EPOCH 36 - PROGRESS: at 61.34% examples, 2277348 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:50,454 : INFO : EPOCH 36 - PROGRESS: at 90.80% examples, 2246662 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:50,752 : INFO : EPOCH 36: training on 8234555 raw words (7443870 effective words) took 3.3s, 2251094 effective words/s\n",
      "2024-06-06 12:06:51,756 : INFO : EPOCH 37 - PROGRESS: at 29.72% examples, 2213582 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:52,761 : INFO : EPOCH 37 - PROGRESS: at 61.93% examples, 2291549 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:53,771 : INFO : EPOCH 37 - PROGRESS: at 93.96% examples, 2319612 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:53,948 : INFO : EPOCH 37: training on 8234555 raw words (7443946 effective words) took 3.2s, 2330049 effective words/s\n",
      "2024-06-06 12:06:54,955 : INFO : EPOCH 38 - PROGRESS: at 31.20% examples, 2316128 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:55,962 : INFO : EPOCH 38 - PROGRESS: at 59.27% examples, 2187008 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:56,969 : INFO : EPOCH 38 - PROGRESS: at 87.02% examples, 2147236 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:06:57,465 : INFO : EPOCH 38: training on 8234555 raw words (7443302 effective words) took 3.5s, 2117044 effective words/s\n",
      "2024-06-06 12:06:58,470 : INFO : EPOCH 39 - PROGRESS: at 29.61% examples, 2203078 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:06:59,475 : INFO : EPOCH 39 - PROGRESS: at 60.75% examples, 2248173 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:07:00,477 : INFO : EPOCH 39 - PROGRESS: at 91.92% examples, 2273683 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:07:00,719 : INFO : EPOCH 39: training on 8234555 raw words (7443840 effective words) took 3.3s, 2289028 effective words/s\n",
      "2024-06-06 12:07:00,719 : INFO : Doc2Vec lifecycle event {'msg': 'training on 329382200 raw words (297746437 effective words) took 173.0s, 1720614 effective words/s', 'datetime': '2024-06-06T12:07:00.719640', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:19:07,377 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w20,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:19:07.377093', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:19:07,377 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:19:07,377 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 20, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:19:08,164 : INFO : PROGRESS: at example #10000, processed 8060579 words (10253583 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:19:08,181 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:19:08,181 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:19:08,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:19:08.246801', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:19:08,247 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:19:08.247171', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:19:08,337 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:19:08,338 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:19:08,339 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:19:08.339346', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:19:08,478 : INFO : estimated required memory for 40031 words and 400 dimensions: 166512500 bytes\n",
      "2024-06-06 12:19:08,478 : INFO : resetting layer weights\n",
      "2024-06-06 12:19:08,540 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=20 shrink_windows=True', 'datetime': '2024-06-06T12:19:08.540088', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:19:09,543 : INFO : EPOCH 0 - PROGRESS: at 18.40% examples, 1372195 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:10,546 : INFO : EPOCH 0 - PROGRESS: at 36.18% examples, 1345422 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:19:11,553 : INFO : EPOCH 0 - PROGRESS: at 54.82% examples, 1350870 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:12,556 : INFO : EPOCH 0 - PROGRESS: at 71.69% examples, 1330997 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:13,561 : INFO : EPOCH 0 - PROGRESS: at 90.22% examples, 1338076 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:14,189 : INFO : EPOCH 0: training on 8234555 raw words (7443277 effective words) took 5.6s, 1318115 effective words/s\n",
      "2024-06-06 12:19:15,201 : INFO : EPOCH 1 - PROGRESS: at 12.73% examples, 931433 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:16,207 : INFO : EPOCH 1 - PROGRESS: at 28.37% examples, 1045070 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:17,210 : INFO : EPOCH 1 - PROGRESS: at 40.70% examples, 1002865 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:18,222 : INFO : EPOCH 1 - PROGRESS: at 57.92% examples, 1066446 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 12:19:19,225 : INFO : EPOCH 1 - PROGRESS: at 74.73% examples, 1105396 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:20,227 : INFO : EPOCH 1 - PROGRESS: at 91.36% examples, 1126993 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:20,927 : INFO : EPOCH 1: training on 8234555 raw words (7443790 effective words) took 6.7s, 1105104 effective words/s\n",
      "2024-06-06 12:19:21,929 : INFO : EPOCH 2 - PROGRESS: at 16.88% examples, 1256010 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:22,929 : INFO : EPOCH 2 - PROGRESS: at 31.43% examples, 1173073 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:23,940 : INFO : EPOCH 2 - PROGRESS: at 47.23% examples, 1167785 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:24,942 : INFO : EPOCH 2 - PROGRESS: at 63.81% examples, 1180867 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:25,946 : INFO : EPOCH 2 - PROGRESS: at 79.67% examples, 1181436 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:26,950 : INFO : EPOCH 2 - PROGRESS: at 98.26% examples, 1215622 words/s, in_qsize 15, out_qsize 0\n",
      "2024-06-06 12:19:27,026 : INFO : EPOCH 2: training on 8234555 raw words (7444322 effective words) took 6.1s, 1220823 effective words/s\n",
      "2024-06-06 12:19:28,030 : INFO : EPOCH 3 - PROGRESS: at 19.66% examples, 1465833 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:29,032 : INFO : EPOCH 3 - PROGRESS: at 36.30% examples, 1349108 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:30,033 : INFO : EPOCH 3 - PROGRESS: at 53.20% examples, 1315812 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:31,034 : INFO : EPOCH 3 - PROGRESS: at 70.91% examples, 1316743 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:32,034 : INFO : EPOCH 3 - PROGRESS: at 90.16% examples, 1341415 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:32,543 : INFO : EPOCH 3: training on 8234555 raw words (7443856 effective words) took 5.5s, 1349661 effective words/s\n",
      "2024-06-06 12:19:33,545 : INFO : EPOCH 4 - PROGRESS: at 13.29% examples, 982286 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:34,562 : INFO : EPOCH 4 - PROGRESS: at 29.83% examples, 1104110 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:35,565 : INFO : EPOCH 4 - PROGRESS: at 46.19% examples, 1138288 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:36,569 : INFO : EPOCH 4 - PROGRESS: at 61.21% examples, 1130334 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:37,578 : INFO : EPOCH 4 - PROGRESS: at 80.90% examples, 1196339 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:38,604 : INFO : EPOCH 4 - PROGRESS: at 98.87% examples, 1215999 words/s, in_qsize 9, out_qsize 1\n",
      "2024-06-06 12:19:38,667 : INFO : EPOCH 4: training on 8234555 raw words (7443586 effective words) took 6.1s, 1215863 effective words/s\n",
      "2024-06-06 12:19:39,673 : INFO : EPOCH 5 - PROGRESS: at 16.77% examples, 1243787 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:40,676 : INFO : EPOCH 5 - PROGRESS: at 34.58% examples, 1283535 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:19:41,679 : INFO : EPOCH 5 - PROGRESS: at 52.61% examples, 1299480 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:42,682 : INFO : EPOCH 5 - PROGRESS: at 67.38% examples, 1246982 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:43,684 : INFO : EPOCH 5 - PROGRESS: at 84.13% examples, 1250326 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:44,670 : INFO : EPOCH 5: training on 8234555 raw words (7443633 effective words) took 6.0s, 1240359 effective words/s\n",
      "2024-06-06 12:19:45,675 : INFO : EPOCH 6 - PROGRESS: at 15.21% examples, 1116871 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:46,686 : INFO : EPOCH 6 - PROGRESS: at 29.80% examples, 1106139 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:47,694 : INFO : EPOCH 6 - PROGRESS: at 45.64% examples, 1123454 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:48,695 : INFO : EPOCH 6 - PROGRESS: at 64.32% examples, 1188620 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:49,695 : INFO : EPOCH 6 - PROGRESS: at 84.17% examples, 1248556 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:50,706 : INFO : EPOCH 6 - PROGRESS: at 97.71% examples, 1206050 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:50,810 : INFO : EPOCH 6: training on 8234555 raw words (7443345 effective words) took 6.1s, 1212783 effective words/s\n",
      "2024-06-06 12:19:51,817 : INFO : EPOCH 7 - PROGRESS: at 17.28% examples, 1283395 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:52,817 : INFO : EPOCH 7 - PROGRESS: at 32.53% examples, 1208671 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:53,822 : INFO : EPOCH 7 - PROGRESS: at 48.51% examples, 1199155 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:54,827 : INFO : EPOCH 7 - PROGRESS: at 64.10% examples, 1186311 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:19:55,828 : INFO : EPOCH 7 - PROGRESS: at 80.90% examples, 1200369 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:56,835 : INFO : EPOCH 7 - PROGRESS: at 95.19% examples, 1176473 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:57,087 : INFO : EPOCH 7: training on 8234555 raw words (7443972 effective words) took 6.3s, 1186120 effective words/s\n",
      "2024-06-06 12:19:58,094 : INFO : EPOCH 8 - PROGRESS: at 18.04% examples, 1342898 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:19:59,098 : INFO : EPOCH 8 - PROGRESS: at 32.43% examples, 1202165 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:00,109 : INFO : EPOCH 8 - PROGRESS: at 48.63% examples, 1198295 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:01,113 : INFO : EPOCH 8 - PROGRESS: at 65.36% examples, 1207303 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:02,117 : INFO : EPOCH 8 - PROGRESS: at 83.28% examples, 1233935 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:03,127 : INFO : EPOCH 8 - PROGRESS: at 98.71% examples, 1218202 words/s, in_qsize 11, out_qsize 0\n",
      "2024-06-06 12:20:03,180 : INFO : EPOCH 8: training on 8234555 raw words (7444308 effective words) took 6.1s, 1222260 effective words/s\n",
      "2024-06-06 12:20:04,184 : INFO : EPOCH 9 - PROGRESS: at 12.45% examples, 914779 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:05,184 : INFO : EPOCH 9 - PROGRESS: at 26.89% examples, 996820 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:06,186 : INFO : EPOCH 9 - PROGRESS: at 45.39% examples, 1124370 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:07,194 : INFO : EPOCH 9 - PROGRESS: at 64.45% examples, 1193828 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:08,202 : INFO : EPOCH 9 - PROGRESS: at 80.87% examples, 1199496 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:09,206 : INFO : EPOCH 9 - PROGRESS: at 97.17% examples, 1200985 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:09,334 : INFO : EPOCH 9: training on 8234555 raw words (7443713 effective words) took 6.2s, 1209999 effective words/s\n",
      "2024-06-06 12:20:10,346 : INFO : EPOCH 10 - PROGRESS: at 16.65% examples, 1226079 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:11,349 : INFO : EPOCH 10 - PROGRESS: at 30.08% examples, 1114145 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:20:12,353 : INFO : EPOCH 10 - PROGRESS: at 47.51% examples, 1170617 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:13,356 : INFO : EPOCH 10 - PROGRESS: at 63.38% examples, 1170200 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:14,367 : INFO : EPOCH 10 - PROGRESS: at 77.99% examples, 1151977 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:15,372 : INFO : EPOCH 10 - PROGRESS: at 90.29% examples, 1113857 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:15,930 : INFO : EPOCH 10: training on 8234555 raw words (7444013 effective words) took 6.6s, 1128786 effective words/s\n",
      "2024-06-06 12:20:16,939 : INFO : EPOCH 11 - PROGRESS: at 15.16% examples, 1113026 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:17,964 : INFO : EPOCH 11 - PROGRESS: at 30.51% examples, 1121811 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:18,968 : INFO : EPOCH 11 - PROGRESS: at 47.64% examples, 1166676 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:19,975 : INFO : EPOCH 11 - PROGRESS: at 66.22% examples, 1216647 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:20,977 : INFO : EPOCH 11 - PROGRESS: at 84.04% examples, 1241343 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:21,966 : INFO : EPOCH 11: training on 8234555 raw words (7443366 effective words) took 6.0s, 1233749 effective words/s\n",
      "2024-06-06 12:20:22,975 : INFO : EPOCH 12 - PROGRESS: at 15.21% examples, 1111583 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:23,980 : INFO : EPOCH 12 - PROGRESS: at 30.27% examples, 1123804 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:24,991 : INFO : EPOCH 12 - PROGRESS: at 43.50% examples, 1071883 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:25,993 : INFO : EPOCH 12 - PROGRESS: at 59.71% examples, 1101791 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:26,995 : INFO : EPOCH 12 - PROGRESS: at 75.28% examples, 1115595 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:28,005 : INFO : EPOCH 12 - PROGRESS: at 93.99% examples, 1159253 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:28,301 : INFO : EPOCH 12: training on 8234555 raw words (7443243 effective words) took 6.3s, 1175267 effective words/s\n",
      "2024-06-06 12:20:29,306 : INFO : EPOCH 13 - PROGRESS: at 15.19% examples, 1115926 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:30,306 : INFO : EPOCH 13 - PROGRESS: at 31.33% examples, 1166740 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:31,310 : INFO : EPOCH 13 - PROGRESS: at 49.23% examples, 1217730 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:32,314 : INFO : EPOCH 13 - PROGRESS: at 67.74% examples, 1253761 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:33,323 : INFO : EPOCH 13 - PROGRESS: at 85.94% examples, 1276986 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:34,262 : INFO : EPOCH 13: training on 8234555 raw words (7444348 effective words) took 6.0s, 1249163 effective words/s\n",
      "2024-06-06 12:20:35,264 : INFO : EPOCH 14 - PROGRESS: at 15.97% examples, 1187929 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:36,265 : INFO : EPOCH 14 - PROGRESS: at 32.86% examples, 1223743 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:37,268 : INFO : EPOCH 14 - PROGRESS: at 48.10% examples, 1190129 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:38,275 : INFO : EPOCH 14 - PROGRESS: at 63.48% examples, 1175150 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:39,286 : INFO : EPOCH 14 - PROGRESS: at 81.90% examples, 1214285 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:40,293 : INFO : EPOCH 14 - PROGRESS: at 98.37% examples, 1215381 words/s, in_qsize 14, out_qsize 0\n",
      "2024-06-06 12:20:40,448 : INFO : EPOCH 14: training on 8234555 raw words (7443726 effective words) took 6.2s, 1203610 effective words/s\n",
      "2024-06-06 12:20:41,451 : INFO : EPOCH 15 - PROGRESS: at 16.77% examples, 1247412 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:42,453 : INFO : EPOCH 15 - PROGRESS: at 33.21% examples, 1235220 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:43,453 : INFO : EPOCH 15 - PROGRESS: at 49.65% examples, 1231064 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:44,456 : INFO : EPOCH 15 - PROGRESS: at 67.97% examples, 1259933 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:45,463 : INFO : EPOCH 15 - PROGRESS: at 83.57% examples, 1242365 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:46,471 : INFO : EPOCH 15 - PROGRESS: at 97.49% examples, 1205696 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:46,625 : INFO : EPOCH 15: training on 8234555 raw words (7443387 effective words) took 6.2s, 1205582 effective words/s\n",
      "2024-06-06 12:20:47,629 : INFO : EPOCH 16 - PROGRESS: at 14.24% examples, 1047846 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:48,638 : INFO : EPOCH 16 - PROGRESS: at 29.31% examples, 1085420 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:49,640 : INFO : EPOCH 16 - PROGRESS: at 42.03% examples, 1039106 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:50,646 : INFO : EPOCH 16 - PROGRESS: at 52.23% examples, 966480 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:51,650 : INFO : EPOCH 16 - PROGRESS: at 65.26% examples, 965353 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:52,655 : INFO : EPOCH 16 - PROGRESS: at 76.96% examples, 949811 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:53,670 : INFO : EPOCH 16 - PROGRESS: at 88.66% examples, 937542 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:54,586 : INFO : EPOCH 16: training on 8234555 raw words (7442999 effective words) took 8.0s, 935063 effective words/s\n",
      "2024-06-06 12:20:55,618 : INFO : EPOCH 17 - PROGRESS: at 12.67% examples, 906569 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:56,618 : INFO : EPOCH 17 - PROGRESS: at 23.57% examples, 863678 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:20:57,626 : INFO : EPOCH 17 - PROGRESS: at 34.58% examples, 848188 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:58,641 : INFO : EPOCH 17 - PROGRESS: at 47.12% examples, 865358 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:20:59,646 : INFO : EPOCH 17 - PROGRESS: at 60.73% examples, 892604 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:21:00,650 : INFO : EPOCH 17 - PROGRESS: at 75.38% examples, 926544 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:01,661 : INFO : EPOCH 17 - PROGRESS: at 91.13% examples, 959356 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:02,249 : INFO : EPOCH 17: training on 8234555 raw words (7443387 effective words) took 7.7s, 971688 effective words/s\n",
      "2024-06-06 12:21:03,258 : INFO : EPOCH 18 - PROGRESS: at 12.78% examples, 935468 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:21:04,258 : INFO : EPOCH 18 - PROGRESS: at 26.12% examples, 964402 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:05,264 : INFO : EPOCH 18 - PROGRESS: at 41.69% examples, 1030815 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:06,273 : INFO : EPOCH 18 - PROGRESS: at 54.31% examples, 1002789 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:07,280 : INFO : EPOCH 18 - PROGRESS: at 70.47% examples, 1042241 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:08,290 : INFO : EPOCH 18 - PROGRESS: at 85.21% examples, 1051280 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:09,104 : INFO : EPOCH 18: training on 8234555 raw words (7443224 effective words) took 6.9s, 1086124 effective words/s\n",
      "2024-06-06 12:21:10,109 : INFO : EPOCH 19 - PROGRESS: at 19.53% examples, 1455410 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 12:21:11,113 : INFO : EPOCH 19 - PROGRESS: at 40.09% examples, 1482856 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:12,118 : INFO : EPOCH 19 - PROGRESS: at 58.29% examples, 1435869 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:13,121 : INFO : EPOCH 19 - PROGRESS: at 76.64% examples, 1419874 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:14,121 : INFO : EPOCH 19 - PROGRESS: at 95.58% examples, 1419606 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:21:14,324 : INFO : EPOCH 19: training on 8234555 raw words (7443498 effective words) took 5.2s, 1426417 effective words/s\n",
      "2024-06-06 12:21:14,324 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148872993 effective words) took 125.8s, 1183561 effective words/s', 'datetime': '2024-06-06T12:21:14.324970', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:28:51,942 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w20,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:28:51.942557', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:28:51,942 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:28:51,943 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 100, 'window': 20, 'min_count': 2, 'epochs': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:28:52,671 : INFO : PROGRESS: at example #10000, processed 8060579 words (11076746 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:28:52,688 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:28:52,688 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:28:52,747 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:28:52.747101', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:28:52,747 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:28:52.747637', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:28:52,822 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:28:52,823 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:28:52,823 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:28:52.823388', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:28:52,957 : INFO : estimated required memory for 40031 words and 100 dimensions: 58172900 bytes\n",
      "2024-06-06 12:28:52,957 : INFO : resetting layer weights\n",
      "2024-06-06 12:28:52,971 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=20 shrink_windows=True', 'datetime': '2024-06-06T12:28:52.971470', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:28:53,983 : INFO : EPOCH 0 - PROGRESS: at 29.91% examples, 2216033 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:28:54,987 : INFO : EPOCH 0 - PROGRESS: at 63.04% examples, 2324582 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:28:55,989 : INFO : EPOCH 0 - PROGRESS: at 91.02% examples, 2247357 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:28:56,353 : INFO : EPOCH 0: training on 8234555 raw words (7443658 effective words) took 3.4s, 2202713 effective words/s\n",
      "2024-06-06 12:28:57,358 : INFO : EPOCH 1 - PROGRESS: at 25.74% examples, 1903779 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:28:58,361 : INFO : EPOCH 1 - PROGRESS: at 50.48% examples, 1871180 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:28:59,361 : INFO : EPOCH 1 - PROGRESS: at 75.86% examples, 1879430 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:29:00,237 : INFO : EPOCH 1: training on 8234555 raw words (7443590 effective words) took 3.9s, 1917335 effective words/s\n",
      "2024-06-06 12:29:01,243 : INFO : EPOCH 2 - PROGRESS: at 27.71% examples, 2047863 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:02,253 : INFO : EPOCH 2 - PROGRESS: at 57.28% examples, 2109041 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:03,253 : INFO : EPOCH 2 - PROGRESS: at 89.66% examples, 2213757 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:03,559 : INFO : EPOCH 2: training on 8234555 raw words (7443684 effective words) took 3.3s, 2241892 effective words/s\n",
      "2024-06-06 12:29:04,562 : INFO : EPOCH 3 - PROGRESS: at 32.86% examples, 2445208 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:05,566 : INFO : EPOCH 3 - PROGRESS: at 62.22% examples, 2303644 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:06,570 : INFO : EPOCH 3 - PROGRESS: at 90.89% examples, 2248459 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:06,871 : INFO : EPOCH 3: training on 8234555 raw words (7443700 effective words) took 3.3s, 2248290 effective words/s\n",
      "2024-06-06 12:29:07,876 : INFO : EPOCH 4 - PROGRESS: at 25.13% examples, 1860978 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:08,879 : INFO : EPOCH 4 - PROGRESS: at 54.07% examples, 2002050 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:09,883 : INFO : EPOCH 4 - PROGRESS: at 82.91% examples, 2052269 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:10,428 : INFO : EPOCH 4: training on 8234555 raw words (7444247 effective words) took 3.6s, 2093835 effective words/s\n",
      "2024-06-06 12:29:11,432 : INFO : EPOCH 5 - PROGRESS: at 27.37% examples, 2027164 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:12,433 : INFO : EPOCH 5 - PROGRESS: at 56.74% examples, 2100695 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:13,436 : INFO : EPOCH 5 - PROGRESS: at 80.89% examples, 2003607 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:14,134 : INFO : EPOCH 5: training on 8234555 raw words (7443251 effective words) took 3.7s, 2009932 effective words/s\n",
      "2024-06-06 12:29:15,141 : INFO : EPOCH 6 - PROGRESS: at 28.21% examples, 2085372 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:16,143 : INFO : EPOCH 6 - PROGRESS: at 56.36% examples, 2082668 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:17,144 : INFO : EPOCH 6 - PROGRESS: at 83.89% examples, 2079003 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:17,684 : INFO : EPOCH 6: training on 8234555 raw words (7443537 effective words) took 3.5s, 2097852 effective words/s\n",
      "2024-06-06 12:29:18,687 : INFO : EPOCH 7 - PROGRESS: at 28.46% examples, 2121250 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:19,688 : INFO : EPOCH 7 - PROGRESS: at 60.41% examples, 2241094 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:20,698 : INFO : EPOCH 7 - PROGRESS: at 93.86% examples, 2321120 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:29:20,900 : INFO : EPOCH 7: training on 8234555 raw words (7444166 effective words) took 3.2s, 2316102 effective words/s\n",
      "2024-06-06 12:29:21,905 : INFO : EPOCH 8 - PROGRESS: at 29.52% examples, 2193671 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:22,906 : INFO : EPOCH 8 - PROGRESS: at 58.52% examples, 2166532 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:23,918 : INFO : EPOCH 8 - PROGRESS: at 85.84% examples, 2121716 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:24,431 : INFO : EPOCH 8: training on 8234555 raw words (7443791 effective words) took 3.5s, 2108756 effective words/s\n",
      "2024-06-06 12:29:25,433 : INFO : EPOCH 9 - PROGRESS: at 28.65% examples, 2131446 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:26,441 : INFO : EPOCH 9 - PROGRESS: at 55.65% examples, 2054232 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:27,450 : INFO : EPOCH 9 - PROGRESS: at 82.76% examples, 2044002 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:28,043 : INFO : EPOCH 9: training on 8234555 raw words (7443778 effective words) took 3.6s, 2061562 effective words/s\n",
      "2024-06-06 12:29:29,047 : INFO : EPOCH 10 - PROGRESS: at 28.94% examples, 2152524 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:30,052 : INFO : EPOCH 10 - PROGRESS: at 61.48% examples, 2274555 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:31,055 : INFO : EPOCH 10 - PROGRESS: at 89.46% examples, 2210648 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:31,407 : INFO : EPOCH 10: training on 8234555 raw words (7442955 effective words) took 3.4s, 2213724 effective words/s\n",
      "2024-06-06 12:29:32,409 : INFO : EPOCH 11 - PROGRESS: at 28.01% examples, 2079632 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:33,409 : INFO : EPOCH 11 - PROGRESS: at 59.71% examples, 2216883 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:34,410 : INFO : EPOCH 11 - PROGRESS: at 87.89% examples, 2179903 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:34,800 : INFO : EPOCH 11: training on 8234555 raw words (7443454 effective words) took 3.4s, 2194738 effective words/s\n",
      "2024-06-06 12:29:35,808 : INFO : EPOCH 12 - PROGRESS: at 29.19% examples, 2160066 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:29:36,813 : INFO : EPOCH 12 - PROGRESS: at 59.60% examples, 2200521 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:37,814 : INFO : EPOCH 12 - PROGRESS: at 93.15% examples, 2303196 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:38,011 : INFO : EPOCH 12: training on 8234555 raw words (7443932 effective words) took 3.2s, 2319609 effective words/s\n",
      "2024-06-06 12:29:39,012 : INFO : EPOCH 13 - PROGRESS: at 33.09% examples, 2464253 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:40,017 : INFO : EPOCH 13 - PROGRESS: at 61.93% examples, 2295056 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:41,017 : INFO : EPOCH 13 - PROGRESS: at 91.35% examples, 2263202 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:41,292 : INFO : EPOCH 13: training on 8234555 raw words (7443946 effective words) took 3.3s, 2269423 effective words/s\n",
      "2024-06-06 12:29:42,296 : INFO : EPOCH 14 - PROGRESS: at 25.71% examples, 1904033 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:43,300 : INFO : EPOCH 14 - PROGRESS: at 59.04% examples, 2184557 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:44,303 : INFO : EPOCH 14 - PROGRESS: at 88.01% examples, 2177200 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:44,715 : INFO : EPOCH 14: training on 8234555 raw words (7443926 effective words) took 3.4s, 2175435 effective words/s\n",
      "2024-06-06 12:29:45,724 : INFO : EPOCH 15 - PROGRESS: at 29.06% examples, 2152092 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:46,727 : INFO : EPOCH 15 - PROGRESS: at 58.29% examples, 2151463 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:47,735 : INFO : EPOCH 15 - PROGRESS: at 86.62% examples, 2140142 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:48,168 : INFO : EPOCH 15: training on 8234555 raw words (7443118 effective words) took 3.5s, 2156904 effective words/s\n",
      "2024-06-06 12:29:49,171 : INFO : EPOCH 16 - PROGRESS: at 28.71% examples, 2136505 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:50,173 : INFO : EPOCH 16 - PROGRESS: at 60.86% examples, 2257622 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:51,178 : INFO : EPOCH 16 - PROGRESS: at 91.13% examples, 2254980 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:51,482 : INFO : EPOCH 16: training on 8234555 raw words (7443527 effective words) took 3.3s, 2247444 effective words/s\n",
      "2024-06-06 12:29:52,488 : INFO : EPOCH 17 - PROGRESS: at 29.04% examples, 2156614 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:53,489 : INFO : EPOCH 17 - PROGRESS: at 58.16% examples, 2151874 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:54,491 : INFO : EPOCH 17 - PROGRESS: at 91.43% examples, 2264274 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:54,736 : INFO : EPOCH 17: training on 8234555 raw words (7443275 effective words) took 3.3s, 2288459 effective words/s\n",
      "2024-06-06 12:29:55,742 : INFO : EPOCH 18 - PROGRESS: at 31.20% examples, 2318420 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:29:56,743 : INFO : EPOCH 18 - PROGRESS: at 59.85% examples, 2215575 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:57,746 : INFO : EPOCH 18 - PROGRESS: at 88.11% examples, 2180310 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:29:58,159 : INFO : EPOCH 18: training on 8234555 raw words (7443395 effective words) took 3.4s, 2175476 effective words/s\n",
      "2024-06-06 12:29:59,162 : INFO : EPOCH 19 - PROGRESS: at 28.13% examples, 2085618 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:00,180 : INFO : EPOCH 19 - PROGRESS: at 55.14% examples, 2026561 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:01,186 : INFO : EPOCH 19 - PROGRESS: at 80.78% examples, 1987348 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:01,829 : INFO : EPOCH 19: training on 8234555 raw words (7443783 effective words) took 3.7s, 2029122 effective words/s\n",
      "2024-06-06 12:30:02,832 : INFO : EPOCH 20 - PROGRESS: at 29.19% examples, 2171487 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:03,835 : INFO : EPOCH 20 - PROGRESS: at 59.85% examples, 2217318 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:04,836 : INFO : EPOCH 20 - PROGRESS: at 87.76% examples, 2174756 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:05,232 : INFO : EPOCH 20: training on 8234555 raw words (7443656 effective words) took 3.4s, 2188375 effective words/s\n",
      "2024-06-06 12:30:06,236 : INFO : EPOCH 21 - PROGRESS: at 28.46% examples, 2118948 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:30:07,239 : INFO : EPOCH 21 - PROGRESS: at 59.04% examples, 2186452 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:08,243 : INFO : EPOCH 21 - PROGRESS: at 92.38% examples, 2285801 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 12:30:08,454 : INFO : EPOCH 21: training on 8234555 raw words (7443214 effective words) took 3.2s, 2310831 effective words/s\n",
      "2024-06-06 12:30:09,461 : INFO : EPOCH 22 - PROGRESS: at 32.15% examples, 2385036 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:10,463 : INFO : EPOCH 22 - PROGRESS: at 59.93% examples, 2218150 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:11,468 : INFO : EPOCH 22 - PROGRESS: at 87.13% examples, 2155517 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:11,932 : INFO : EPOCH 22: training on 8234555 raw words (7444191 effective words) took 3.5s, 2141146 effective words/s\n",
      "2024-06-06 12:30:12,935 : INFO : EPOCH 23 - PROGRESS: at 27.81% examples, 2060659 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:13,936 : INFO : EPOCH 23 - PROGRESS: at 56.75% examples, 2100691 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:14,938 : INFO : EPOCH 23 - PROGRESS: at 83.89% examples, 2081613 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:15,509 : INFO : EPOCH 23: training on 8234555 raw words (7443973 effective words) took 3.6s, 2081955 effective words/s\n",
      "2024-06-06 12:30:16,513 : INFO : EPOCH 24 - PROGRESS: at 29.19% examples, 2170134 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:17,515 : INFO : EPOCH 24 - PROGRESS: at 59.04% examples, 2187990 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:18,520 : INFO : EPOCH 24 - PROGRESS: at 87.41% examples, 2163795 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:18,967 : INFO : EPOCH 24: training on 8234555 raw words (7443643 effective words) took 3.5s, 2153922 effective words/s\n",
      "2024-06-06 12:30:19,977 : INFO : EPOCH 25 - PROGRESS: at 28.94% examples, 2139356 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:20,982 : INFO : EPOCH 25 - PROGRESS: at 60.27% examples, 2224259 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:21,986 : INFO : EPOCH 25 - PROGRESS: at 90.16% examples, 2225217 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:22,366 : INFO : EPOCH 25: training on 8234555 raw words (7442801 effective words) took 3.4s, 2190255 effective words/s\n",
      "2024-06-06 12:30:23,368 : INFO : EPOCH 26 - PROGRESS: at 27.91% examples, 2071702 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:24,374 : INFO : EPOCH 26 - PROGRESS: at 56.75% examples, 2096279 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:25,379 : INFO : EPOCH 26 - PROGRESS: at 88.54% examples, 2190050 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:25,806 : INFO : EPOCH 26: training on 8234555 raw words (7443310 effective words) took 3.4s, 2165142 effective words/s\n",
      "2024-06-06 12:30:26,816 : INFO : EPOCH 27 - PROGRESS: at 28.13% examples, 2071172 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:27,816 : INFO : EPOCH 27 - PROGRESS: at 55.77% examples, 2058452 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:28,816 : INFO : EPOCH 27 - PROGRESS: at 85.21% examples, 2109967 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:29,302 : INFO : EPOCH 27: training on 8234555 raw words (7443291 effective words) took 3.5s, 2129994 effective words/s\n",
      "2024-06-06 12:30:30,309 : INFO : EPOCH 28 - PROGRESS: at 26.55% examples, 1959487 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 12:30:31,315 : INFO : EPOCH 28 - PROGRESS: at 55.50% examples, 2046892 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:32,319 : INFO : EPOCH 28 - PROGRESS: at 84.99% examples, 2099803 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:30:32,777 : INFO : EPOCH 28: training on 8234555 raw words (7444081 effective words) took 3.5s, 2143269 effective words/s\n",
      "2024-06-06 12:30:33,780 : INFO : EPOCH 29 - PROGRESS: at 29.06% examples, 2161787 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:34,780 : INFO : EPOCH 29 - PROGRESS: at 57.18% examples, 2116756 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:35,781 : INFO : EPOCH 29 - PROGRESS: at 84.99% examples, 2107998 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:36,272 : INFO : EPOCH 29: training on 8234555 raw words (7442238 effective words) took 3.5s, 2130084 effective words/s\n",
      "2024-06-06 12:30:37,283 : INFO : EPOCH 30 - PROGRESS: at 30.51% examples, 2256051 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:38,286 : INFO : EPOCH 30 - PROGRESS: at 57.29% examples, 2111455 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:39,298 : INFO : EPOCH 30 - PROGRESS: at 85.83% examples, 2116479 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:39,783 : INFO : EPOCH 30: training on 8234555 raw words (7444125 effective words) took 3.5s, 2121249 effective words/s\n",
      "2024-06-06 12:30:40,791 : INFO : EPOCH 31 - PROGRESS: at 28.13% examples, 2076384 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:41,794 : INFO : EPOCH 31 - PROGRESS: at 57.94% examples, 2139942 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:42,795 : INFO : EPOCH 31 - PROGRESS: at 83.99% examples, 2080025 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:43,300 : INFO : EPOCH 31: training on 8234555 raw words (7444636 effective words) took 3.5s, 2117262 effective words/s\n",
      "2024-06-06 12:30:44,304 : INFO : EPOCH 32 - PROGRESS: at 28.82% examples, 2145197 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:45,306 : INFO : EPOCH 32 - PROGRESS: at 56.62% examples, 2095124 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:46,313 : INFO : EPOCH 32 - PROGRESS: at 84.01% examples, 2080410 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:46,880 : INFO : EPOCH 32: training on 8234555 raw words (7444594 effective words) took 3.6s, 2080732 effective words/s\n",
      "2024-06-06 12:30:47,882 : INFO : EPOCH 33 - PROGRESS: at 27.34% examples, 2029220 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:48,882 : INFO : EPOCH 33 - PROGRESS: at 55.50% examples, 2058639 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:49,884 : INFO : EPOCH 33 - PROGRESS: at 83.77% examples, 2079768 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:50,470 : INFO : EPOCH 33: training on 8234555 raw words (7443852 effective words) took 3.6s, 2074500 effective words/s\n",
      "2024-06-06 12:30:51,474 : INFO : EPOCH 34 - PROGRESS: at 28.65% examples, 2125596 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:52,478 : INFO : EPOCH 34 - PROGRESS: at 56.95% examples, 2104894 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:53,483 : INFO : EPOCH 34 - PROGRESS: at 88.43% examples, 2187073 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:53,820 : INFO : EPOCH 34: training on 8234555 raw words (7444061 effective words) took 3.3s, 2222954 effective words/s\n",
      "2024-06-06 12:30:54,828 : INFO : EPOCH 35 - PROGRESS: at 28.94% examples, 2144676 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:55,833 : INFO : EPOCH 35 - PROGRESS: at 58.41% examples, 2155171 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:56,834 : INFO : EPOCH 35 - PROGRESS: at 86.17% examples, 2133441 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:30:57,296 : INFO : EPOCH 35: training on 8234555 raw words (7444643 effective words) took 3.5s, 2142675 effective words/s\n",
      "2024-06-06 12:30:58,299 : INFO : EPOCH 36 - PROGRESS: at 27.36% examples, 2028079 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:30:59,303 : INFO : EPOCH 36 - PROGRESS: at 57.28% examples, 2117981 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:00,304 : INFO : EPOCH 36 - PROGRESS: at 90.42% examples, 2239409 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:31:00,576 : INFO : EPOCH 36: training on 8234555 raw words (7443039 effective words) took 3.3s, 2270330 effective words/s\n",
      "2024-06-06 12:31:01,583 : INFO : EPOCH 37 - PROGRESS: at 33.38% examples, 2477635 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:31:02,583 : INFO : EPOCH 37 - PROGRESS: at 67.04% examples, 2481826 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:03,588 : INFO : EPOCH 37 - PROGRESS: at 91.33% examples, 2258891 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:03,867 : INFO : EPOCH 37: training on 8234555 raw words (7443240 effective words) took 3.3s, 2262603 effective words/s\n",
      "2024-06-06 12:31:04,871 : INFO : EPOCH 38 - PROGRESS: at 28.94% examples, 2153138 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:05,873 : INFO : EPOCH 38 - PROGRESS: at 58.52% examples, 2167015 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:06,873 : INFO : EPOCH 38 - PROGRESS: at 85.83% examples, 2130715 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:07,340 : INFO : EPOCH 38: training on 8234555 raw words (7443756 effective words) took 3.5s, 2144773 effective words/s\n",
      "2024-06-06 12:31:08,343 : INFO : EPOCH 39 - PROGRESS: at 28.13% examples, 2084327 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:09,344 : INFO : EPOCH 39 - PROGRESS: at 60.17% examples, 2231691 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:31:10,356 : INFO : EPOCH 39 - PROGRESS: at 91.83% examples, 2267900 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:31:10,601 : INFO : EPOCH 39: training on 8234555 raw words (7443879 effective words) took 3.3s, 2283389 effective words/s\n",
      "2024-06-06 12:31:10,602 : INFO : Doc2Vec lifecycle event {'msg': 'training on 329382200 raw words (297746936 effective words) took 137.6s, 2163394 effective words/s', 'datetime': '2024-06-06T12:31:10.602049', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:39:31,802 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:39:31.802257', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:39:31,802 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:39:31,802 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:39:32,532 : INFO : PROGRESS: at example #10000, processed 8060579 words (11060258 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:39:32,550 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:39:32,551 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:39:32,612 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:39:32.612195', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:39:32,612 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:39:32.612576', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:39:32,683 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:39:32,683 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:39:32,684 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:39:32.684185', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:39:32,805 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 12:39:32,805 : INFO : resetting layer weights\n",
      "2024-06-06 12:39:32,835 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T12:39:32.835109', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:39:33,840 : INFO : EPOCH 0 - PROGRESS: at 33.67% examples, 2506456 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:34,840 : INFO : EPOCH 0 - PROGRESS: at 67.74% examples, 2510187 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:35,761 : INFO : EPOCH 0: training on 8234555 raw words (7443703 effective words) took 2.9s, 2543875 effective words/s\n",
      "2024-06-06 12:39:36,764 : INFO : EPOCH 1 - PROGRESS: at 34.82% examples, 2585848 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:37,771 : INFO : EPOCH 1 - PROGRESS: at 67.97% examples, 2510039 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:38,772 : INFO : EPOCH 1 - PROGRESS: at 94.54% examples, 2337170 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:38,935 : INFO : EPOCH 1: training on 8234555 raw words (7444030 effective words) took 3.2s, 2343517 effective words/s\n",
      "2024-06-06 12:39:39,936 : INFO : EPOCH 2 - PROGRESS: at 28.01% examples, 2078526 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:40,935 : INFO : EPOCH 2 - PROGRESS: at 55.64% examples, 2062060 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:41,935 : INFO : EPOCH 2 - PROGRESS: at 84.61% examples, 2100070 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:42,419 : INFO : EPOCH 2: training on 8234555 raw words (7444296 effective words) took 3.5s, 2134723 effective words/s\n",
      "2024-06-06 12:39:43,423 : INFO : EPOCH 3 - PROGRESS: at 29.52% examples, 2195277 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:44,426 : INFO : EPOCH 3 - PROGRESS: at 60.41% examples, 2235969 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:45,430 : INFO : EPOCH 3 - PROGRESS: at 91.13% examples, 2252671 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:45,679 : INFO : EPOCH 3: training on 8234555 raw words (7442992 effective words) took 3.3s, 2282745 effective words/s\n",
      "2024-06-06 12:39:46,685 : INFO : EPOCH 4 - PROGRESS: at 30.39% examples, 2256291 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:47,693 : INFO : EPOCH 4 - PROGRESS: at 62.18% examples, 2292611 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:48,693 : INFO : EPOCH 4 - PROGRESS: at 90.06% examples, 2224186 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:48,990 : INFO : EPOCH 4: training on 8234555 raw words (7444240 effective words) took 3.3s, 2247508 effective words/s\n",
      "2024-06-06 12:39:49,992 : INFO : EPOCH 5 - PROGRESS: at 30.15% examples, 2251526 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:50,996 : INFO : EPOCH 5 - PROGRESS: at 58.29% examples, 2157221 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:51,999 : INFO : EPOCH 5 - PROGRESS: at 88.30% examples, 2185653 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:52,401 : INFO : EPOCH 5: training on 8234555 raw words (7443668 effective words) took 3.4s, 2181958 effective words/s\n",
      "2024-06-06 12:39:53,404 : INFO : EPOCH 6 - PROGRESS: at 30.63% examples, 2281484 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:54,406 : INFO : EPOCH 6 - PROGRESS: at 60.99% examples, 2260843 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:55,406 : INFO : EPOCH 6 - PROGRESS: at 92.01% examples, 2281051 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:39:55,633 : INFO : EPOCH 6: training on 8234555 raw words (7443266 effective words) took 3.2s, 2303296 effective words/s\n",
      "2024-06-06 12:39:56,634 : INFO : EPOCH 7 - PROGRESS: at 29.80% examples, 2226123 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:57,638 : INFO : EPOCH 7 - PROGRESS: at 61.48% examples, 2277282 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:58,642 : INFO : EPOCH 7 - PROGRESS: at 93.29% examples, 2308172 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:39:58,867 : INFO : EPOCH 7: training on 8234555 raw words (7442874 effective words) took 3.2s, 2301374 effective words/s\n",
      "2024-06-06 12:39:59,869 : INFO : EPOCH 8 - PROGRESS: at 34.25% examples, 2555565 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:00,871 : INFO : EPOCH 8 - PROGRESS: at 70.54% examples, 2620988 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:01,759 : INFO : EPOCH 8: training on 8234555 raw words (7443639 effective words) took 2.9s, 2574517 effective words/s\n",
      "2024-06-06 12:40:02,761 : INFO : EPOCH 9 - PROGRESS: at 30.98% examples, 2309028 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:03,763 : INFO : EPOCH 9 - PROGRESS: at 63.11% examples, 2340145 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:04,768 : INFO : EPOCH 9 - PROGRESS: at 92.85% examples, 2298438 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:05,006 : INFO : EPOCH 9: training on 8234555 raw words (7444430 effective words) took 3.2s, 2293178 effective words/s\n",
      "2024-06-06 12:40:06,009 : INFO : EPOCH 10 - PROGRESS: at 30.63% examples, 2283963 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:07,016 : INFO : EPOCH 10 - PROGRESS: at 62.22% examples, 2299178 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:08,021 : INFO : EPOCH 10 - PROGRESS: at 93.26% examples, 2305182 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:08,236 : INFO : EPOCH 10: training on 8234555 raw words (7443528 effective words) took 3.2s, 2305156 effective words/s\n",
      "2024-06-06 12:40:09,240 : INFO : EPOCH 11 - PROGRESS: at 31.43% examples, 2341150 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:10,242 : INFO : EPOCH 11 - PROGRESS: at 64.22% examples, 2381518 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:11,246 : INFO : EPOCH 11 - PROGRESS: at 93.54% examples, 2315026 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:11,429 : INFO : EPOCH 11: training on 8234555 raw words (7443762 effective words) took 3.2s, 2332490 effective words/s\n",
      "2024-06-06 12:40:12,436 : INFO : EPOCH 12 - PROGRESS: at 32.29% examples, 2392935 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:13,441 : INFO : EPOCH 12 - PROGRESS: at 64.89% examples, 2398616 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:14,441 : INFO : EPOCH 12 - PROGRESS: at 95.67% examples, 2367085 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:14,560 : INFO : EPOCH 12: training on 8234555 raw words (7443510 effective words) took 3.1s, 2378145 effective words/s\n",
      "2024-06-06 12:40:15,564 : INFO : EPOCH 13 - PROGRESS: at 31.21% examples, 2323804 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:16,566 : INFO : EPOCH 13 - PROGRESS: at 62.43% examples, 2312961 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:17,569 : INFO : EPOCH 13 - PROGRESS: at 92.39% examples, 2287249 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:17,795 : INFO : EPOCH 13: training on 8234555 raw words (7444243 effective words) took 3.2s, 2302063 effective words/s\n",
      "2024-06-06 12:40:18,796 : INFO : EPOCH 14 - PROGRESS: at 28.72% examples, 2140476 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:40:19,800 : INFO : EPOCH 14 - PROGRESS: at 59.38% examples, 2200269 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:40:20,800 : INFO : EPOCH 14 - PROGRESS: at 91.35% examples, 2264172 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:21,060 : INFO : EPOCH 14: training on 8234555 raw words (7443111 effective words) took 3.3s, 2280395 effective words/s\n",
      "2024-06-06 12:40:22,065 : INFO : EPOCH 15 - PROGRESS: at 33.29% examples, 2473363 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:23,066 : INFO : EPOCH 15 - PROGRESS: at 65.26% examples, 2418938 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:24,076 : INFO : EPOCH 15 - PROGRESS: at 97.03% examples, 2396447 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:24,150 : INFO : EPOCH 15: training on 8234555 raw words (7443830 effective words) took 3.1s, 2410348 effective words/s\n",
      "2024-06-06 12:40:25,164 : INFO : EPOCH 16 - PROGRESS: at 31.08% examples, 2288426 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:26,166 : INFO : EPOCH 16 - PROGRESS: at 62.45% examples, 2299865 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:27,166 : INFO : EPOCH 16 - PROGRESS: at 91.48% examples, 2258046 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:27,417 : INFO : EPOCH 16: training on 8234555 raw words (7442516 effective words) took 3.3s, 2278658 effective words/s\n",
      "2024-06-06 12:40:28,423 : INFO : EPOCH 17 - PROGRESS: at 30.51% examples, 2269530 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:29,427 : INFO : EPOCH 17 - PROGRESS: at 62.91% examples, 2325041 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:30,427 : INFO : EPOCH 17 - PROGRESS: at 95.66% examples, 2369403 words/s, in_qsize 17, out_qsize 2\n",
      "2024-06-06 12:40:30,529 : INFO : EPOCH 17: training on 8234555 raw words (7443915 effective words) took 3.1s, 2392663 effective words/s\n",
      "2024-06-06 12:40:31,534 : INFO : EPOCH 18 - PROGRESS: at 35.49% examples, 2636845 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:32,539 : INFO : EPOCH 18 - PROGRESS: at 68.51% examples, 2534703 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:33,524 : INFO : EPOCH 18: training on 8234555 raw words (7444063 effective words) took 3.0s, 2486770 effective words/s\n",
      "2024-06-06 12:40:34,527 : INFO : EPOCH 19 - PROGRESS: at 31.55% examples, 2350215 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:35,533 : INFO : EPOCH 19 - PROGRESS: at 63.15% examples, 2334489 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:36,535 : INFO : EPOCH 19 - PROGRESS: at 94.21% examples, 2330889 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:36,704 : INFO : EPOCH 19: training on 8234555 raw words (7442436 effective words) took 3.2s, 2341235 effective words/s\n",
      "2024-06-06 12:40:37,710 : INFO : EPOCH 20 - PROGRESS: at 32.03% examples, 2379554 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:38,712 : INFO : EPOCH 20 - PROGRESS: at 62.45% examples, 2310371 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:39,719 : INFO : EPOCH 20 - PROGRESS: at 94.67% examples, 2339861 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:39,862 : INFO : EPOCH 20: training on 8234555 raw words (7443772 effective words) took 3.2s, 2358284 effective words/s\n",
      "2024-06-06 12:40:40,866 : INFO : EPOCH 21 - PROGRESS: at 31.08% examples, 2314308 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:41,866 : INFO : EPOCH 21 - PROGRESS: at 63.26% examples, 2345058 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:42,869 : INFO : EPOCH 21 - PROGRESS: at 94.10% examples, 2331670 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:43,035 : INFO : EPOCH 21: training on 8234555 raw words (7444264 effective words) took 3.2s, 2347399 effective words/s\n",
      "2024-06-06 12:40:44,036 : INFO : EPOCH 22 - PROGRESS: at 30.85% examples, 2302786 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:45,044 : INFO : EPOCH 22 - PROGRESS: at 62.68% examples, 2317571 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:40:46,050 : INFO : EPOCH 22 - PROGRESS: at 90.64% examples, 2239816 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:46,334 : INFO : EPOCH 22: training on 8234555 raw words (7443832 effective words) took 3.3s, 2257170 effective words/s\n",
      "2024-06-06 12:40:47,344 : INFO : EPOCH 23 - PROGRESS: at 33.21% examples, 2455039 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:40:48,345 : INFO : EPOCH 23 - PROGRESS: at 67.85% examples, 2508602 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:49,305 : INFO : EPOCH 23: training on 8234555 raw words (7443477 effective words) took 3.0s, 2507961 effective words/s\n",
      "2024-06-06 12:40:50,311 : INFO : EPOCH 24 - PROGRESS: at 33.32% examples, 2470027 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:51,311 : INFO : EPOCH 24 - PROGRESS: at 69.02% examples, 2559469 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:52,314 : INFO : EPOCH 24 - PROGRESS: at 98.25% examples, 2433479 words/s, in_qsize 15, out_qsize 0\n",
      "2024-06-06 12:40:52,350 : INFO : EPOCH 24: training on 8234555 raw words (7444214 effective words) took 3.0s, 2445334 effective words/s\n",
      "2024-06-06 12:40:53,354 : INFO : EPOCH 25 - PROGRESS: at 32.41% examples, 2410750 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:54,357 : INFO : EPOCH 25 - PROGRESS: at 64.66% examples, 2396991 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:55,315 : INFO : EPOCH 25: training on 8234555 raw words (7444333 effective words) took 3.0s, 2511914 effective words/s\n",
      "2024-06-06 12:40:56,319 : INFO : EPOCH 26 - PROGRESS: at 35.85% examples, 2666451 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:57,319 : INFO : EPOCH 26 - PROGRESS: at 70.12% examples, 2604592 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:40:58,253 : INFO : EPOCH 26: training on 8234555 raw words (7444070 effective words) took 2.9s, 2535046 effective words/s\n",
      "2024-06-06 12:40:59,260 : INFO : EPOCH 27 - PROGRESS: at 28.94% examples, 2147829 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:00,274 : INFO : EPOCH 27 - PROGRESS: at 58.16% examples, 2138248 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:01,276 : INFO : EPOCH 27 - PROGRESS: at 89.32% examples, 2200463 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:01,598 : INFO : EPOCH 27: training on 8234555 raw words (7444365 effective words) took 3.3s, 2226632 effective words/s\n",
      "2024-06-06 12:41:02,612 : INFO : EPOCH 28 - PROGRESS: at 33.41% examples, 2459300 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:03,616 : INFO : EPOCH 28 - PROGRESS: at 66.79% examples, 2460161 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:04,618 : INFO : EPOCH 28 - PROGRESS: at 95.71% examples, 2362074 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:04,734 : INFO : EPOCH 28: training on 8234555 raw words (7443739 effective words) took 3.1s, 2374720 effective words/s\n",
      "2024-06-06 12:41:05,736 : INFO : EPOCH 29 - PROGRESS: at 31.67% examples, 2363501 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:06,740 : INFO : EPOCH 29 - PROGRESS: at 62.91% examples, 2330774 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:07,744 : INFO : EPOCH 29 - PROGRESS: at 93.96% examples, 2326581 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:07,913 : INFO : EPOCH 29: training on 8234555 raw words (7443763 effective words) took 3.2s, 2342957 effective words/s\n",
      "2024-06-06 12:41:08,919 : INFO : EPOCH 30 - PROGRESS: at 30.75% examples, 2284014 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:09,923 : INFO : EPOCH 30 - PROGRESS: at 61.83% examples, 2286957 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:10,940 : INFO : EPOCH 30 - PROGRESS: at 91.08% examples, 2242858 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:11,206 : INFO : EPOCH 30: training on 8234555 raw words (7444876 effective words) took 3.3s, 2261405 effective words/s\n",
      "2024-06-06 12:41:12,208 : INFO : EPOCH 31 - PROGRESS: at 32.65% examples, 2432231 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:13,209 : INFO : EPOCH 31 - PROGRESS: at 63.92% examples, 2372491 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:14,209 : INFO : EPOCH 31 - PROGRESS: at 94.43% examples, 2343812 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:14,366 : INFO : EPOCH 31: training on 8234555 raw words (7443811 effective words) took 3.2s, 2357025 effective words/s\n",
      "2024-06-06 12:41:15,372 : INFO : EPOCH 32 - PROGRESS: at 32.40% examples, 2406339 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:16,372 : INFO : EPOCH 32 - PROGRESS: at 64.77% examples, 2402493 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:17,374 : INFO : EPOCH 32 - PROGRESS: at 96.91% examples, 2400491 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:17,450 : INFO : EPOCH 32: training on 8234555 raw words (7444043 effective words) took 3.1s, 2415315 effective words/s\n",
      "2024-06-06 12:41:18,451 : INFO : EPOCH 33 - PROGRESS: at 36.16% examples, 2695081 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:19,452 : INFO : EPOCH 33 - PROGRESS: at 69.51% examples, 2581210 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:20,382 : INFO : EPOCH 33: training on 8234555 raw words (7443535 effective words) took 2.9s, 2539668 effective words/s\n",
      "2024-06-06 12:41:21,384 : INFO : EPOCH 34 - PROGRESS: at 31.92% examples, 2380354 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:22,385 : INFO : EPOCH 34 - PROGRESS: at 64.65% examples, 2401112 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:23,393 : INFO : EPOCH 34 - PROGRESS: at 95.47% examples, 2362748 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:23,518 : INFO : EPOCH 34: training on 8234555 raw words (7443201 effective words) took 3.1s, 2374502 effective words/s\n",
      "2024-06-06 12:41:24,526 : INFO : EPOCH 35 - PROGRESS: at 30.98% examples, 2297505 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:25,529 : INFO : EPOCH 35 - PROGRESS: at 63.92% examples, 2362510 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:41:26,513 : INFO : EPOCH 35: training on 8234555 raw words (7443794 effective words) took 3.0s, 2486609 effective words/s\n",
      "2024-06-06 12:41:27,519 : INFO : EPOCH 36 - PROGRESS: at 31.55% examples, 2345004 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:28,522 : INFO : EPOCH 36 - PROGRESS: at 62.78% examples, 2323079 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:29,526 : INFO : EPOCH 36 - PROGRESS: at 94.54% examples, 2338189 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:29,683 : INFO : EPOCH 36: training on 8234555 raw words (7444121 effective words) took 3.2s, 2349013 effective words/s\n",
      "2024-06-06 12:41:30,686 : INFO : EPOCH 37 - PROGRESS: at 35.16% examples, 2617169 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:31,690 : INFO : EPOCH 37 - PROGRESS: at 69.70% examples, 2584888 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:32,652 : INFO : EPOCH 37: training on 8234555 raw words (7444413 effective words) took 3.0s, 2509339 effective words/s\n",
      "2024-06-06 12:41:33,657 : INFO : EPOCH 38 - PROGRESS: at 29.83% examples, 2219381 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:34,657 : INFO : EPOCH 38 - PROGRESS: at 61.12% examples, 2265401 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:35,660 : INFO : EPOCH 38 - PROGRESS: at 91.56% examples, 2267437 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:35,904 : INFO : EPOCH 38: training on 8234555 raw words (7443897 effective words) took 3.3s, 2290014 effective words/s\n",
      "2024-06-06 12:41:36,911 : INFO : EPOCH 39 - PROGRESS: at 30.51% examples, 2265470 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:37,915 : INFO : EPOCH 39 - PROGRESS: at 62.43% examples, 2307207 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:38,915 : INFO : EPOCH 39 - PROGRESS: at 93.51% examples, 2313948 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:41:39,100 : INFO : EPOCH 39: training on 8234555 raw words (7444582 effective words) took 3.2s, 2330148 effective words/s\n",
      "2024-06-06 12:41:39,100 : INFO : Doc2Vec lifecycle event {'msg': 'training on 329382200 raw words (297752154 effective words) took 126.3s, 2357658 effective words/s', 'datetime': '2024-06-06T12:41:39.100748', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:49:19,850 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:49:19.850727', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:49:19,851 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:49:19,851 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 2, 'epochs': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:49:20,602 : INFO : PROGRESS: at example #10000, processed 8060579 words (10743320 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:49:20,620 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:49:20,621 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:49:20,682 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:49:20.682098', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:49:20,682 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:49:20.682484', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:49:20,762 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:49:20,763 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:49:20,763 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:49:20.763560', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:49:20,894 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 12:49:20,894 : INFO : resetting layer weights\n",
      "2024-06-06 12:49:20,925 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T12:49:20.925391', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:49:21,929 : INFO : EPOCH 0 - PROGRESS: at 30.38% examples, 2265754 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:22,929 : INFO : EPOCH 0 - PROGRESS: at 61.61% examples, 2285275 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:23,930 : INFO : EPOCH 0 - PROGRESS: at 93.96% examples, 2330966 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:24,104 : INFO : EPOCH 0: training on 8234555 raw words (7443785 effective words) took 3.2s, 2342825 effective words/s\n",
      "2024-06-06 12:49:25,115 : INFO : EPOCH 1 - PROGRESS: at 30.15% examples, 2232435 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:26,116 : INFO : EPOCH 1 - PROGRESS: at 62.55% examples, 2310886 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:27,118 : INFO : EPOCH 1 - PROGRESS: at 93.49% examples, 2311680 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:27,299 : INFO : EPOCH 1: training on 8234555 raw words (7443499 effective words) took 3.2s, 2331045 effective words/s\n",
      "2024-06-06 12:49:28,300 : INFO : EPOCH 2 - PROGRESS: at 30.62% examples, 2286278 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:29,311 : INFO : EPOCH 2 - PROGRESS: at 61.26% examples, 2262103 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:30,317 : INFO : EPOCH 2 - PROGRESS: at 85.72% examples, 2119114 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:30,801 : INFO : EPOCH 2: training on 8234555 raw words (7443363 effective words) took 3.5s, 2126043 effective words/s\n",
      "2024-06-06 12:49:31,805 : INFO : EPOCH 3 - PROGRESS: at 26.59% examples, 1966741 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:32,809 : INFO : EPOCH 3 - PROGRESS: at 56.83% examples, 2101464 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:33,810 : INFO : EPOCH 3 - PROGRESS: at 81.90% examples, 2028343 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:34,434 : INFO : EPOCH 3: training on 8234555 raw words (7443618 effective words) took 3.6s, 2050132 effective words/s\n",
      "2024-06-06 12:49:35,439 : INFO : EPOCH 4 - PROGRESS: at 28.01% examples, 2073341 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:36,445 : INFO : EPOCH 4 - PROGRESS: at 56.36% examples, 2079743 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:37,446 : INFO : EPOCH 4 - PROGRESS: at 84.61% examples, 2094398 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:37,952 : INFO : EPOCH 4: training on 8234555 raw words (7444136 effective words) took 3.5s, 2116543 effective words/s\n",
      "2024-06-06 12:49:38,962 : INFO : EPOCH 5 - PROGRESS: at 32.74% examples, 2420235 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:39,967 : INFO : EPOCH 5 - PROGRESS: at 61.45% examples, 2268981 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:40,969 : INFO : EPOCH 5 - PROGRESS: at 90.29% examples, 2230542 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:41,285 : INFO : EPOCH 5: training on 8234555 raw words (7444011 effective words) took 3.3s, 2234322 effective words/s\n",
      "2024-06-06 12:49:42,292 : INFO : EPOCH 6 - PROGRESS: at 30.05% examples, 2239199 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:43,293 : INFO : EPOCH 6 - PROGRESS: at 62.57% examples, 2318153 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:44,293 : INFO : EPOCH 6 - PROGRESS: at 91.25% examples, 2261668 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:44,566 : INFO : EPOCH 6: training on 8234555 raw words (7443502 effective words) took 3.3s, 2271773 effective words/s\n",
      "2024-06-06 12:49:45,580 : INFO : EPOCH 7 - PROGRESS: at 28.11% examples, 2062969 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:46,593 : INFO : EPOCH 7 - PROGRESS: at 56.02% examples, 2051093 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:47,602 : INFO : EPOCH 7 - PROGRESS: at 85.84% examples, 2109699 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:48,137 : INFO : EPOCH 7: training on 8234555 raw words (7444092 effective words) took 3.6s, 2085529 effective words/s\n",
      "2024-06-06 12:49:49,140 : INFO : EPOCH 8 - PROGRESS: at 29.62% examples, 2207567 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:50,149 : INFO : EPOCH 8 - PROGRESS: at 56.86% examples, 2096317 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:51,152 : INFO : EPOCH 8 - PROGRESS: at 85.84% examples, 2123924 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:51,651 : INFO : EPOCH 8: training on 8234555 raw words (7443742 effective words) took 3.5s, 2119413 effective words/s\n",
      "2024-06-06 12:49:52,657 : INFO : EPOCH 9 - PROGRESS: at 31.66% examples, 2353779 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:49:53,660 : INFO : EPOCH 9 - PROGRESS: at 60.73% examples, 2247961 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:54,662 : INFO : EPOCH 9 - PROGRESS: at 91.00% examples, 2250950 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:54,945 : INFO : EPOCH 9: training on 8234555 raw words (7443147 effective words) took 3.3s, 2260224 effective words/s\n",
      "2024-06-06 12:49:55,951 : INFO : EPOCH 10 - PROGRESS: at 31.55% examples, 2344945 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:56,951 : INFO : EPOCH 10 - PROGRESS: at 59.71% examples, 2212434 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:49:57,961 : INFO : EPOCH 10 - PROGRESS: at 89.77% examples, 2216731 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:49:58,315 : INFO : EPOCH 10: training on 8234555 raw words (7443818 effective words) took 3.4s, 2210013 effective words/s\n",
      "2024-06-06 12:49:59,325 : INFO : EPOCH 11 - PROGRESS: at 28.32% examples, 2089167 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:00,326 : INFO : EPOCH 11 - PROGRESS: at 56.86% examples, 2097164 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:01,332 : INFO : EPOCH 11 - PROGRESS: at 85.08% examples, 2102573 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:01,801 : INFO : EPOCH 11: training on 8234555 raw words (7444065 effective words) took 3.5s, 2136049 effective words/s\n",
      "2024-06-06 12:50:02,803 : INFO : EPOCH 12 - PROGRESS: at 29.72% examples, 2218308 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:03,806 : INFO : EPOCH 12 - PROGRESS: at 58.92% examples, 2185064 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:04,813 : INFO : EPOCH 12 - PROGRESS: at 90.29% examples, 2233855 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:05,152 : INFO : EPOCH 12: training on 8234555 raw words (7444020 effective words) took 3.3s, 2222569 effective words/s\n",
      "2024-06-06 12:50:06,155 : INFO : EPOCH 13 - PROGRESS: at 29.91% examples, 2232936 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:07,157 : INFO : EPOCH 13 - PROGRESS: at 59.83% examples, 2218856 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:08,158 : INFO : EPOCH 13 - PROGRESS: at 91.35% examples, 2263842 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:08,462 : INFO : EPOCH 13: training on 8234555 raw words (7444335 effective words) took 3.3s, 2249990 effective words/s\n",
      "2024-06-06 12:50:09,468 : INFO : EPOCH 14 - PROGRESS: at 29.91% examples, 2226425 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:10,468 : INFO : EPOCH 14 - PROGRESS: at 56.71% examples, 2098153 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:11,470 : INFO : EPOCH 14 - PROGRESS: at 82.31% examples, 2040271 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:12,064 : INFO : EPOCH 14: training on 8234555 raw words (7443917 effective words) took 3.6s, 2067546 effective words/s\n",
      "2024-06-06 12:50:13,066 : INFO : EPOCH 15 - PROGRESS: at 30.15% examples, 2253708 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:14,068 : INFO : EPOCH 15 - PROGRESS: at 60.98% examples, 2263749 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:15,071 : INFO : EPOCH 15 - PROGRESS: at 94.54% examples, 2343575 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:15,251 : INFO : EPOCH 15: training on 8234555 raw words (7444115 effective words) took 3.2s, 2336716 effective words/s\n",
      "2024-06-06 12:50:16,256 : INFO : EPOCH 16 - PROGRESS: at 32.53% examples, 2415696 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:17,259 : INFO : EPOCH 16 - PROGRESS: at 61.47% examples, 2275699 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:18,260 : INFO : EPOCH 16 - PROGRESS: at 89.41% examples, 2213348 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:18,614 : INFO : EPOCH 16: training on 8234555 raw words (7443090 effective words) took 3.4s, 2214485 effective words/s\n",
      "2024-06-06 12:50:19,616 : INFO : EPOCH 17 - PROGRESS: at 32.04% examples, 2389051 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:20,617 : INFO : EPOCH 17 - PROGRESS: at 60.48% examples, 2246477 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:21,617 : INFO : EPOCH 17 - PROGRESS: at 91.33% examples, 2265921 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:21,883 : INFO : EPOCH 17: training on 8234555 raw words (7443635 effective words) took 3.3s, 2278198 effective words/s\n",
      "2024-06-06 12:50:22,892 : INFO : EPOCH 18 - PROGRESS: at 28.94% examples, 2141721 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:23,898 : INFO : EPOCH 18 - PROGRESS: at 57.41% examples, 2113292 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:24,899 : INFO : EPOCH 18 - PROGRESS: at 86.17% examples, 2131417 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:25,346 : INFO : EPOCH 18: training on 8234555 raw words (7443723 effective words) took 3.5s, 2150443 effective words/s\n",
      "2024-06-06 12:50:26,348 : INFO : EPOCH 19 - PROGRESS: at 33.08% examples, 2463623 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:27,352 : INFO : EPOCH 19 - PROGRESS: at 61.93% examples, 2294781 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:28,360 : INFO : EPOCH 19 - PROGRESS: at 91.66% examples, 2266172 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:28,609 : INFO : EPOCH 19: training on 8234555 raw words (7443381 effective words) took 3.3s, 2281890 effective words/s\n",
      "2024-06-06 12:50:29,611 : INFO : EPOCH 20 - PROGRESS: at 30.15% examples, 2252294 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:30,614 : INFO : EPOCH 20 - PROGRESS: at 60.27% examples, 2235878 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:31,618 : INFO : EPOCH 20 - PROGRESS: at 88.68% examples, 2195982 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:31,986 : INFO : EPOCH 20: training on 8234555 raw words (7444472 effective words) took 3.4s, 2205251 effective words/s\n",
      "2024-06-06 12:50:32,988 : INFO : EPOCH 21 - PROGRESS: at 28.49% examples, 2124259 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:33,989 : INFO : EPOCH 21 - PROGRESS: at 62.67% examples, 2325168 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:34,990 : INFO : EPOCH 21 - PROGRESS: at 93.41% examples, 2316560 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:35,230 : INFO : EPOCH 21: training on 8234555 raw words (7443787 effective words) took 3.2s, 2295757 effective words/s\n",
      "2024-06-06 12:50:36,236 : INFO : EPOCH 22 - PROGRESS: at 30.38% examples, 2260712 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:37,238 : INFO : EPOCH 22 - PROGRESS: at 57.28% examples, 2117284 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:38,247 : INFO : EPOCH 22 - PROGRESS: at 87.25% examples, 2156208 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:38,636 : INFO : EPOCH 22: training on 8234555 raw words (7443804 effective words) took 3.4s, 2186672 effective words/s\n",
      "2024-06-06 12:50:39,640 : INFO : EPOCH 23 - PROGRESS: at 27.59% examples, 2041879 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:40,641 : INFO : EPOCH 23 - PROGRESS: at 57.95% examples, 2146168 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:41,641 : INFO : EPOCH 23 - PROGRESS: at 87.41% examples, 2167541 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:42,028 : INFO : EPOCH 23: training on 8234555 raw words (7444416 effective words) took 3.4s, 2195683 effective words/s\n",
      "2024-06-06 12:50:43,030 : INFO : EPOCH 24 - PROGRESS: at 29.28% examples, 2182839 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:44,030 : INFO : EPOCH 24 - PROGRESS: at 59.58% examples, 2212549 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:45,037 : INFO : EPOCH 24 - PROGRESS: at 90.42% examples, 2238532 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:45,365 : INFO : EPOCH 24: training on 8234555 raw words (7444214 effective words) took 3.3s, 2231426 effective words/s\n",
      "2024-06-06 12:50:46,371 : INFO : EPOCH 25 - PROGRESS: at 31.67% examples, 2353246 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:47,373 : INFO : EPOCH 25 - PROGRESS: at 61.34% examples, 2271757 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:48,375 : INFO : EPOCH 25 - PROGRESS: at 90.51% examples, 2240573 words/s, in_qsize 17, out_qsize 2\n",
      "2024-06-06 12:50:48,672 : INFO : EPOCH 25: training on 8234555 raw words (7443876 effective words) took 3.3s, 2252016 effective words/s\n",
      "2024-06-06 12:50:49,678 : INFO : EPOCH 26 - PROGRESS: at 26.92% examples, 1986870 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:50,681 : INFO : EPOCH 26 - PROGRESS: at 58.16% examples, 2150972 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:51,687 : INFO : EPOCH 26 - PROGRESS: at 88.80% examples, 2194528 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:52,055 : INFO : EPOCH 26: training on 8234555 raw words (7444018 effective words) took 3.4s, 2201823 effective words/s\n",
      "2024-06-06 12:50:53,059 : INFO : EPOCH 27 - PROGRESS: at 30.51% examples, 2271850 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:54,061 : INFO : EPOCH 27 - PROGRESS: at 60.73% examples, 2251220 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:55,061 : INFO : EPOCH 27 - PROGRESS: at 90.03% examples, 2231494 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:55,385 : INFO : EPOCH 27: training on 8234555 raw words (7443428 effective words) took 3.3s, 2236218 effective words/s\n",
      "2024-06-06 12:50:56,395 : INFO : EPOCH 28 - PROGRESS: at 29.91% examples, 2217709 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:50:57,399 : INFO : EPOCH 28 - PROGRESS: at 58.05% examples, 2140490 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:50:58,403 : INFO : EPOCH 28 - PROGRESS: at 88.24% examples, 2177557 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 12:50:58,784 : INFO : EPOCH 28: training on 8234555 raw words (7443405 effective words) took 3.4s, 2190682 effective words/s\n",
      "2024-06-06 12:50:59,788 : INFO : EPOCH 29 - PROGRESS: at 28.60% examples, 2126390 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:00,789 : INFO : EPOCH 29 - PROGRESS: at 56.26% examples, 2081934 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:01,791 : INFO : EPOCH 29 - PROGRESS: at 85.96% examples, 2132940 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:02,233 : INFO : EPOCH 29: training on 8234555 raw words (7444250 effective words) took 3.4s, 2159640 effective words/s\n",
      "2024-06-06 12:51:03,235 : INFO : EPOCH 30 - PROGRESS: at 30.38% examples, 2270264 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 12:51:04,238 : INFO : EPOCH 30 - PROGRESS: at 62.31% examples, 2309938 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:05,240 : INFO : EPOCH 30 - PROGRESS: at 90.89% examples, 2251822 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:05,530 : INFO : EPOCH 30: training on 8234555 raw words (7443565 effective words) took 3.3s, 2258353 effective words/s\n",
      "2024-06-06 12:51:06,535 : INFO : EPOCH 31 - PROGRESS: at 30.05% examples, 2239455 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:07,536 : INFO : EPOCH 31 - PROGRESS: at 64.09% examples, 2378291 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:08,537 : INFO : EPOCH 31 - PROGRESS: at 91.66% examples, 2271925 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:08,838 : INFO : EPOCH 31: training on 8234555 raw words (7444272 effective words) took 3.3s, 2251862 effective words/s\n",
      "2024-06-06 12:51:09,845 : INFO : EPOCH 32 - PROGRESS: at 30.39% examples, 2257531 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:10,850 : INFO : EPOCH 32 - PROGRESS: at 59.83% examples, 2209739 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:11,852 : INFO : EPOCH 32 - PROGRESS: at 88.93% examples, 2197860 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:12,212 : INFO : EPOCH 32: training on 8234555 raw words (7444024 effective words) took 3.4s, 2207239 effective words/s\n",
      "2024-06-06 12:51:13,220 : INFO : EPOCH 33 - PROGRESS: at 29.06% examples, 2153367 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:14,227 : INFO : EPOCH 33 - PROGRESS: at 62.18% examples, 2293773 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:15,228 : INFO : EPOCH 33 - PROGRESS: at 93.26% examples, 2305151 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:15,475 : INFO : EPOCH 33: training on 8234555 raw words (7444466 effective words) took 3.3s, 2282302 effective words/s\n",
      "2024-06-06 12:51:16,482 : INFO : EPOCH 34 - PROGRESS: at 30.02% examples, 2234841 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:17,485 : INFO : EPOCH 34 - PROGRESS: at 60.17% examples, 2225870 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:18,494 : INFO : EPOCH 34 - PROGRESS: at 90.16% examples, 2225803 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:18,803 : INFO : EPOCH 34: training on 8234555 raw words (7443966 effective words) took 3.3s, 2237971 effective words/s\n",
      "2024-06-06 12:51:19,805 : INFO : EPOCH 35 - PROGRESS: at 30.51% examples, 2278420 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:20,808 : INFO : EPOCH 35 - PROGRESS: at 58.29% examples, 2159178 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:21,810 : INFO : EPOCH 35 - PROGRESS: at 89.18% examples, 2208588 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:22,166 : INFO : EPOCH 35: training on 8234555 raw words (7443536 effective words) took 3.4s, 2214208 effective words/s\n",
      "2024-06-06 12:51:23,175 : INFO : EPOCH 36 - PROGRESS: at 28.71% examples, 2126309 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:24,178 : INFO : EPOCH 36 - PROGRESS: at 54.19% examples, 2002481 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:25,180 : INFO : EPOCH 36 - PROGRESS: at 83.22% examples, 2059606 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:25,721 : INFO : EPOCH 36: training on 8234555 raw words (7443704 effective words) took 3.6s, 2094854 effective words/s\n",
      "2024-06-06 12:51:26,729 : INFO : EPOCH 37 - PROGRESS: at 28.38% examples, 2102967 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:27,729 : INFO : EPOCH 37 - PROGRESS: at 57.41% examples, 2121572 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:28,733 : INFO : EPOCH 37 - PROGRESS: at 88.11% examples, 2179505 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:29,106 : INFO : EPOCH 37: training on 8234555 raw words (7443661 effective words) took 3.4s, 2199992 effective words/s\n",
      "2024-06-06 12:51:30,109 : INFO : EPOCH 38 - PROGRESS: at 31.55% examples, 2351756 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:31,114 : INFO : EPOCH 38 - PROGRESS: at 61.48% examples, 2275628 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:32,116 : INFO : EPOCH 38 - PROGRESS: at 90.89% examples, 2249000 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 12:51:32,415 : INFO : EPOCH 38: training on 8234555 raw words (7443661 effective words) took 3.3s, 2250405 effective words/s\n",
      "2024-06-06 12:51:33,425 : INFO : EPOCH 39 - PROGRESS: at 28.94% examples, 2140775 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:34,428 : INFO : EPOCH 39 - PROGRESS: at 60.17% examples, 2223612 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:35,437 : INFO : EPOCH 39 - PROGRESS: at 86.11% examples, 2125287 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 12:51:35,876 : INFO : EPOCH 39: training on 8234555 raw words (7444028 effective words) took 3.5s, 2152115 effective words/s\n",
      "2024-06-06 12:51:35,876 : INFO : Doc2Vec lifecycle event {'msg': 'training on 329382200 raw words (297753547 effective words) took 135.0s, 2206370 effective words/s', 'datetime': '2024-06-06T12:51:35.876923', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 12:59:57,604 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T12:59:57.604578', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 12:59:57,604 : INFO : collecting all words and their counts\n",
      "2024-06-06 12:59:57,605 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 10, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 12:59:58,322 : INFO : PROGRESS: at example #10000, processed 8060579 words (11235702 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 12:59:58,341 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 12:59:58,342 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 12:59:58,409 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T12:59:58.409185', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:59:58,409 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T12:59:58.409677', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:59:58,483 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 12:59:58,484 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 12:59:58,484 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T12:59:58.484521', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 12:59:58,605 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 12:59:58,606 : INFO : resetting layer weights\n",
      "2024-06-06 12:59:58,635 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T12:59:58.635623', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 12:59:59,639 : INFO : EPOCH 0 - PROGRESS: at 31.33% examples, 2334564 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:00,643 : INFO : EPOCH 0 - PROGRESS: at 63.80% examples, 2362600 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:01,644 : INFO : EPOCH 0 - PROGRESS: at 95.58% examples, 2368640 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:01,772 : INFO : EPOCH 0: training on 8234555 raw words (7444789 effective words) took 3.1s, 2374509 effective words/s\n",
      "2024-06-06 13:00:02,781 : INFO : EPOCH 1 - PROGRESS: at 32.79% examples, 2425675 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:03,783 : INFO : EPOCH 1 - PROGRESS: at 63.49% examples, 2346078 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:04,784 : INFO : EPOCH 1 - PROGRESS: at 86.62% examples, 2146544 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:05,294 : INFO : EPOCH 1: training on 8234555 raw words (7444733 effective words) took 3.5s, 2114940 effective words/s\n",
      "2024-06-06 13:00:06,297 : INFO : EPOCH 2 - PROGRESS: at 25.86% examples, 1914827 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:07,300 : INFO : EPOCH 2 - PROGRESS: at 50.15% examples, 1859961 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:08,304 : INFO : EPOCH 2 - PROGRESS: at 76.74% examples, 1897818 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:09,141 : INFO : EPOCH 2: training on 8234555 raw words (7443307 effective words) took 3.8s, 1935434 effective words/s\n",
      "2024-06-06 13:00:10,143 : INFO : EPOCH 3 - PROGRESS: at 31.20% examples, 2328332 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:11,149 : INFO : EPOCH 3 - PROGRESS: at 59.50% examples, 2201347 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:12,151 : INFO : EPOCH 3 - PROGRESS: at 88.55% examples, 2192164 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 13:00:12,519 : INFO : EPOCH 3: training on 8234555 raw words (7443406 effective words) took 3.4s, 2204260 effective words/s\n",
      "2024-06-06 13:00:13,524 : INFO : EPOCH 4 - PROGRESS: at 28.32% examples, 2100934 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:14,527 : INFO : EPOCH 4 - PROGRESS: at 60.73% examples, 2250618 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:15,540 : INFO : EPOCH 4 - PROGRESS: at 85.94% examples, 2122891 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:00:16,022 : INFO : EPOCH 4: training on 8234555 raw words (7443836 effective words) took 3.5s, 2126234 effective words/s\n",
      "2024-06-06 13:00:17,025 : INFO : EPOCH 5 - PROGRESS: at 28.94% examples, 2154181 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:18,031 : INFO : EPOCH 5 - PROGRESS: at 59.50% examples, 2200624 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:19,034 : INFO : EPOCH 5 - PROGRESS: at 85.72% examples, 2123334 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:19,503 : INFO : EPOCH 5: training on 8234555 raw words (7443355 effective words) took 3.5s, 2138902 effective words/s\n",
      "2024-06-06 13:00:20,513 : INFO : EPOCH 6 - PROGRESS: at 29.06% examples, 2149503 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:21,514 : INFO : EPOCH 6 - PROGRESS: at 55.28% examples, 2040842 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:22,518 : INFO : EPOCH 6 - PROGRESS: at 82.44% examples, 2038356 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:23,111 : INFO : EPOCH 6: training on 8234555 raw words (7444002 effective words) took 3.6s, 2063965 effective words/s\n",
      "2024-06-06 13:00:24,113 : INFO : EPOCH 7 - PROGRESS: at 26.58% examples, 1968679 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:25,118 : INFO : EPOCH 7 - PROGRESS: at 56.13% examples, 2075778 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:26,123 : INFO : EPOCH 7 - PROGRESS: at 82.20% examples, 2035127 words/s, in_qsize 20, out_qsize 2\n",
      "2024-06-06 13:00:26,748 : INFO : EPOCH 7: training on 8234555 raw words (7443741 effective words) took 3.6s, 2047828 effective words/s\n",
      "2024-06-06 13:00:27,754 : INFO : EPOCH 8 - PROGRESS: at 28.71% examples, 2129813 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:28,757 : INFO : EPOCH 8 - PROGRESS: at 57.39% examples, 2119654 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:29,757 : INFO : EPOCH 8 - PROGRESS: at 89.96% examples, 2226464 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:30,044 : INFO : EPOCH 8: training on 8234555 raw words (7444298 effective words) took 3.3s, 2259480 effective words/s\n",
      "2024-06-06 13:00:31,048 : INFO : EPOCH 9 - PROGRESS: at 33.18% examples, 2464960 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:32,053 : INFO : EPOCH 9 - PROGRESS: at 59.14% examples, 2188320 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:33,056 : INFO : EPOCH 9 - PROGRESS: at 89.32% examples, 2207094 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:33,401 : INFO : EPOCH 9: training on 8234555 raw words (7442437 effective words) took 3.4s, 2218059 effective words/s\n",
      "2024-06-06 13:00:34,405 : INFO : EPOCH 10 - PROGRESS: at 29.19% examples, 2168142 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:35,407 : INFO : EPOCH 10 - PROGRESS: at 54.32% examples, 2011504 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:36,412 : INFO : EPOCH 10 - PROGRESS: at 83.77% examples, 2074556 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:36,950 : INFO : EPOCH 10: training on 8234555 raw words (7443021 effective words) took 3.5s, 2097780 effective words/s\n",
      "2024-06-06 13:00:37,958 : INFO : EPOCH 11 - PROGRESS: at 27.36% examples, 2017296 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:38,961 : INFO : EPOCH 11 - PROGRESS: at 54.93% examples, 2028803 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:39,964 : INFO : EPOCH 11 - PROGRESS: at 82.30% examples, 2036010 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:00:40,570 : INFO : EPOCH 11: training on 8234555 raw words (7443449 effective words) took 3.6s, 2057371 effective words/s\n",
      "2024-06-06 13:00:41,576 : INFO : EPOCH 12 - PROGRESS: at 26.80% examples, 1978082 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:42,577 : INFO : EPOCH 12 - PROGRESS: at 55.03% examples, 2036346 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:43,583 : INFO : EPOCH 12 - PROGRESS: at 81.44% examples, 2013925 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:44,208 : INFO : EPOCH 12: training on 8234555 raw words (7444657 effective words) took 3.6s, 2047160 effective words/s\n",
      "2024-06-06 13:00:45,214 : INFO : EPOCH 13 - PROGRESS: at 29.50% examples, 2190148 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:46,217 : INFO : EPOCH 13 - PROGRESS: at 60.27% examples, 2230984 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:47,220 : INFO : EPOCH 13 - PROGRESS: at 88.24% examples, 2182077 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:47,597 : INFO : EPOCH 13: training on 8234555 raw words (7443463 effective words) took 3.4s, 2197244 effective words/s\n",
      "2024-06-06 13:00:48,604 : INFO : EPOCH 14 - PROGRESS: at 29.52% examples, 2188785 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:49,611 : INFO : EPOCH 14 - PROGRESS: at 56.02% examples, 2063489 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:00:50,616 : INFO : EPOCH 14 - PROGRESS: at 82.01% examples, 2023756 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:51,209 : INFO : EPOCH 14: training on 8234555 raw words (7444062 effective words) took 3.6s, 2061631 effective words/s\n",
      "2024-06-06 13:00:52,215 : INFO : EPOCH 15 - PROGRESS: at 29.83% examples, 2217045 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:53,219 : INFO : EPOCH 15 - PROGRESS: at 57.81% examples, 2136463 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:54,221 : INFO : EPOCH 15 - PROGRESS: at 84.85% examples, 2100238 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:54,724 : INFO : EPOCH 15: training on 8234555 raw words (7443578 effective words) took 3.5s, 2118413 effective words/s\n",
      "2024-06-06 13:00:55,728 : INFO : EPOCH 16 - PROGRESS: at 29.41% examples, 2187377 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:00:56,730 : INFO : EPOCH 16 - PROGRESS: at 59.27% examples, 2195998 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:57,743 : INFO : EPOCH 16 - PROGRESS: at 85.84% examples, 2121888 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:00:58,200 : INFO : EPOCH 16: training on 8234555 raw words (7444315 effective words) took 3.5s, 2142713 effective words/s\n",
      "2024-06-06 13:00:59,202 : INFO : EPOCH 17 - PROGRESS: at 29.17% examples, 2174020 words/s, in_qsize 17, out_qsize 2\n",
      "2024-06-06 13:01:00,212 : INFO : EPOCH 17 - PROGRESS: at 53.95% examples, 1992598 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:01:01,212 : INFO : EPOCH 17 - PROGRESS: at 82.44% examples, 2040429 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:01:01,847 : INFO : EPOCH 17: training on 8234555 raw words (7443575 effective words) took 3.6s, 2041911 effective words/s\n",
      "2024-06-06 13:01:02,849 : INFO : EPOCH 18 - PROGRESS: at 30.98% examples, 2310279 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:01:03,854 : INFO : EPOCH 18 - PROGRESS: at 58.92% examples, 2182156 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:01:04,857 : INFO : EPOCH 18 - PROGRESS: at 86.17% examples, 2136297 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:01:05,313 : INFO : EPOCH 18: training on 8234555 raw words (7443835 effective words) took 3.5s, 2148263 effective words/s\n",
      "2024-06-06 13:01:06,316 : INFO : EPOCH 19 - PROGRESS: at 28.94% examples, 2155338 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:01:07,316 : INFO : EPOCH 19 - PROGRESS: at 59.74% examples, 2215690 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:01:08,320 : INFO : EPOCH 19 - PROGRESS: at 87.13% examples, 2160443 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:01:08,797 : INFO : EPOCH 19: training on 8234555 raw words (7443671 effective words) took 3.5s, 2137480 effective words/s\n",
      "2024-06-06 13:01:08,798 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148875530 effective words) took 70.2s, 2121871 effective words/s', 'datetime': '2024-06-06T13:01:08.798044', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 13:05:31,861 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w20,mc2,s0.001,t10>', 'datetime': '2024-06-06T13:05:31.861539', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 13:05:31,861 : INFO : collecting all words and their counts\n",
      "2024-06-06 13:05:31,862 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 200, 'window': 20, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 13:05:32,581 : INFO : PROGRESS: at example #10000, processed 8060579 words (11207483 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 13:05:32,597 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 13:05:32,598 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 13:05:32,658 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T13:05:32.658431', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:05:32,658 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T13:05:32.658808', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:05:32,734 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 13:05:32,735 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 13:05:32,735 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T13:05:32.735286', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:05:32,859 : INFO : estimated required memory for 40031 words and 200 dimensions: 94286100 bytes\n",
      "2024-06-06 13:05:32,859 : INFO : resetting layer weights\n",
      "2024-06-06 13:05:32,888 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=20 shrink_windows=True', 'datetime': '2024-06-06T13:05:32.888393', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 13:05:33,891 : INFO : EPOCH 0 - PROGRESS: at 27.70% examples, 2053890 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:34,897 : INFO : EPOCH 0 - PROGRESS: at 55.79% examples, 2061081 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:35,911 : INFO : EPOCH 0 - PROGRESS: at 82.68% examples, 2039213 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:36,508 : INFO : EPOCH 0: training on 8234555 raw words (7443918 effective words) took 3.6s, 2057476 effective words/s\n",
      "2024-06-06 13:05:37,510 : INFO : EPOCH 1 - PROGRESS: at 27.70% examples, 2055446 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:38,511 : INFO : EPOCH 1 - PROGRESS: at 55.86% examples, 2070493 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:39,528 : INFO : EPOCH 1 - PROGRESS: at 80.43% examples, 1982881 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:40,475 : INFO : EPOCH 1: training on 8234555 raw words (7443339 effective words) took 4.0s, 1877170 effective words/s\n",
      "2024-06-06 13:05:41,477 : INFO : EPOCH 2 - PROGRESS: at 21.81% examples, 1620381 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:42,479 : INFO : EPOCH 2 - PROGRESS: at 43.52% examples, 1617795 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:43,479 : INFO : EPOCH 2 - PROGRESS: at 63.35% examples, 1566254 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:44,488 : INFO : EPOCH 2 - PROGRESS: at 86.62% examples, 1609916 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:45,015 : INFO : EPOCH 2: training on 8234555 raw words (7443402 effective words) took 4.5s, 1639925 effective words/s\n",
      "2024-06-06 13:05:46,021 : INFO : EPOCH 3 - PROGRESS: at 25.14% examples, 1859297 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:47,022 : INFO : EPOCH 3 - PROGRESS: at 51.13% examples, 1897550 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:48,023 : INFO : EPOCH 3 - PROGRESS: at 73.31% examples, 1816516 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:49,033 : INFO : EPOCH 3 - PROGRESS: at 98.14% examples, 1820150 words/s, in_qsize 16, out_qsize 0\n",
      "2024-06-06 13:05:49,094 : INFO : EPOCH 3: training on 8234555 raw words (7443290 effective words) took 4.1s, 1825621 effective words/s\n",
      "2024-06-06 13:05:50,097 : INFO : EPOCH 4 - PROGRESS: at 20.19% examples, 1508659 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:51,099 : INFO : EPOCH 4 - PROGRESS: at 45.51% examples, 1690030 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:52,114 : INFO : EPOCH 4 - PROGRESS: at 70.62% examples, 1741838 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:05:53,116 : INFO : EPOCH 4 - PROGRESS: at 92.28% examples, 1709149 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:53,397 : INFO : EPOCH 4: training on 8234555 raw words (7445205 effective words) took 4.3s, 1730523 effective words/s\n",
      "2024-06-06 13:05:54,399 : INFO : EPOCH 5 - PROGRESS: at 24.39% examples, 1814882 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:05:55,407 : INFO : EPOCH 5 - PROGRESS: at 48.40% examples, 1793497 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 13:05:56,410 : INFO : EPOCH 5 - PROGRESS: at 75.62% examples, 1870874 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:57,251 : INFO : EPOCH 5: training on 8234555 raw words (7444025 effective words) took 3.9s, 1932472 effective words/s\n",
      "2024-06-06 13:05:58,252 : INFO : EPOCH 6 - PROGRESS: at 28.24% examples, 2096829 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:05:59,250 : INFO : EPOCH 6 - PROGRESS: at 51.48% examples, 1915402 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:00,252 : INFO : EPOCH 6 - PROGRESS: at 76.25% examples, 1889680 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:01,199 : INFO : EPOCH 6: training on 8234555 raw words (7443538 effective words) took 4.0s, 1883554 effective words/s\n",
      "2024-06-06 13:06:02,201 : INFO : EPOCH 7 - PROGRESS: at 25.12% examples, 1863012 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:03,200 : INFO : EPOCH 7 - PROGRESS: at 46.87% examples, 1742788 words/s, in_qsize 19, out_qsize 1\n",
      "2024-06-06 13:06:04,204 : INFO : EPOCH 7 - PROGRESS: at 71.90% examples, 1782514 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:05,212 : INFO : EPOCH 7 - PROGRESS: at 98.47% examples, 1826752 words/s, in_qsize 13, out_qsize 0\n",
      "2024-06-06 13:06:05,246 : INFO : EPOCH 7: training on 8234555 raw words (7444066 effective words) took 4.1s, 1838005 effective words/s\n",
      "2024-06-06 13:06:06,277 : INFO : EPOCH 8 - PROGRESS: at 23.39% examples, 1692426 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:07,279 : INFO : EPOCH 8 - PROGRESS: at 48.40% examples, 1770412 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:08,279 : INFO : EPOCH 8 - PROGRESS: at 73.81% examples, 1814019 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:09,181 : INFO : EPOCH 8: training on 8234555 raw words (7443579 effective words) took 3.9s, 1890303 effective words/s\n",
      "2024-06-06 13:06:10,184 : INFO : EPOCH 9 - PROGRESS: at 26.55% examples, 1965298 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 13:06:11,184 : INFO : EPOCH 9 - PROGRESS: at 50.02% examples, 1857511 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:12,188 : INFO : EPOCH 9 - PROGRESS: at 74.17% examples, 1839113 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:13,188 : INFO : EPOCH 9 - PROGRESS: at 99.88% examples, 1855043 words/s, in_qsize 1, out_qsize 1\n",
      "2024-06-06 13:06:13,188 : INFO : EPOCH 9: training on 8234555 raw words (7443312 effective words) took 4.0s, 1856948 effective words/s\n",
      "2024-06-06 13:06:14,193 : INFO : EPOCH 10 - PROGRESS: at 28.24% examples, 2090552 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:15,195 : INFO : EPOCH 10 - PROGRESS: at 56.49% examples, 2087554 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:16,204 : INFO : EPOCH 10 - PROGRESS: at 84.98% examples, 2098833 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:16,753 : INFO : EPOCH 10: training on 8234555 raw words (7442793 effective words) took 3.6s, 2087571 effective words/s\n",
      "2024-06-06 13:06:17,755 : INFO : EPOCH 11 - PROGRESS: at 24.74% examples, 1840503 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:18,755 : INFO : EPOCH 11 - PROGRESS: at 49.44% examples, 1838509 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:19,760 : INFO : EPOCH 11 - PROGRESS: at 73.50% examples, 1822373 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:20,761 : INFO : EPOCH 11 - PROGRESS: at 94.33% examples, 1752823 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:20,972 : INFO : EPOCH 11: training on 8234555 raw words (7444042 effective words) took 4.2s, 1764599 effective words/s\n",
      "2024-06-06 13:06:21,976 : INFO : EPOCH 12 - PROGRESS: at 24.42% examples, 1810096 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:06:22,979 : INFO : EPOCH 12 - PROGRESS: at 50.93% examples, 1888520 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:23,987 : INFO : EPOCH 12 - PROGRESS: at 73.19% examples, 1808818 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:24,989 : INFO : EPOCH 12 - PROGRESS: at 98.83% examples, 1833033 words/s, in_qsize 10, out_qsize 0\n",
      "2024-06-06 13:06:25,018 : INFO : EPOCH 12: training on 8234555 raw words (7443548 effective words) took 4.0s, 1839660 effective words/s\n",
      "2024-06-06 13:06:26,033 : INFO : EPOCH 13 - PROGRESS: at 24.67% examples, 1806190 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:06:27,038 : INFO : EPOCH 13 - PROGRESS: at 52.62% examples, 1936525 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:28,044 : INFO : EPOCH 13 - PROGRESS: at 72.29% examples, 1780417 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:29,044 : INFO : EPOCH 13 - PROGRESS: at 95.58% examples, 1768900 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:29,203 : INFO : EPOCH 13: training on 8234555 raw words (7443876 effective words) took 4.2s, 1778857 effective words/s\n",
      "2024-06-06 13:06:30,206 : INFO : EPOCH 14 - PROGRESS: at 24.26% examples, 1802990 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:31,217 : INFO : EPOCH 14 - PROGRESS: at 52.32% examples, 1933904 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:32,221 : INFO : EPOCH 14 - PROGRESS: at 74.60% examples, 1841408 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:33,198 : INFO : EPOCH 14: training on 8234555 raw words (7443538 effective words) took 4.0s, 1863504 effective words/s\n",
      "2024-06-06 13:06:34,200 : INFO : EPOCH 15 - PROGRESS: at 24.39% examples, 1813270 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:35,214 : INFO : EPOCH 15 - PROGRESS: at 51.35% examples, 1898095 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:36,216 : INFO : EPOCH 15 - PROGRESS: at 73.40% examples, 1813082 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:37,226 : INFO : EPOCH 15 - PROGRESS: at 98.83% examples, 1828542 words/s, in_qsize 10, out_qsize 0\n",
      "2024-06-06 13:06:37,248 : INFO : EPOCH 15: training on 8234555 raw words (7443766 effective words) took 4.0s, 1838617 effective words/s\n",
      "2024-06-06 13:06:38,252 : INFO : EPOCH 16 - PROGRESS: at 24.27% examples, 1801807 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:39,257 : INFO : EPOCH 16 - PROGRESS: at 51.13% examples, 1895188 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:40,262 : INFO : EPOCH 16 - PROGRESS: at 72.92% examples, 1803587 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:41,279 : INFO : EPOCH 16 - PROGRESS: at 94.07% examples, 1738856 words/s, in_qsize 19, out_qsize 2\n",
      "2024-06-06 13:06:41,584 : INFO : EPOCH 16: training on 8234555 raw words (7443616 effective words) took 4.3s, 1716971 effective words/s\n",
      "2024-06-06 13:06:42,592 : INFO : EPOCH 17 - PROGRESS: at 23.15% examples, 1715374 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:43,593 : INFO : EPOCH 17 - PROGRESS: at 48.30% examples, 1789942 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 13:06:44,597 : INFO : EPOCH 17 - PROGRESS: at 71.39% examples, 1766261 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:45,598 : INFO : EPOCH 17 - PROGRESS: at 94.33% examples, 1751116 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:45,795 : INFO : EPOCH 17: training on 8234555 raw words (7444362 effective words) took 4.2s, 1768338 effective words/s\n",
      "2024-06-06 13:06:46,799 : INFO : EPOCH 18 - PROGRESS: at 24.78% examples, 1837571 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:47,803 : INFO : EPOCH 18 - PROGRESS: at 48.26% examples, 1790630 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:48,805 : INFO : EPOCH 18 - PROGRESS: at 71.90% examples, 1781812 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:49,809 : INFO : EPOCH 18 - PROGRESS: at 97.83% examples, 1815364 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:49,889 : INFO : EPOCH 18: training on 8234555 raw words (7443145 effective words) took 4.1s, 1818624 effective words/s\n",
      "2024-06-06 13:06:50,892 : INFO : EPOCH 19 - PROGRESS: at 23.09% examples, 1715857 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:51,914 : INFO : EPOCH 19 - PROGRESS: at 47.51% examples, 1745712 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:52,917 : INFO : EPOCH 19 - PROGRESS: at 71.63% examples, 1762518 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:06:53,921 : INFO : EPOCH 19 - PROGRESS: at 95.66% examples, 1768736 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:06:54,088 : INFO : EPOCH 19: training on 8234555 raw words (7442808 effective words) took 4.2s, 1773216 effective words/s\n",
      "2024-06-06 13:06:54,089 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148873168 effective words) took 81.2s, 1832819 effective words/s', 'datetime': '2024-06-06T13:06:54.089089', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/mixture/_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 13:12:14,988 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc2,s0.001,t10>', 'datetime': '2024-06-06T13:12:14.988613', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 13:12:14,988 : INFO : collecting all words and their counts\n",
      "2024-06-06 13:12:14,989 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 100, 'window': 10, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 13:12:15,698 : INFO : PROGRESS: at example #10000, processed 8060579 words (11360501 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 13:12:15,714 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 13:12:15,715 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 13:12:15,768 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T13:12:15.768555', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:12:15,769 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T13:12:15.768997', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:12:15,837 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 13:12:15,838 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 13:12:15,839 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T13:12:15.839817', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:12:15,958 : INFO : estimated required memory for 40031 words and 100 dimensions: 58172900 bytes\n",
      "2024-06-06 13:12:15,958 : INFO : resetting layer weights\n",
      "2024-06-06 13:12:15,978 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-06-06T13:12:15.978489', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 13:12:16,990 : INFO : EPOCH 0 - PROGRESS: at 36.43% examples, 2684782 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:17,997 : INFO : EPOCH 0 - PROGRESS: at 74.06% examples, 2737807 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:18,687 : INFO : EPOCH 0: training on 8234555 raw words (7443931 effective words) took 2.7s, 2749586 effective words/s\n",
      "2024-06-06 13:12:19,690 : INFO : EPOCH 1 - PROGRESS: at 37.31% examples, 2768164 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:20,690 : INFO : EPOCH 1 - PROGRESS: at 74.63% examples, 2780093 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:21,346 : INFO : EPOCH 1: training on 8234555 raw words (7444421 effective words) took 2.7s, 2801450 effective words/s\n",
      "2024-06-06 13:12:22,353 : INFO : EPOCH 2 - PROGRESS: at 37.05% examples, 2740008 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:23,354 : INFO : EPOCH 2 - PROGRESS: at 74.42% examples, 2764084 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:24,023 : INFO : EPOCH 2: training on 8234555 raw words (7443676 effective words) took 2.7s, 2781300 effective words/s\n",
      "2024-06-06 13:12:25,026 : INFO : EPOCH 3 - PROGRESS: at 37.30% examples, 2770057 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:26,026 : INFO : EPOCH 3 - PROGRESS: at 74.81% examples, 2784365 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:26,681 : INFO : EPOCH 3: training on 8234555 raw words (7443911 effective words) took 2.7s, 2802167 effective words/s\n",
      "2024-06-06 13:12:27,685 : INFO : EPOCH 4 - PROGRESS: at 37.31% examples, 2765512 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:28,688 : INFO : EPOCH 4 - PROGRESS: at 74.32% examples, 2762110 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:29,357 : INFO : EPOCH 4: training on 8234555 raw words (7443594 effective words) took 2.7s, 2782824 effective words/s\n",
      "2024-06-06 13:12:30,360 : INFO : EPOCH 5 - PROGRESS: at 37.42% examples, 2777723 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:31,360 : INFO : EPOCH 5 - PROGRESS: at 74.42% examples, 2771429 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:32,020 : INFO : EPOCH 5: training on 8234555 raw words (7443971 effective words) took 2.7s, 2796532 effective words/s\n",
      "2024-06-06 13:12:33,023 : INFO : EPOCH 6 - PROGRESS: at 37.56% examples, 2788712 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:34,026 : INFO : EPOCH 6 - PROGRESS: at 75.36% examples, 2802616 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:34,661 : INFO : EPOCH 6: training on 8234555 raw words (7444848 effective words) took 2.6s, 2820965 effective words/s\n",
      "2024-06-06 13:12:35,665 : INFO : EPOCH 7 - PROGRESS: at 37.31% examples, 2764555 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:36,671 : INFO : EPOCH 7 - PROGRESS: at 75.36% examples, 2795871 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:37,312 : INFO : EPOCH 7: training on 8234555 raw words (7443320 effective words) took 2.7s, 2808786 effective words/s\n",
      "2024-06-06 13:12:38,316 : INFO : EPOCH 8 - PROGRESS: at 36.94% examples, 2740843 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:39,318 : INFO : EPOCH 8 - PROGRESS: at 74.06% examples, 2755361 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:39,997 : INFO : EPOCH 8: training on 8234555 raw words (7443874 effective words) took 2.7s, 2774298 effective words/s\n",
      "2024-06-06 13:12:41,004 : INFO : EPOCH 9 - PROGRESS: at 37.05% examples, 2741572 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:12:42,004 : INFO : EPOCH 9 - PROGRESS: at 74.93% examples, 2782884 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:12:42,659 : INFO : EPOCH 9: training on 8234555 raw words (7443583 effective words) took 2.7s, 2797384 effective words/s\n",
      "2024-06-06 13:12:43,666 : INFO : EPOCH 10 - PROGRESS: at 37.42% examples, 2765333 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:44,671 : INFO : EPOCH 10 - PROGRESS: at 75.36% examples, 2794134 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:45,316 : INFO : EPOCH 10: training on 8234555 raw words (7443540 effective words) took 2.7s, 2803146 effective words/s\n",
      "2024-06-06 13:12:46,323 : INFO : EPOCH 11 - PROGRESS: at 37.09% examples, 2740543 words/s, in_qsize 20, out_qsize 1\n",
      "2024-06-06 13:12:47,325 : INFO : EPOCH 11 - PROGRESS: at 74.31% examples, 2758429 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:47,989 : INFO : EPOCH 11: training on 8234555 raw words (7443921 effective words) took 2.7s, 2785830 effective words/s\n",
      "2024-06-06 13:12:48,991 : INFO : EPOCH 12 - PROGRESS: at 37.56% examples, 2789871 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:49,994 : INFO : EPOCH 12 - PROGRESS: at 75.28% examples, 2800177 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:50,632 : INFO : EPOCH 12: training on 8234555 raw words (7443926 effective words) took 2.6s, 2817802 effective words/s\n",
      "2024-06-06 13:12:51,635 : INFO : EPOCH 13 - PROGRESS: at 36.94% examples, 2745357 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:52,636 : INFO : EPOCH 13 - PROGRESS: at 74.59% examples, 2775244 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:53,298 : INFO : EPOCH 13: training on 8234555 raw words (7443532 effective words) took 2.7s, 2794262 effective words/s\n",
      "2024-06-06 13:12:54,302 : INFO : EPOCH 14 - PROGRESS: at 37.56% examples, 2783903 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:55,305 : INFO : EPOCH 14 - PROGRESS: at 75.62% examples, 2807526 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:55,939 : INFO : EPOCH 14: training on 8234555 raw words (7442832 effective words) took 2.6s, 2819190 effective words/s\n",
      "2024-06-06 13:12:56,941 : INFO : EPOCH 15 - PROGRESS: at 37.56% examples, 2790515 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:12:57,943 : INFO : EPOCH 15 - PROGRESS: at 75.36% examples, 2805960 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:12:58,575 : INFO : EPOCH 15: training on 8234555 raw words (7444549 effective words) took 2.6s, 2825536 effective words/s\n",
      "2024-06-06 13:12:59,580 : INFO : EPOCH 16 - PROGRESS: at 37.68% examples, 2791692 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:13:00,580 : INFO : EPOCH 16 - PROGRESS: at 75.86% examples, 2820728 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:13:01,239 : INFO : EPOCH 16: training on 8234555 raw words (7444059 effective words) took 2.7s, 2796413 effective words/s\n",
      "2024-06-06 13:13:02,242 : INFO : EPOCH 17 - PROGRESS: at 37.31% examples, 2766798 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:13:03,246 : INFO : EPOCH 17 - PROGRESS: at 73.25% examples, 2722596 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:13:03,947 : INFO : EPOCH 17: training on 8234555 raw words (7443816 effective words) took 2.7s, 2750329 effective words/s\n",
      "2024-06-06 13:13:04,951 : INFO : EPOCH 18 - PROGRESS: at 37.44% examples, 2774509 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:13:05,952 : INFO : EPOCH 18 - PROGRESS: at 74.71% examples, 2777675 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:13:06,613 : INFO : EPOCH 18: training on 8234555 raw words (7444026 effective words) took 2.7s, 2793500 effective words/s\n",
      "2024-06-06 13:13:07,622 : INFO : EPOCH 19 - PROGRESS: at 37.44% examples, 2760092 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:13:08,623 : INFO : EPOCH 19 - PROGRESS: at 74.81% examples, 2774780 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:13:09,284 : INFO : EPOCH 19: training on 8234555 raw words (7443555 effective words) took 2.7s, 2787431 effective words/s\n",
      "2024-06-06 13:13:09,285 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148876885 effective words) took 53.3s, 2792809 effective words/s', 'datetime': '2024-06-06T13:13:09.285390', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 13:16:43,481 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w20,mc2,s0.001,t10>', 'datetime': '2024-06-06T13:16:43.481523', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-06-06 13:16:43,481 : INFO : collecting all words and their counts\n",
      "2024-06-06 13:16:43,482 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 - Test F1 Score: 0.6423302286387776\n",
      "Training model with hyperparameters: {'vector_size': 400, 'window': 20, 'min_count': 2, 'epochs': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 13:16:44,197 : INFO : PROGRESS: at example #10000, processed 8060579 words (11277022 words/s), 77097 word types, 0 tags\n",
      "2024-06-06 13:16:44,214 : INFO : collected 77987 word types and 10221 unique tags from a corpus of 10221 examples and 8234555 words\n",
      "2024-06-06 13:16:44,214 : INFO : Creating a fresh vocabulary\n",
      "2024-06-06 13:16:44,275 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 40031 unique words (51.33% of original 77987, drops 37956)', 'datetime': '2024-06-06T13:16:44.275247', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:16:44,275 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8196599 word corpus (99.54% of original 8234555, drops 37956)', 'datetime': '2024-06-06T13:16:44.275618', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:16:44,350 : INFO : deleting the raw counts dictionary of 77987 items\n",
      "2024-06-06 13:16:44,351 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2024-06-06 13:16:44,351 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7433441.747793369 word corpus (90.7%% of prior 8196599)', 'datetime': '2024-06-06T13:16:44.351923', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-06-06 13:16:44,469 : INFO : estimated required memory for 40031 words and 400 dimensions: 166512500 bytes\n",
      "2024-06-06 13:16:44,469 : INFO : resetting layer weights\n",
      "2024-06-06 13:16:44,526 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 40031 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=20 shrink_windows=True', 'datetime': '2024-06-06T13:16:44.526351', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-06-06 13:16:45,533 : INFO : EPOCH 0 - PROGRESS: at 20.70% examples, 1538743 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:46,539 : INFO : EPOCH 0 - PROGRESS: at 42.20% examples, 1561698 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:47,546 : INFO : EPOCH 0 - PROGRESS: at 64.01% examples, 1575519 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:48,548 : INFO : EPOCH 0 - PROGRESS: at 85.31% examples, 1581535 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:49,263 : INFO : EPOCH 0: training on 8234555 raw words (7444014 effective words) took 4.7s, 1572078 effective words/s\n",
      "2024-06-06 13:16:50,268 : INFO : EPOCH 1 - PROGRESS: at 21.22% examples, 1575759 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:51,273 : INFO : EPOCH 1 - PROGRESS: at 42.82% examples, 1587616 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:52,274 : INFO : EPOCH 1 - PROGRESS: at 64.55% examples, 1594518 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:53,282 : INFO : EPOCH 1 - PROGRESS: at 86.07% examples, 1597526 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:53,898 : INFO : EPOCH 1: training on 8234555 raw words (7443977 effective words) took 4.6s, 1606574 effective words/s\n",
      "2024-06-06 13:16:54,900 : INFO : EPOCH 2 - PROGRESS: at 21.22% examples, 1579780 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:55,905 : INFO : EPOCH 2 - PROGRESS: at 42.95% examples, 1594195 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:16:56,911 : INFO : EPOCH 2 - PROGRESS: at 64.90% examples, 1601604 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:16:57,913 : INFO : EPOCH 2 - PROGRESS: at 86.62% examples, 1609128 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:16:58,505 : INFO : EPOCH 2: training on 8234555 raw words (7443458 effective words) took 4.6s, 1615896 effective words/s\n",
      "2024-06-06 13:16:59,508 : INFO : EPOCH 3 - PROGRESS: at 20.85% examples, 1554622 words/s, in_qsize 18, out_qsize 1\n",
      "2024-06-06 13:17:00,513 : INFO : EPOCH 3 - PROGRESS: at 43.04% examples, 1598515 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:01,516 : INFO : EPOCH 3 - PROGRESS: at 64.90% examples, 1603138 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:02,528 : INFO : EPOCH 3 - PROGRESS: at 87.16% examples, 1614962 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:03,100 : INFO : EPOCH 3: training on 8234555 raw words (7443462 effective words) took 4.6s, 1620765 effective words/s\n",
      "2024-06-06 13:17:04,111 : INFO : EPOCH 4 - PROGRESS: at 21.73% examples, 1597515 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:05,113 : INFO : EPOCH 4 - PROGRESS: at 43.73% examples, 1619923 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:06,117 : INFO : EPOCH 4 - PROGRESS: at 66.10% examples, 1628154 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:07,121 : INFO : EPOCH 4 - PROGRESS: at 87.55% examples, 1621871 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:07,663 : INFO : EPOCH 4: training on 8234555 raw words (7443744 effective words) took 4.6s, 1631856 effective words/s\n",
      "2024-06-06 13:17:08,670 : INFO : EPOCH 5 - PROGRESS: at 21.62% examples, 1596082 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:09,672 : INFO : EPOCH 5 - PROGRESS: at 43.63% examples, 1617723 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:10,678 : INFO : EPOCH 5 - PROGRESS: at 65.14% examples, 1606149 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:11,679 : INFO : EPOCH 5 - PROGRESS: at 87.02% examples, 1614785 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:12,249 : INFO : EPOCH 5: training on 8234555 raw words (7443196 effective words) took 4.6s, 1623373 effective words/s\n",
      "2024-06-06 13:17:13,257 : INFO : EPOCH 6 - PROGRESS: at 21.60% examples, 1594515 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:14,260 : INFO : EPOCH 6 - PROGRESS: at 43.73% examples, 1621026 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:15,265 : INFO : EPOCH 6 - PROGRESS: at 66.20% examples, 1631147 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:16,268 : INFO : EPOCH 6 - PROGRESS: at 88.11% examples, 1632732 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:16,802 : INFO : EPOCH 6: training on 8234555 raw words (7442840 effective words) took 4.6s, 1635116 effective words/s\n",
      "2024-06-06 13:17:17,820 : INFO : EPOCH 7 - PROGRESS: at 21.73% examples, 1587492 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:18,824 : INFO : EPOCH 7 - PROGRESS: at 43.86% examples, 1616894 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:19,829 : INFO : EPOCH 7 - PROGRESS: at 65.99% examples, 1619787 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:20,832 : INFO : EPOCH 7 - PROGRESS: at 88.11% examples, 1628629 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:21,357 : INFO : EPOCH 7: training on 8234555 raw words (7443693 effective words) took 4.6s, 1634832 effective words/s\n",
      "2024-06-06 13:17:22,362 : INFO : EPOCH 8 - PROGRESS: at 21.62% examples, 1599333 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:23,362 : INFO : EPOCH 8 - PROGRESS: at 43.73% examples, 1625124 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:24,367 : INFO : EPOCH 8 - PROGRESS: at 65.99% examples, 1628235 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:25,369 : INFO : EPOCH 8 - PROGRESS: at 88.20% examples, 1637601 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:25,894 : INFO : EPOCH 8: training on 8234555 raw words (7442998 effective words) took 4.5s, 1640955 effective words/s\n",
      "2024-06-06 13:17:26,901 : INFO : EPOCH 9 - PROGRESS: at 21.81% examples, 1613197 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:27,903 : INFO : EPOCH 9 - PROGRESS: at 43.99% examples, 1631707 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:28,908 : INFO : EPOCH 9 - PROGRESS: at 66.31% examples, 1634841 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:29,913 : INFO : EPOCH 9 - PROGRESS: at 88.33% examples, 1636956 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:30,420 : INFO : EPOCH 9: training on 8234555 raw words (7443019 effective words) took 4.5s, 1644677 effective words/s\n",
      "2024-06-06 13:17:31,422 : INFO : EPOCH 10 - PROGRESS: at 21.73% examples, 1612726 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:32,422 : INFO : EPOCH 10 - PROGRESS: at 43.86% examples, 1632738 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:33,425 : INFO : EPOCH 10 - PROGRESS: at 66.44% examples, 1642950 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:34,437 : INFO : EPOCH 10 - PROGRESS: at 88.43% examples, 1640424 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:34,932 : INFO : EPOCH 10: training on 8234555 raw words (7443445 effective words) took 4.5s, 1650276 effective words/s\n",
      "2024-06-06 13:17:35,938 : INFO : EPOCH 11 - PROGRESS: at 21.81% examples, 1615449 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:36,938 : INFO : EPOCH 11 - PROGRESS: at 43.86% examples, 1629859 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:37,948 : INFO : EPOCH 11 - PROGRESS: at 66.32% examples, 1634054 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:38,952 : INFO : EPOCH 11 - PROGRESS: at 88.54% examples, 1641243 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:39,478 : INFO : EPOCH 11: training on 8234555 raw words (7444053 effective words) took 4.5s, 1638177 effective words/s\n",
      "2024-06-06 13:17:40,484 : INFO : EPOCH 12 - PROGRESS: at 21.73% examples, 1605254 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:41,485 : INFO : EPOCH 12 - PROGRESS: at 43.99% examples, 1632870 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:42,487 : INFO : EPOCH 12 - PROGRESS: at 66.31% examples, 1638184 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:43,488 : INFO : EPOCH 12 - PROGRESS: at 88.43% examples, 1642946 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:43,993 : INFO : EPOCH 12: training on 8234555 raw words (7444243 effective words) took 4.5s, 1649224 effective words/s\n",
      "2024-06-06 13:17:44,995 : INFO : EPOCH 13 - PROGRESS: at 21.59% examples, 1603863 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:46,005 : INFO : EPOCH 13 - PROGRESS: at 44.11% examples, 1633610 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:47,011 : INFO : EPOCH 13 - PROGRESS: at 66.56% examples, 1639168 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:48,012 : INFO : EPOCH 13 - PROGRESS: at 88.54% examples, 1641832 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:48,500 : INFO : EPOCH 13: training on 8234555 raw words (7444232 effective words) took 4.5s, 1652056 effective words/s\n",
      "2024-06-06 13:17:49,506 : INFO : EPOCH 14 - PROGRESS: at 21.73% examples, 1607990 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:50,507 : INFO : EPOCH 14 - PROGRESS: at 43.99% examples, 1634091 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:51,515 : INFO : EPOCH 14 - PROGRESS: at 66.20% examples, 1632857 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:52,516 : INFO : EPOCH 14 - PROGRESS: at 88.67% examples, 1645295 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:53,011 : INFO : EPOCH 14: training on 8234555 raw words (7443576 effective words) took 4.5s, 1651007 effective words/s\n",
      "2024-06-06 13:17:54,018 : INFO : EPOCH 15 - PROGRESS: at 21.81% examples, 1612843 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:55,021 : INFO : EPOCH 15 - PROGRESS: at 44.11% examples, 1635012 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:56,035 : INFO : EPOCH 15 - PROGRESS: at 67.03% examples, 1647297 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:57,036 : INFO : EPOCH 15 - PROGRESS: at 89.32% examples, 1652134 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:17:57,506 : INFO : EPOCH 15: training on 8234555 raw words (7443316 effective words) took 4.5s, 1656699 effective words/s\n",
      "2024-06-06 13:17:58,512 : INFO : EPOCH 16 - PROGRESS: at 21.92% examples, 1621861 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:17:59,516 : INFO : EPOCH 16 - PROGRESS: at 44.51% examples, 1647941 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:18:00,517 : INFO : EPOCH 16 - PROGRESS: at 66.67% examples, 1645625 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:01,519 : INFO : EPOCH 16 - PROGRESS: at 88.54% examples, 1644104 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:18:02,011 : INFO : EPOCH 16: training on 8234555 raw words (7444266 effective words) took 4.5s, 1652779 effective words/s\n",
      "2024-06-06 13:18:03,014 : INFO : EPOCH 17 - PROGRESS: at 21.81% examples, 1621043 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:18:04,018 : INFO : EPOCH 17 - PROGRESS: at 44.23% examples, 1642302 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:05,019 : INFO : EPOCH 17 - PROGRESS: at 66.56% examples, 1644385 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:06,022 : INFO : EPOCH 17 - PROGRESS: at 88.67% examples, 1647381 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:06,510 : INFO : EPOCH 17: training on 8234555 raw words (7443682 effective words) took 4.5s, 1655424 effective words/s\n",
      "2024-06-06 13:18:07,515 : INFO : EPOCH 18 - PROGRESS: at 21.81% examples, 1615340 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:08,516 : INFO : EPOCH 18 - PROGRESS: at 44.11% examples, 1637665 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:18:09,519 : INFO : EPOCH 18 - PROGRESS: at 66.44% examples, 1640594 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:10,520 : INFO : EPOCH 18 - PROGRESS: at 89.05% examples, 1653831 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:11,003 : INFO : EPOCH 18: training on 8234555 raw words (7443512 effective words) took 4.5s, 1657011 effective words/s\n",
      "2024-06-06 13:18:12,013 : INFO : EPOCH 19 - PROGRESS: at 21.73% examples, 1600543 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:13,019 : INFO : EPOCH 19 - PROGRESS: at 44.11% examples, 1630568 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:14,023 : INFO : EPOCH 19 - PROGRESS: at 67.04% examples, 1649179 words/s, in_qsize 20, out_qsize 0\n",
      "2024-06-06 13:18:15,025 : INFO : EPOCH 19 - PROGRESS: at 89.06% examples, 1648899 words/s, in_qsize 19, out_qsize 0\n",
      "2024-06-06 13:18:15,503 : INFO : EPOCH 19: training on 8234555 raw words (7444079 effective words) took 4.5s, 1654753 effective words/s\n",
      "2024-06-06 13:18:15,503 : INFO : Doc2Vec lifecycle event {'msg': 'training on 164691100 raw words (148872805 effective words) took 91.0s, 1636355 effective words/s', 'datetime': '2024-06-06T13:18:15.503915', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 - Train F1 Score: 0.6331577663310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-06-06 13:25:38,961 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'best_doc2vec_model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-06-06T13:25:38.961010', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'saving'}\n",
      "2024-06-06 13:25:38,961 : INFO : storing np array 'vectors' to best_doc2vec_model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 - Test F1 Score: 0.6423302286387776\n",
      "Best Hyperparameters: {'vector_size': 400, 'window': 10, 'min_count': 2, 'epochs': 20}\n",
      "Best Train F1 Score: 0.6331577663310187\n",
      "Best Test F1 Score: 0.6423302286387776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 13:25:39,216 : INFO : storing np array 'syn1neg' to best_doc2vec_model.syn1neg.npy\n",
      "2024-06-06 13:25:39,259 : INFO : not storing attribute cum_table\n",
      "2024-06-06 13:25:39,284 : INFO : saved best_doc2vec_model\n",
      "2024-06-06 13:25:39,284 : INFO : loading Doc2Vec object from best_doc2vec_model\n",
      "2024-06-06 13:25:39,292 : INFO : loading dv recursively from best_doc2vec_model.dv.* with mmap=None\n",
      "2024-06-06 13:25:39,292 : INFO : loading wv recursively from best_doc2vec_model.wv.* with mmap=None\n",
      "2024-06-06 13:25:39,292 : INFO : loading vectors from best_doc2vec_model.wv.vectors.npy with mmap=None\n",
      "2024-06-06 13:25:39,301 : INFO : loading syn1neg from best_doc2vec_model.syn1neg.npy with mmap=None\n",
      "2024-06-06 13:25:39,310 : INFO : setting ignored attribute cum_table to None\n",
      "2024-06-06 13:25:39,430 : INFO : Doc2Vec lifecycle event {'fname': 'best_doc2vec_model', 'datetime': '2024-06-06T13:25:39.430257', 'gensim': '4.3.2', 'python': '3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 108\u001b[0m\n\u001b[1;32m    106\u001b[0m train_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_train_vectors, y_train, num_clusters)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Training Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_train, \u001b[43m[\u001b[49m\u001b[43mtrain_report\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajority_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    110\u001b[0m test_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_test_vectors, y_test, num_clusters)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Testing Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 108\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m train_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_train_vectors, y_train, num_clusters)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Training Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_train, [\u001b[43mtrain_report\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajority_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clusters)]))\n\u001b[1;32m    110\u001b[0m test_report \u001b[38;5;241m=\u001b[39m evaluate_model(X_test_vectors, y_test, num_clusters)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Testing Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import logging\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Set up logging for verbose output\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Function to train Doc2Vec model with given hyperparameters\n",
    "def train_doc2vec(X_train, X_test, vector_size, window, min_count, epochs):\n",
    "    train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "    \n",
    "    model = Doc2Vec(\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=10,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    model.build_vocab(train_documents)\n",
    "    model.train(train_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    # Infer vectors for training and testing data\n",
    "    X_train_vectors = [model.infer_vector(doc) for doc in X_train]\n",
    "    X_test_vectors = [model.infer_vector(doc) for doc in X_test]\n",
    "    \n",
    "    return model, X_train_vectors, X_test_vectors\n",
    "\n",
    "# Function to perform GMM clustering and evaluation\n",
    "def evaluate_model(X_vectors, y_true, num_clusters):\n",
    "    gmm = GaussianMixture(n_components=num_clusters, random_state=42)\n",
    "    clusters = gmm.fit_predict(X_vectors)\n",
    "    \n",
    "    cluster_mapping = {}\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_data = y_true[clusters == cluster]\n",
    "        if not cluster_data.empty:\n",
    "            common_severity_level = cluster_data.mode().values[0]\n",
    "            cluster_mapping[cluster] = common_severity_level\n",
    "    \n",
    "    y_pred = [cluster_mapping[cluster] for cluster in clusters]\n",
    "    return classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Hyperparameter ranges\n",
    "param_grid = {\n",
    "    'vector_size': [100, 200, 400],\n",
    "    'window': [5, 10, 20],\n",
    "    'min_count': [2],\n",
    "    'epochs': [20, 40]\n",
    "}\n",
    "\n",
    "# Generate random hyperparameter combinations\n",
    "def random_search(param_grid, n_iter=10):\n",
    "    keys = list(param_grid.keys())\n",
    "    hyperparams_list = []\n",
    "    for _ in range(n_iter):\n",
    "        params = {key: random.choice(param_grid[key]) for key in keys}\n",
    "        hyperparams_list.append(params)\n",
    "    return hyperparams_list\n",
    "\n",
    "# Perform randomized grid search\n",
    "random_hyperparams = random_search(param_grid, n_iter=10)\n",
    "num_clusters = 3\n",
    "best_train_score = 0\n",
    "best_test_score = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for i, params in enumerate(random_hyperparams):\n",
    "    print(f\"Training model with hyperparameters: {params}\")\n",
    "    model, X_train_vectors, X_test_vectors = train_doc2vec(X_train, X_test, **params)\n",
    "    \n",
    "    train_result = evaluate_model(X_train_vectors, y_train, num_clusters)\n",
    "    train_score = train_result['weighted avg']['f1-score']\n",
    "    print(f\"Iteration {i+1} - Train F1 Score: {train_score}\")\n",
    "    \n",
    "    test_result = evaluate_model(X_test_vectors, y_test, num_clusters)\n",
    "    test_score = test_result['weighted avg']['f1-score']\n",
    "    print(f\"Iteration {i+1} - Test F1 Score: {test_score}\")\n",
    "    \n",
    "    if test_score > best_test_score:\n",
    "        best_train_score = train_score\n",
    "        best_test_score = test_score\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train F1 Score: {best_train_score}\")\n",
    "print(f\"Best Test F1 Score: {best_test_score}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model:\n",
    "    best_model.save(\"best_doc2vec_model\")\n",
    "\n",
    "# Load the best model for final evaluation\n",
    "loaded_model = Doc2Vec.load(\"best_doc2vec_model\")\n",
    "\n",
    "# Infer vectors using the loaded model\n",
    "X_train_vectors = [loaded_model.infer_vector(doc) for doc in X_train]\n",
    "X_test_vectors = [loaded_model.infer_vector(doc) for doc in X_test]\n",
    "\n",
    "# Evaluate with the loaded model\n",
    "train_report = evaluate_model(X_train_vectors, y_train, num_clusters)\n",
    "print(\"\\nFinal Training Classification Report:\")\n",
    "print(classification_report(y_train, [train_report[i]['majority_label'] for i in range(num_clusters)]))\n",
    "\n",
    "test_report = evaluate_model(X_test_vectors, y_test, num_clusters)\n",
    "print(\"\\nFinal Testing Classification Report:\")\n",
    "print(classification_report(y_test, [test_report[i]['majority_label'] for i in range(num_clusters)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Extract vectors\n",
    "vectors = np.array(df['doc2vec_vector'].tolist())\n",
    "\n",
    "# Define number of clusters\n",
    "num_clusters = 3  # This should be tuned based on your data\n",
    "\n",
    "# Train K-Means model\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from clusters to discharge types\n",
    "cluster_mapping = {}\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "    common_discharge_type = cluster_data['severity_level'].mode().values[0]\n",
    "    cluster_mapping[cluster] = common_discharge_type\n",
    "\n",
    "# Map clusters to discharge types\n",
    "df['predicted_severity_level'] = df['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      " Minimal Care/Recovery at Home       0.74      1.00      0.85      9508\n",
      "Moderate Care/Support Required       0.00      0.00      0.00      2723\n",
      "                Severe Outcome       0.00      0.00      0.00       546\n",
      "\n",
      "                      accuracy                           0.74     12777\n",
      "                     macro avg       0.25      0.33      0.28     12777\n",
      "                  weighted avg       0.55      0.74      0.63     12777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification\n",
    "print(classification_report(df['severity_level'], df['predicted_severity_level']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m min_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[1;32m     39\u001b[0m dm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# PV-DM\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_doc2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Extract vectors\u001b[39;00m\n\u001b[1;32m     44\u001b[0m vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc2vec_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mtrain_doc2vec\u001b[0;34m(vector_size, window, min_count, epochs, alpha, min_alpha, dm)\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(\n\u001b[1;32m     17\u001b[0m     documents,\n\u001b[1;32m     18\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mvector_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     dm\u001b[38;5;241m=\u001b[39mdm\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Infer vectors for the documents\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc2vec_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mtrain_doc2vec.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(\n\u001b[1;32m     17\u001b[0m     documents,\n\u001b[1;32m     18\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mvector_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     dm\u001b[38;5;241m=\u001b[39mdm\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Infer vectors for the documents\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc2vec_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/doc2vec.py:651\u001b[0m, in \u001b[0;36mDoc2Vec.infer_vector\u001b[0;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         train_document_dm_concat(\n\u001b[1;32m    647\u001b[0m             \u001b[38;5;28mself\u001b[39m, doc_words, doctag_indexes, alpha, work, neu1,\n\u001b[1;32m    648\u001b[0m             learn_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, learn_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, doctag_vectors\u001b[38;5;241m=\u001b[39mdoctag_vectors, doctags_lockf\u001b[38;5;241m=\u001b[39mdoctags_lockf\n\u001b[1;32m    649\u001b[0m         )\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m         \u001b[43mtrain_document_dm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneu1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearn_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctag_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctags_lockf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctags_lockf\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     alpha \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m alpha_delta\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doctag_vectors[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to train Doc2Vec model with given hyperparameters\n",
    "def train_doc2vec(vector_size, window, min_count, epochs, alpha, min_alpha, dm):\n",
    "    # Create TaggedDocument\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['tokens'])]\n",
    "\n",
    "    # Train Doc2Vec model\n",
    "    model = Doc2Vec(\n",
    "        documents,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=10,\n",
    "        epochs=epochs,\n",
    "        alpha=alpha,\n",
    "        min_alpha=min_alpha,\n",
    "        dm=dm\n",
    "    )\n",
    "\n",
    "    # Infer vectors for the documents\n",
    "    df['doc2vec_vector'] = df['tokens'].apply(lambda x: model.infer_vector(x))\n",
    "    return model\n",
    "\n",
    "# Train the model with different hyperparameters\n",
    "vector_size = 300\n",
    "window = 5\n",
    "min_count = 2\n",
    "epochs = 40\n",
    "alpha = 0.025\n",
    "min_alpha = 0.0001\n",
    "dm = 1  # PV-DM\n",
    "\n",
    "model = train_doc2vec(vector_size, window, min_count, epochs, alpha, min_alpha, dm)\n",
    "\n",
    "# Extract vectors\n",
    "vectors = np.array(df['doc2vec_vector'].tolist())\n",
    "\n",
    "# Define number of clusters\n",
    "num_clusters = 3  # This should be tuned based on your data\n",
    "\n",
    "# Train K-Means model\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(vectors)\n",
    "\n",
    "# Create a mapping from clusters to discharge types\n",
    "cluster_mapping = {}\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "    common_discharge_type = cluster_data['severity_level'].mode().values[0]\n",
    "    cluster_mapping[cluster] = common_discharge_type\n",
    "\n",
    "# Map clusters to discharge types\n",
    "df['predicted_severity_level'] = df['cluster'].map(cluster_mapping)\n",
    "\n",
    "# Evaluate the classification\n",
    "print(classification_report(df['severity_level'], df['predicted_severity_level']))\n",
    "\n",
    "# Experiment with different hyperparameters\n",
    "hyperparams = [\n",
    "    {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 50, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1},\n",
    "    {'vector_size': 400, 'window': 10, 'min_count': 2, 'epochs': 60, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1},\n",
    "    {'vector_size': 300, 'window': 5, 'min_count': 5, 'epochs': 40, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 0},\n",
    "    {'vector_size': 300, 'window': 5, 'min_count': 2, 'epochs': 100, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1},\n",
    "]\n",
    "\n",
    "for params in hyperparams:\n",
    "    model = train_doc2vec(**params)\n",
    "    vectors = np.array(df['doc2vec_vector'].tolist())\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(vectors)\n",
    "    cluster_mapping = {}\n",
    "\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_data = df[df['cluster'] == cluster]\n",
    "        common_discharge_type = cluster_data['severity_level'].mode().values[0]\n",
    "        cluster_mapping[cluster] = common_discharge_type\n",
    "\n",
    "    df['predicted_severity_level'] = df['cluster'].map(cluster_mapping)\n",
    "    print(f\"Hyperparameters: {params}\")\n",
    "    print(classification_report(df['severity_level'], df['predicted_severity_level']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparameters: {'vector_size': 300, 'window': 10, 'min_count': 5, 'epochs': 50, 'alpha': 0.025, 'min_alpha': 0.0001, 'dm': 1}\n",
      "Tagged Documents\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_hyperparams):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model with hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_doc2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluate_model(num_clusters)\n\u001b[1;32m     78\u001b[0m     score \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mtrain_doc2vec\u001b[0;34m(vector_size, window, min_count, epochs, alpha, min_alpha, dm)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTagged Documents\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train Doc2Vec model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDoc2Vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Infer vectors for the documents\u001b[39;00m\n\u001b[1;32m     30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc2vec_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: model\u001b[38;5;241m.\u001b[39minfer_vector(x))\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/doc2vec.py:296\u001b[0m, in \u001b[0;36mDoc2Vec.__init__\u001b[0;34m(self, documents, corpus_file, vector_size, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, dv, dv_mapfile, comment, trim_rule, callbacks, window, epochs, shrink_windows, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# EXPERIMENTAL lockf feature; create minimal no-op lockf arrays (1 element of 1.0)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# advanced users should directly resize/adjust as desired after any vocab growth\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdv\u001b[38;5;241m.\u001b[39mvectors_lockf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mREAL)  \u001b[38;5;66;03m# 0.0 values suppress word-backprop-updates; 1.0 allows\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnull_word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdm_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[1;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[1;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[1;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/site-packages/gensim/models/word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/cse251u/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "\n",
    "# Function to train Doc2Vec model with given hyperparameters\n",
    "def train_doc2vec(vector_size, window, min_count, epochs, alpha, min_alpha, dm):\n",
    "    # Create TaggedDocument\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['tokens'])]\n",
    "    print('Tagged Documents')\n",
    "    # Train Doc2Vec model\n",
    "    model = Doc2Vec(\n",
    "        documents,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=10,\n",
    "        epochs=epochs,\n",
    "        alpha=alpha,\n",
    "        min_alpha=min_alpha,\n",
    "        dm=dm\n",
    "    )\n",
    "\n",
    "    # Infer vectors for the documents\n",
    "    df['doc2vec_vector'] = df['tokens'].apply(lambda x: model.infer_vector(x))\n",
    "    return model\n",
    "\n",
    "# Function to perform K-Means clustering and evaluation\n",
    "def evaluate_model(num_clusters):\n",
    "    vectors = np.array(df['doc2vec_vector'].tolist())\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(vectors)\n",
    "\n",
    "    cluster_mapping = {}\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_data = df[df['cluster'] == cluster]\n",
    "        common_discharge_type = cluster_data['severity_level'].mode().values[0]\n",
    "        cluster_mapping[cluster] = common_discharge_type\n",
    "\n",
    "    df['predicted_severity_level'] = df['cluster'].map(cluster_mapping)\n",
    "    return classification_report(df['severity_level'], df['predicted_severity_level'], output_dict=True)\n",
    "\n",
    "# Hyperparameter ranges\n",
    "param_grid = {\n",
    "    'vector_size': [200, 300, 400],\n",
    "    'window': [5, 10],\n",
    "    'min_count': [2, 5],\n",
    "    'epochs': [10],\n",
    "    'alpha': [0.025],\n",
    "    'min_alpha': [0.0001],\n",
    "    'dm': [0, 1]\n",
    "}\n",
    "\n",
    "# Generate random hyperparameter combinations\n",
    "def random_search(param_grid, n_iter=10):\n",
    "    keys = list(param_grid.keys())\n",
    "    hyperparams_list = []\n",
    "    for _ in range(n_iter):\n",
    "        params = {key: random.choice(param_grid[key]) for key in keys}\n",
    "        hyperparams_list.append(params)\n",
    "    return hyperparams_list\n",
    "\n",
    "# Perform randomized grid search\n",
    "random_hyperparams = random_search(param_grid, n_iter=10)\n",
    "num_clusters = 3\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for i, params in enumerate(random_hyperparams):\n",
    "    print(f\"Training model with hyperparameters: {params}\")\n",
    "    model = train_doc2vec(**params)\n",
    "    result = evaluate_model(num_clusters)\n",
    "    score = result['weighted avg']['f1-score']\n",
    "    print(f\"Iteration {i+1} - F1 Score: {score}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "# Retrain with best hyperparameters and evaluate\n",
    "if best_params:\n",
    "    model = train_doc2vec(**best_params)\n",
    "    final_report = evaluate_model(num_clusters)\n",
    "    print(\"Final Classification Report:\")\n",
    "    print(classification_report(df['severity_level'], df['predicted_severity_level']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse251u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
